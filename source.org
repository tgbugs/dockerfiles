# -*- orgstrap-cypher: sha256; orgstrap-norm-func-name: orgstrap-norm-func--prp-1\.1; orgstrap-block-checksum: 6b7135beb5779c7a931e94673c9a18c95f656ff5f9fa4e9484669949c8072d01; -*-
# [[orgstrap][jump to the orgstrap block for this file]]
#+title: Literate source for docker files

#+property: header-args :eval no-export
#+property: header-args:bash :var BUILDKIT_PROGRESS="plain"
#+property: header-args:conf :mkdirp yes :noweb yes
#+property: header-args:dockerfile :noweb yes :mkdirp yes :comments link
#+property: header-args:screen :session org-session :cmd sh :noweb yes

#+name: orgstrap-shebang
#+begin_src bash :eval never :results none :exports none
{ __p=$(mktemp -d);touch ${__p}/=;chmod +x ${__p}/=;__op=$PATH;PATH=${__p}:$PATH;} > ${null="/dev/null"}
$file= $MyInvocation.MyCommand.Source
$ErrorActionPreference= "silentlycontinue"
file=$0
args=$@
$ErrorActionPreference= "Continue"
{ PATH=$__op;rm ${__p}/=;rmdir ${__p};} > $null
emacs -batch -no-site-file -eval "(let (vc-follow-symlinks) (defun orgstrap--confirm-eval (l _) (not (memq (intern l) '(elisp emacs-lisp)))) (let ((file (pop argv)) enable-local-variables) (find-file-literally file) (end-of-line) (when (eq (char-before) ?\^m) (let ((coding-system-for-read 'utf-8)) (revert-buffer nil t t)))) (let ((enable-local-eval t) (enable-local-variables :all) (major-mode 'org-mode)) (require 'org) (org-set-regexps-and-options) (hack-local-variables)))" "${file}" -- $args
exit
<# powershell open
#+end_src

* Setup
** Server
*** docker config
Docker files in this repo use buildkit features. To enable it include
the following in [[/etc/docker/daemon.json]].
#+name: docker-daemon-config
#+begin_src json :tangle /etc/docker/daemon.json :tangle no
{"experimental": true,
 "features": {"buildkit": true}}
#+end_src
*** portage ssh keys
Make sure that =/var/lib/portage/home/.ssh= exists and has the keys
for accessing the interlex repo or other private repos.
*** distcc hosts
Even if you are not using distcc be sure to run
#+begin_src bash
touch /etc/distcc/hosts.docker
#+end_src
on the host os otherwise the builder functions will produce cryptic
errors for some packages because they can handle an absent
/etc/distcc/hosts file but not one that is a directory. Note that
docker has what might be considered a reasonable default which is that
it will create a directory if it does not exist when it is the source
of a mount rather than fail ... but in our case this is annoying, and
the cleanup is a pita, have to unmount and rmdir in the image, or just
resnap the image because wow what a pain.

** Client
Building the precursor images in =gentoo/stage3= for this repo from
[[https://github.com/gentoo/gentoo-docker-images][scratch]] requires the =buildx= extension which requires experimental
features to be enabled in the client.

If you want to push the images to a remote docker repository add the
auths section as well (and fill it in with your credentials).
#+name: docker-client-config
#+begin_src json :tangle ~/.docker/config.json :tangle no
{"experimental": "enabled",
 "auths": {
   "https://index.docker.io/v1/": {
     "auth": "XXX NOT A REAL KEY FILL ME IN XXX"}}}
#+end_src

** Package host
Prepare package host folders. The server will be started automatically
below if it is not already up.
#+begin_src screen
mkdir -p ~/files/binpkgs/multi
#+end_src
*** prepare all binpkg repos
We have to prepare all the binpkg repos so that during a first build
they have some basic metadata, otherwise trying to emerge binpkgs will
fail with strange errors in strange ways.
#+name: &run-quickpkg-first-time
#+begin_src screen
for stage3 in {hardened,amd64-musl-hardened}; do
    docker pull gentoo/stage3:${stage3}
    docker run \
    -v ~/files/binpkgs/multi:/var/cache/binpkgs \
    -e FEATURES=binpkg-multi-instance \
    -e QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022" \
    --rm \
    gentoo/stage3:${stage3} \
    quickpkg "virtual/ssh";
done
#+end_src

** Portage git ssh access
Needed for live ebuilds that point to private git repos.
Eventually this should be baked into the docker in docker top level image.

You will need to generate ssh keys for the host system if they do not
already exist, and you will need to register them with the git remote.

This is similar to what we do for [[*portage-maven][portage-maven]].

The default location for the portage home directory is now
=/var/lib/portage/home/.ssh= which means that the ssh config and
private keys can be stored there persistently and safely without
violating the sandbox during package fetch.

In the even that you have to deal with some strange legacy case you
may want to symlink a path outside the sandbox to a path inside the
sandbox due to the change in home directory from =/var/tmp/portage= ->
=/var/lib/portage/home=. Inside the images we have to run
=ln -s /var/tmp/portage/.ssh /var/lib/portage/home/.ssh=.

If =/var/tmp/portage= is still the portage home folder and it is a
ramdisk that is wiped on reboot you will want the following.
#+begin_src bash :tangle /su::/etc/local.d/20portage-symlinks.start :tangle-mode 0755 :tangle no
# relink .ssh across restarts
ln -s /mnt/str/portage/.ssh /var/tmp/portage/
chown -h portage:portage /var/tmp/portage/.ssh
#+end_src

** git ignore
This takes care of itself.
#+begin_src conf :tangle .gitignore
.gitignore
docker-profile/*
repos/*
musl/*
gnu/*
other/*
sckan/*
#+end_src
* Ops
** CLI
The standard way to use this file to build is to run the following block
WARNING: never run this command from inside the =org-session= screen, input
will be severely broken
#+begin_src bash
./source.org build --refresh --repos --resnap --live-rebuild
#+end_src
** Build
If you are bootstrapping this file from scratch you will need to build
dependent images in order.

To prepare a fresh cycle of images.
# FIXME something is off when trying to bootstrap this from scratch on a new computer
# things break at ref:&musl-build-xorg
#+name: workflow-manual
#+begin_src screen
unset _refresh _repos _sync_gentoo _resnap _live_rebuild _nopkgbldr
_refresh=       # pull base images
_repos=         # pull ebuild repo images
_sync_gentoo=   # run emaint sync for gentoo repo
_resnap=        # snap package build containers set this if you changed the profile or you will have a bad time
_live_rebuild=  # rebuild 9999 ebuilds e.g. from git
_nopkgbldr=     # do not run package building steps

<<&workflow-vars>>
<<&workflow-common>>
#+end_src

#+name: &workflow-vars
#+begin_src bash
# XXX NOTE that these are embedded in the docker files right now
_img_stage3=${_img_stage3:-gentoo/stage3:amd64-musl-hardened}

__is3_0=${_img_stage3/\//-}
__is3_1=${__is3_0/:/-}
__src_from_img=${__is3_1/gentoo/latest}
_src_stage3=${__src_stage3:-${__src_from_img}}

_img_portage=${_img_portage:-gentoo/portage:latest}
#+end_src

#+name: workflow-cli
#+begin_src screen
<<&screen-set-vars>>
<<&workflow-vars>>
<<&workflow-common>>
#+end_src

#+name: &workflow-common
#+begin_src screen
<<&workflow-funs>>

package-server
pull
pushd ~/git/dockerfiles
tangle &&
run-musl
# package host
# build a bunch of packages
popd
#+end_src

# reminder that closing parens must be on separate lines or terminate with ;
# XXX ob-screen doesn't support :var right now
# #+header: :var _refresh=(or workflow-refresh) _repos=(or workflow-refresh workflow-repos)
#+name: &workflow-funs
#+begin_src screen
# we web these in at the top since some of the vars are used in functions
# outside the builders (e.g. package-server)

<<&builder-vars>>

function package-server () {
# FIXME needs to run in another terminal, container, or daemon
# but for now it blocks other commands which is ok
curl --fail --head http://localhost:8089/${_binpkgs_repo_name}/Packages || {
    pushd ${_path_binpkgs_root}
    python -m http.server 8089 --bind 127.0.0.1
    popd
}
}

function pull () {
if [ -n "${_refresh}" ]; then
    # even when refresh is set avoid spurious pulls where the underlying stage3 has not changed
    local DIST="https://distfiles.gentoo.org/releases/amd64/autobuilds"
    local STAGE3_LATEST="$(curl --fail --silent "${DIST}/${_src_stage3}.txt" |\
        tail -n 1 | cut -f 1 -d'/' | sed -r 's/(....)(..)(..)T(..)(..)(..)/\1-\2-\3T\4:\5:\6/')"
    local LOCDOC_LATEST="$(docker image inspect ${_img_stage3} --format '{{.Created}}')"
    local S3_DATE=$(date -In --utc --date "${STAGE3_LATEST}")
    local LD_DATE=$(date -In --utc --date "${LOCDOC_LATEST}")
    # XXX there is technically a narrow window between the release of
    # a stage3 and the building of a docker image where this might fail
    # have to use double square brackets for this to work correctly
    [[ ${S3_DATE} < ${LD_DATE} ]] || \
    docker pull ${_img_stage3}
fi

if [ -n "${_refresh}" ] || [ -n "${_repos}" ]; then
    # these are updated more or less in sync with the upstream snapshot source
    docker pull ${_img_portage}
    docker rm local-portage-snap
    docker create -v /var/db/repos/gentoo --name local-portage-snap ${_img_portage} /bin/true
fi
}

function tangle () {
[ -d ./bin ] && rm -r ./bin
[ -d ./docker-profile ] && rm -r ./docker-profile
[ -d ./gnu ] && rm -r ./gnu
[ -d ./musl ] && rm -r ./musl
[ -d ./repos ] && rm -r ./repos
[ -d ./other ] && rm -r ./other
./source.org tangle
return $?
}

function run-gnu () {
echo TODO
}

<<&container-check>>

<<&builder-resnap>>

<<&builder-bootstrap>>

<<&builder-world>>

<<&builder-arb>>

<<&builder-arb-priv>>

<<&builder-debug>>

function run-musl () {
local REPOS="${_repos}"
local SYNC_GENTOO="${_sync_gentoo}"
local RESNAP="${_resnap}"
local LIVE_REBUILD="${_live_rebuild}"
local NOBUILD="${_nopkgbldr}"
echo start bootstrap
<<&musl-build-user>> || return $?;
<<&musl-build-portage-maven>> || return $?;
<<&musl-build-profile>> || return $?;
<<&musl-build-profile-x>> || return $?;
<<&musl-build-profile-nox>> || return $?;
<<&musl-build-profile-static-x>> || return $?;
  <<&musl-build-eselect-repo>> || return $?;
    [ -z $REPOS ] || {
    <<&repos-build-repos>> || return $?;
    docker container inspect local-repos-snap > /dev/null &&
    docker rm local-repos-snap;
    docker create -v /var/db/repos --name local-repos-snap tgbugs/repos:latest /bin/true || return $?;
    echo repos done;
    }
    container-check
    <<&musl-build-updated>> || return $?; echo mbu;
      <<&musl-build-updated-user>> || return $?; echo mbuu;
      <<&musl-run-updated-quickpkg>> || return $?; echo mruq;

      <<&musl-build-pypy3>> || return $?; echo mbpypy3;
        <<&musl-run-pypy3-quickpkg>> || return $?; echo mrpypy3q;

        <<&musl-build-package-builder-nox>> || return $?; echo mbpbn;
        <<&musl-build-binpkg-only-nox>> || return $?; echo mbbon;

        # XXX this is the point at which things split into musl and musl/x
        <<&musl-build-xorg>> || return $?; echo mbx;
        <<&musl-run-xorg-quickpkg>> || return $?; echo mrxq;

        <<&musl-build-package-builder>> || return $?; echo mbpb;
        <<&musl-build-binpkg-only>> || return $?; echo mbpo;

        # XXX split to musl/static/x
        <<&musl-build-static-xorg>> || return $?; echo mbsx;
        <<&musl-run-static-xorg-quickpkg>> || return $?; echo mrsxp;

        <<&musl-build-static-package-builder>> || return $?; echo mbspb;
        <<&musl-build-static-binpkg-only>> || return $?; echo mbsbo;


# TODO build any new packages
echo musl builder start
[ -z $RESNAP ] || builder-resnap
[ ! -z $NOBUILD ] || builder-bootstrap
# FIXME this needs to run with --getbinpkg
[ ! -z $NOBUILD ] || \
<<&musl-run-build-need-priv>>
[ ! -z $NOBUILD ] || builder-world || return $?
# TODO smart-live-rebuild
[ -z $LIVE_REBUILD ] || builder-arb @live-rebuild

echo musl static builder start
[ -z $RESNAP ] || static-builder-resnap
# TODO static-builder-bootstrap
[ ! -z $NOBUILD ] || static-builder-world  # FIXME if this is not run once at the start then something fails above
[ -z $LIVE_REBUILD ] || static-builder-arb @live-rebuild

# TODO consider whether we need to rebuild baselayout openrc sgml-common due to config issues with quickpkg

# image builds

echo start image builds

## emacs
<<&musl-build-emacs>> || return $?; echo mbe;  # XXX fail on stale profile is very confusing

## kg
<<&musl-build-kg-release>> || return $?; echo mbkgr;
<<&musl-build-kg-release-user>> || return $?; echo mbkgru;
<<&musl-build-kg-dev>> || return $?; echo mbkgd;
<<&musl-build-kg-dev-user>> || return $?; echo mbkgdu;

## sbcl
<<&musl-build-sbcl>> || return $?; echo mbsbcl;
<<&musl-build-sbcl-user>> || return $?; echo mbsbclu;

## racket
<<&musl-build-racket>> || return $?; echo mbrac;
<<&musl-build-racket-user>> || return $?; echo mbracu;

## dynapad
<<&musl-build-dynapad-base>> || return $?; echo mbdb;
<<&musl-build-dynapad-user>> || return $?; echo mbdbu;
#<<&musl-build-dynapad>> || return $?; # needs to be done by hand

## NIF-ontology
<<&musl-build-icedtea>> || return $?; echo mbicdt;
<<&musl-build-protege>> || return $?; echo mbp;
<<&musl-build-NIF-ontology>> || return $?; echo mbno;

## interlex
<<&musl-build-interlex>> || return $?; echo mbilx;

## sparcur
<<&musl-build-sparcur>> || return $?; echo mbsp;
<<&musl-build-sparcur-user>> || return $?; echo mbspu;

}
#+end_src

# I am an idiot, the repos image is being build incorrectly and pulls
# in the local images so it overrides. DUH.

#+begin_src screen
<<&musl-run-updated-user>>
#+end_src
** Debug build
Sometimes a build will fail.
As long as you aren't using buildkit features such as mount you can
rerun a build command with ~DOCKER_BUILDKIT=0~ prepended which will
keep the intermediate containers around so you can attach to the last
known good layer and try to run things yourself.

Alternately, it may be a better approach to simply truncate the docker
file directly after the last known good step

** Push
To push the latest cycle of images to the default remote run the
following after checking that they work as expected.

#+begin_src bash
for _image in $(docker images --filter=reference="tgbugs/musl:*" --filter=reference="tgbugs/repos:*" --filter=since='tgbugs/musl:eselect-repo' --format "{{.Repository}}:{{.Tag}}" | grep -v snap); do
    docker push "${_image}"
done
#+end_src

** Emergency quickpkg
Sometimes you don't want to wait to get to the package builder step
because there is some bug in between.
#+name: &docker-quickpkg
#+begin_src bash
function docker-quickpkg () {
# FIXME TODO pass the image to package
docker run \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-e FEATURES=binpkg-multi-instance \
-e QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022" \
--rm \
tgbugs/musl:static-xorg \
quickpkg \
${@}
}
#+end_src
** Cleanup
#+name: &docker-cleanup
#+begin_src screen
docker container prune --force
docker volume    prune --force
docker image     prune --force
docker builder   prune --force
#+end_src
* Default variables
Default variable values that will eventually have cli overrides.
# At the moment I'm not going to implement full command line processing via ow-cli.
#+name: &host-binpkgs-root-path
: ~/files/binpkgs

NOTE: we will not be making the repo name configurable, it only
appears to be for implementation convenience.
#+name: &host-binpkgs-repo-name
: multi

#+name: &host-distfiles-path
: /mnt/str/portage/distfiles

#+name: &host-distcc-hosts-path
: /etc/distcc/hosts.docker

#+name: &host-ssh-path
: /var/lib/portage/home/.ssh

# FIXME grrrr the need to be able to set these computationally
# passed via the command line means that we have to descend into elisp
# or we have to have a oneshot self modifying configuration command
# which is also bad because it breaks version control

# ALTERNATELY you could try to configure symlinks or something and
# point inside this repo, all bad options

# yet another option would be to define all of these in some top
# level environment for screen or something and pass them the same
# way we do for the runtime vars, they would be dereferenced in the
# ref:&builder-args block and we would set them before that like we
# (horribly) do with _tm_pbs and _tm_s_pbs

# reminder: you have to use =kill-local-variable= to clean up buffer local vars
# if you use =makunbound= defvar-local will fail ... and even then there are issues
# so sometimes you just have to kill and reopen the buffer (sigh)
* Next
** TODO ebuilds changing behind the scenes
:PROPERTIES:
:CREATED:  [2022-03-21 Mon 20:50]
:END:
so it turns out that it is possible to change an ebuild, rebuild the package
and .. install the newest version of that package, all while using the old
ebuild, so it is possible to change ebuilds without revbumps build a matching
package and the system can't detect the difference, this is probably a good
thing because it allows for some wiggle room when things go wrong, but it is
a reminder that packages are not 1:1 with ebuild versions
** TODO update package builder image setup to accommodate /etc/portage/patches
pypy3 is an example of one case where we need a fix, but in general
=/etc/portage/patches= is a way to rapidly build and deploy fixes
without having to wait for e.g. a full pull request cycle to finish.
** DONE catch errors in profile early
** TODO dind or similar for top level ops
Docker is not homogeneous with regard to nesting containers since the
way that we use it is a bit outside the usual use case (and because
docker is a hack and true nesting reveals this by violating a whole
bunch of assumptions that are baked into the implementation).

As a result, a hack is required to be able to fake nesting. In this
case the simplest approach seems to be to make the ur-host's docker
process accessible to the top level ops container. Not truly
homogeneous, but better than nothing. This is done by mounting the
socket for the docker daemon when you run the top level build image.

Since this is a build process security considerations are identical
for the true host and the top level image. If we weren't running in
the top level image we would be running on the true host directly so
sandboxing is irrelevant.

An example approach would be to run something like the following.
#+begin_src bash
docker run -v /var/run/docker.sock:/var/run/docker.sock tgbugs/musl:docker
#+end_src

** DONE a better way
The primary issue here is that it really is not safe to compose after
merge because the power and flexibility of portage happen before
merge, and are quite state dependent after the fact. The key then is
to be able to create images that do compose well, and the only at
the very end materialize them by installing all the packages at once.

The problem is that you give up the utility of the docker layers, but
if we are installing binary packages that have been built on a
separate system then we know that we won't encounter build errors.

The final obstacle to full composability in this way is the issue of
incompatible use flags, but I think it is safe to say that it is not
really possible to solve that problem.

This consideration suggests that the layers of docker images, while
useful, are fundamentally at odds with composability when there are
files inside images that track state (e.g. =/var/lib/portage/world=).

** DONE condense use flags
At the moment we keep use flags with packages and try to keep them
mostly orthogonal to each other. However, at a certain point it is
going to be easier to maintain a single shared use flag image that
will be synchronized across all images. Granular control is nice from
a learning and minimal specification point of view, but from an
engineering an maintenance point of view it is vastly easier easier to
maintain a single shared use flag image that will be synchronized
across all images. Granular control is nice from a learning and
minimal specification point of view, but from an engineering an
maintenance point of view it is simpler to unify the individual image
environments into a single file.
** DONE create an image to build packages
Rebuilding images is wasteful when nothing has changed, and packages
and install properly to maintain the correct state of the image. While
=COPY --from= works, it mangles things like =/var/lib/portage/world=,
and if use flags were changed on a dependency by another source image
then unusual and unexpected errors could occur. This is another reason
to move to manage use flags one or two images, one image for cases
where X11 is not needed, and another where it is.

In fact, I'm fairly certain that having a shared use flag environment
is necessary for it to be possible to safely compose packages and
images. Composition across environments requires something like nix
where each package carries around its own environment. It might be
possible to do better than this by allowing composition in cases where
the environments are compatible, but that would still require
computation at composition time, you can't just layer images an expect
things to work.

alternately mount =/var/cache/binpkgs= and then run quickpkg or
something devious like that
** TODO separate user image
Should be able to =COPY --from=tgbugs/musl:user= across all images.
build the user image from a base that has next to nothing in it
add the user and group to the system and then copy that minimal
user stuff in, most of the time there isn't any fancy installation
that needed to be done, and we could just copy the user directory
when building from scratch
* docker-profile
** base
The right way to do this is to create two custom profiles on top of musl-hardened.

https://wiki.gentoo.org/wiki/Profile_(Portage)#custom

Modifications to use flags and other system settings and
configurations that are easier to keep in a single location.
# FIXME this may need to be versioned, or we just force rebuild on all
# the images from scratch which we often have to do anyway, though some
# packages may not be affect by profile changes
*** build
#+name: &docker-profile-build-base
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:base \
--file docker-profile/base/Dockerfile docker-profile/base
#+end_src

*** file
#+name: &profile-adds
#+begin_src dockerfile
# we don't put this in var/db/repos because repos is managed via tgbugs/repos:latest
ARG bp=docker-profile/base/

ADD ${bp}docker-profile                          var/db/docker-profile
ADD ${bp}docker-profile.conf                     etc/portage/repos.conf/docker-profile.conf
ADD ${bp}binrepos-multi.conf                     etc/portage/binrepos.conf/multi.conf
ADD ${bp}package.accept_keywords                 etc/portage/package.accept_keywords/profile
ADD ${bp}package.mask                            etc/portage/package.mask/profile
ADD ${bp}emacs.env                               etc/portage/env/app-editors/emacs
ADD ${bp}erlang.env                              etc/portage/env/dev-lang/erlang
ADD ${bp}no-distcc.env                           etc/portage/env/no-distcc
ADD ${bp}package.env                             etc/portage/package.env/profile
ADD ${bp}musl-find_library.patch                 etc/portage/patches/dev-lang/python:2.7/musl-find_library.patch
ADD ${bp}musl-include-sys-time.patch             etc/portage/patches/dev-python/pypy3-exe/musl-include-sys-time.patch
ADD ${bp}musl-fix-stdio-defs.patch               etc/portage/patches/dev-python/pypy3-exe/musl-fix-stdio-defs.patch
ADD ${bp}pypy3-json-str-subclass-safety.patch    etc/portage/patches/dev-python/pypy3/json-str-subclass-safety.patch
#+end_src

#+begin_src dockerfile :tangle ./docker-profile/base/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

<<&profile-adds>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

*** etc
**** repos.conf
#+begin_src conf :tangle ./docker-profile/base/docker-profile.conf
[docker-profile]
location = /var/db/docker-profile
#+end_src
**** binrepos.conf
#+begin_src conf :tangle ./docker-profile/base/binrepos-multi.conf
[tgbugs-multi]
priority = 100
sync-uri = http://local.binhost:8089/multi
#+end_src
**** package.accept_keywords
#+begin_src conf :tangle ./docker-profile/base/package.accept_keywords
dev-python/*::tgbugs-overlay
dev-scheme/racket::tgbugs-overlay
#+end_src
**** package.mask
#+begin_src conf :tangle ./docker-profile/base/package.mask
dev-scheme/racket::gentoo
#+end_src
**** env
***** no distcc
# TODO MAKEOPTS_LOCAL
# FIXME "${FEATURES} -distcc" vs "-distcc" behavior?
# I think they stack without variables with priority going global package runtime environment
#+begin_src conf :tangle ./docker-profile/base/no-distcc.env
FEATURES="-distcc"
#+end_src
***** app-editors/emacs
#+begin_src conf :tangle ./docker-profile/base/emacs.env
NATIVE_FULL_AOT=1
#+end_src
***** dev-lang/erlang
https://bugs.gentoo.org/857099
https://github.com/OpenRC/openrc/blob/master/service-script-guide.md#be-wary-of-need-net-dependencies
#+begin_src conf :tangle ./docker-profile/base/erlang.env
post_src_install() { sed -i '/need/d' "${D}"/etc/init.d/epmd; }
#+end_src
**** package.env
# dev-python/numpy no-distcc
# XXX manually setting FEATURES=-distcc worked, but it seems that stacking features in make.conf doesn't?
#+begin_src conf :tangle ./docker-profile/base/package.env
dev-python/pypy3 no-distcc
dev-util/cmake no-distcc
dev-util/colm no-distcc
#+end_src
*** profiles
#+begin_src conf :tangle ./docker-profile/base/docker-profile/metadata/layout.conf
masters = gentoo
profile-formats = portage-2
#+end_src

#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/repo_name
docker-profile
#+end_src

# NOTE that tgbugs/musl/x is listed here but not populated until later
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/profiles.desc
amd64 tgbugs               dev
amd64 tgbugs/x             dev
amd64 tgbugs/gnu           dev
amd64 tgbugs/gnu/x         dev
amd64 tgbugs/musl          dev
amd64 tgbugs/musl/x        dev
amd64 tgbugs/musl/static   dev
amd64 tgbugs/musl/static/x dev
#+end_src
**** packages
Useful to keep these out of file:/var/lib/portage/world so that individual
docker files can just =ADD= their world file and then =emerge @world=. It
also makes it much easier for the package builder to operate based on world files.
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/packages
*dev-vcs/git
*app-eselect/eselect-repository
#+end_src
**** make.defaults
# old, we use INSTALL_MASK for simplicity
#+begin_comment
See warning about https://wiki.gentoo.org/wiki/Localization/Guide#LINGUAS.
We are safe here because this base profile is shared between all our
systems and because we do not redistribute the binary packages.

We restrict =LINGUAS= here to reduce the size of the images that are
produced.  Larger images with localization enabled can be produced by
removing the restriction, but are not included by default. This
approach is likely better than using =INSTALL_MASK=.
#+end_comment

# USE="-doc"
# LINGUAS="en"
# for some reason empty video cards does not actually disable all the flags

# NOTE: the hardened profile sets USE=-cli and USE=-jit and some other stuff
# that changes behavior [[/usr/portage/profiles/features/hardened/make.defaults]]

Normally we don't set =USE== in make.conf, however there is no way to set
global use flags in a profile without doing so.
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/make.defaults
INSTALL_MASK="${INSTALL_MASK}
/usr/share/locale
-/usr/share/locale/en
-/usr/share/locale/en@boldquot
-/usr/share/locale/en@quot
-/usr/share/locale/en@shaw
-/usr/share/locale/en_US"

FEATURES="${FEATURES} binpkg-multi-instance"

EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --binpkg-respect-use=y"  # FIXME portageq shows bru opt twice ??

# icu is needed due to musl collation issues
# jemalloc can improve performance re issues with musl allocator
USE="${USE} icu jemalloc"

USE="${USE} -gstreamer"

VIDEO_CARDS="-*"

# ensure that packages are readable by other users via umask 022
# use unmodified config in case a config file is modified, configs
# should never wind up modified when using package builder images
# see https://bugs.gentoo.org/307455 for more
# FIXME XXX current issues include
# /etc/hosts -> sys-apps/baselayout
# /etc/rc.conf -> sys-apps/openrc
# /etc/sgml/catalog -> app-text/sgml-common
# which seem to have been modified by other merges
QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022"

ACCT_GROUP_BLAZEGRAPH_ID=834
ACCT_USER_BLAZEGRAPH_ID="${ACCT_GROUP_BLAZEGRAPH_ID}"

ACCT_GROUP_SCIGRAPH_ID=835
ACCT_USER_SCIGRAPH_ID="${ACCT_GROUP_SCIGRAPH_ID}"

ACCT_GROUP_SPARC_ID=836
ACCT_USER_SPARC_ID="${ACCT_GROUP_SPARC_ID}"

ACCT_GROUP_PROTCUR_ID=837
ACCT_USER_PROTCUR_ID="${ACCT_GROUP_PROTCUR_ID}"

ACCT_GROUP_SCIBOT_ID=838
ACCT_USER_SCIBOT_ID="${ACCT_GROUP_SCIBOT_ID}"

ACCT_GROUP_INTERLEX_ID=839
ACCT_USER_INTERLEX_ID="${ACCT_GROUP_INTERLEX_ID}"

ACCT_GROUP_NIFSTD_TOOLS_ID=840
ACCT_USER_NIFSTD_TOOLS_ID="${ACCT_GROUP_NIFSTD_TOOLS_ID}"

ACCT_GROUP_METABASE_ID=841
ACCT_USER_METABASE_ID="${ACCT_GROUP_METABASE_ID}"

EGIT_OVERRIDE_REPO_SCIGRAPH_SCIGRAPH=https://github.com/SciCrunch/SciGraph.git
EGIT_OVERRIDE_BRANCH_SCIGRAPH_SCIGRAPH=cypher-execute-fix

# temporary commit override until the converter is fixed
EGIT_OVERRIDE_COMMIT_OPEN_PHYSIOLOGY_OPEN_PHYSIOLOGY_VIEWER=2f6d17c2ccc052eecc17e57b469ade42be8cf216
#+end_src

# FIXME the ACCT_ and EGIT_OVERRIDE_ should probably be in env, but we rebuild
# this profile so frequently I think putting it in make.defaults is probably ok

**** mask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.mask
# insurance
dev-lang/rust
dev-lang/rust-bin
>=dev-python/cryptography-3.4.8
>=dev-python/pyopenssl-21

# gtknor
>=gnome-base/librsvg-2.41
>x11-themes/adwaita-icon-theme-3.33

# dynapad
>=media-gfx/imagemagick-7
#+end_src
**** unmask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.unmask
# gtknor
<gnome-base/librsvg-2.41
dev-python/dicttoxml
#+end_src
**** accept_keywords
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.accept_keywords
dev-python/pipenv ~amd64
app-misc/yq ~amd64

# harfbuzz 3.1.2 needs freetype-2.11.1 otherwise build fails
=media-libs/freetype-2.11.1 ~amd64

# tgbugs-overlay
dev-db/blazegraph-bin ~amd64
dev-db/pguri **
dev-java/robot-bin ~amd64
dev-java/scigraph-bin ~amd64
dev-node/apinat-converter **
#dev-scheme/racket ~amd64  # profile can't restrict by repo :(

# tgbugs-overlay python
dev-python/interlex **
dev-python/sparcur **

# sparcur
app-text/xlsx2csv ~amd64
dev-python/semver ~amd64

# gtknor
<gnome-base/librsvg-2.41 **

# emacs
app-emacs/vterm ~amd64

# sbcl
dev-lisp/asdf ~amd64
dev-lisp/uiop ~amd64
dev-lisp/sbcl ~amd64

# pypy3
dev-python/pypy3-exe ~amd64
dev-python/pypy3 ~amd64
#+end_src
# probably have to put dev-python/*::tgbugs-overlay in /etc/portage/package.accept_keywords/profile
# dev-python/pyontutils ~amd64
# XXX if we introduce pypy3 this is going to be a mess

# interesting issue with dev-python/interlex ** nominally being completely
# irrelevant and orthognal to the rest of the contstraints on other images
# that will never install it, it technically triggers a rebuild of everything
# because we make the profile a dependency, we mitigate this by using binpkgs
# but really we should be able to put things like this in the package builder
# image and snapshot and then only in the docker files that will actually
# install that package itself ... hrm ... unfortunately that is WAY harder
# for someone to understand and track than it is to stick it in here and
# rebuild everything ... sigh, eventually we will implement this optimization
**** package.use
# TODO consider dev-db/sqlite secure-delete
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.use
# setpriv command
sys-apps/util-linux caps

# font rendering
media-libs/freetype -cleartype-hinting -cleartype_hinting

# reduce deps
dev-libs/uriparser -doc

# needed to ensure that -egl doesn't introduce conflicts
x11-base/xorg-server minimal

app-editors/emacs dynamic-loading gmp json threads

# gdb don't pull in the world
sys-devel/gdb -nls -python

# pyzmq
net-libs/zeromq drafts

dev-scheme/racket cs bc cgc jit

# graphviz
media-libs/gd truetype fontconfig

# pypy3
dev-python/pypy3-exe jit
dev-python/pypy3 sqlite

# keep ipykernel deps minimal for emacs-jupyter
dev-python/ipython -smp

# tgbugs-overlay python
dev-python/interlex alt database
dev-python/orthauth yaml
dev-python/pint babel uncertainties
dev-python/sparcur cron  # XXX FIXME not all images want to pull in the cron deps, or the dashboard deps
#+end_src

**** use.mask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/use.mask
# reduce deps
perl
gtk
cups
postscript

# reduce xorg deps
llvm
egl
gles2
gallium
dbus
vala
introspection
elogind

# allow pypy3 as a python target
-python_targets_pypy3
#+end_src
**** x/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/x/parent
..
#+end_src
**** nox/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/nox/parent
..
#+end_src
**** gnu/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/parent
gentoo:default/linux/amd64/17.1/hardened
..
#+end_src
**** gnu/x/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/x/parent
..
../../x
#+end_src
**** gnu/nox/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/nox/parent
..
../../nox
#+end_src
**** musl/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/parent
gentoo:default/linux/amd64/17.0/musl/hardened
..
#+end_src
**** musl/x/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/x/parent
..
../../x
#+end_src
**** musl/nox/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/nox/parent
..
../../nox
#+end_src
**** musl/static
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/parent
..
#+end_src
**** musl/static/x
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/x/parent
..
../../../x
#+end_src
**** musl/static/nox
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/nox/parent
..
../../../nox
#+end_src
** static
*** profiles
***** make.defaults
We only set =static-libs= not =static= because =static= statically
links the executable which we rarely want, in which case a positive
static use flag should be added below, rather than turning off nearly
every instance of =static= that we encounter.
#+begin_src conf :tangle ./docker-profile/static/docker-profile/profiles/tgbugs/musl/static/make.defaults
USE="${USE} static-libs"
#+end_src
***** package.use :ARCHIVE:
#+begin_src conf :tangle ./docker-profile/static/docker-profile/profiles/tgbugs/musl/static/package.use :tangle no
# don't build openssh with static libs because it conflicts with the
# pie use flag for hardened which cannot be unset
net-misc/openssh -static

# bzip2 is completely broken if compiled with either of these use flags ???
# that is, it will compile but will leave the system unable to compress anything
app-arch/bzip2 -static

# trying to build with static causes a configure error due to container projections
# building with security=insecure supposedly can work around this
# cross compile check process_vm_readv # ccc process_vm_readv
# FIXME, further reading seems to suggest that we don't actually want static? just
# static-libs? so going to try that
app-arch/gzip -static
sys-apps/debianutils -static
sys-apps/coreutils -static
sys-devel/patch -static
sys-apps/findutils -static
sys-apps/sed -static
sys-devel/make -static
net-misc/wget -static
sys-apps/diffutils -static
sys-apps/grep -static
app-editors/nano -static
sys-devel/flex -static
sys-devel/bison -static
#+end_src

#+begin_src bash
echo \
sys-devel/bison \
-static >> /etc/portage/package.use/sigh && \
emerge -uDN @world
#+end_src
** x
*** profiles
**** parent
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/parent
..
#+end_src
**** packages
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/packages
*media-fonts/dejavu
*media-libs/fontconfig
*media-libs/freetype
#+end_src
**** make.defaults
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/x/make.defaults
USE="${USE} X"
VIDEO_CARDS="-*"
#+end_src
**** package.use
# we might consider including svg and libxml2 because they are already pulled in by racket and some other components
# app-editors/emacs libxml2 svg
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.use
# ,*/* X # FIXME it seems that wildcards are not allowed in here so for now has to be done later

media-libs/freetype harfbuzz

# the mesa ebuilds in the main tree are missing the fact that
# gbm expects egl to be enabled, if it is not build errors
media-libs/mesa -gbm

app-editors/emacs gui Xaw3d xft # XXX note that latest reccomendations are to use harfbuzz + cairo for text shaping (or something like that)
app-emacs/emacs-common gui

# avoid extra deps
dev-util/cmake -ncurses

# scigraph
x11-base/xorg-server xvfb
#+end_src

**** mask
# Looks like the mesa issue has been fixed.
# The media-libs/mesa-21.1 set fails to build even with all the use flags set correctly.
# Same issue with media-libs/mesa-21.1 https://bugs.gentoo.org/828491. Currently 21.2.6
# is the only one that will compile correctly.
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.mask
#+end_src
**** accept_keywords
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.accept_keywords
#+end_src
** nox
Explicit nox profile.
*** build
#+name: &musl-build-profile-nox
#+begin_src screen
docker build \
--tag tgbugs/musl:profile-nox \
--file docker-profile/nox/Dockerfile docker-profile/nox
#+end_src

*** file
#+begin_src dockerfile :tangle ./docker-profile/nox/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD docker-profile var/db/docker-profile

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

*** profiles
**** parent
#+begin_src conf :tangle ./docker-profile/nox/docker-profile/profiles/tgbugs/nox/parent
..
#+end_src

**** package.use
#+begin_src conf :tangle ./docker-profile/nox/docker-profile/profiles/tgbugs/nox/package.use
dev-java/icedtea headless-awt
#+end_src

* repos
Overlays can take up quite a bit of space so it is better to mount
them the same way we mount the gentoo repo during build so that we can
keep the images a bit slimmer. We can publish the build images
independently, and it is also worth noting that from a reproducibility
perspective the exact ebuilds are stored in file:/var/db/pkg/.

*** debug
#+begin_src bash
docker run \
--entrypoint /bin/sh \
-it tgbugs/repos:latest
#+end_src
*** build
# FIXME the --no-cache option here means that setting --repos forces a
# rebuild of _everything_ downstream even if repos didn't change
#+name: &repos-build-repos
#+begin_src screen
docker build \
--no-cache \
--build-arg SYNC_GENTOO=$SYNC_GENTOO \
--tag tgbugs/repos:latest \
--file repos/Dockerfile repos
#+end_src
*** file
#+begin_src dockerfile :tangle ./repos/Dockerfile
FROM tgbugs/musl:eselect-repo as builder

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
   emaint sync --repo musl \
&& emaint sync --repo lisp \
&& emaint sync --repo tgbugs-overlay

# manual sync in cases where there is a showstopper blocking progress
ARG SYNC_GENTOO

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
   test -z $SYNC_GENTOO || emaint sync --repo gentoo

# emergency backup
ARG BASE="https://github.com/tgbugs/musl/releases/download/icedtea-bin-3.18.0-alpine-helper-0/"
ARG TMCH=34581ad0f14b5898abfb8d0a7ad89d560270a2e5
RUN \
mkdir -p /usr/local/portage/dev-java/icedtea-bin \
&& pushd /usr/local/portage/dev-java/icedtea-bin \
&& ln -s /var/db/repos/musl/dev-java/icedtea-bin/files \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/icedtea-bin-3.18.0.ebuild" \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/Manifest"

FROM busybox:latest

WORKDIR /
COPY --from=builder /var/db/repos /var/db/repos
COPY --from=gentoo/portage:latest /var/db/repos/gentoo /var/db/repos/gentoo
COPY --from=builder /usr/local/portage /usr/local/portage
CMD /bin/true
VOLUME /var/db/repos
#+end_src
* musl
Pushes to https://hub.docker.com/r/tgbugs/musl. \\
Derived from [[https://hub.docker.com/r/gentoo/stage3/tags?page=1&ordering=last_updated&name=musl-hardened][gentoo/stage3:amd64-musl-hardened]] \\
Further derived from https://ftp-osl.osuosl.org/pub/gentoo/releases/amd64/autobuilds/current-stage3-amd64-musl-hardened/ \\
and from https://gitweb.gentoo.org/proj/releng.git/tree/releases/specs/amd64/musl/stage3-hardened.spec
** profile
TODO use =static-libs=?
*** build
#+name: &musl-build-profile
#+begin_src screen
docker build \
--tag tgbugs/musl:profile \
--file musl/profile/Dockerfile .
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/profile/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

<<&profile-adds>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src
** profile-x
*** build
#+name: &musl-build-profile-x
#+begin_src screen
docker build \
--tag tgbugs/musl:profile-x \
--file musl/profile-x/Dockerfile .
#+end_src

*** file
We do not need to include any of the files from the base profile here
because they are already in musl:updated which this profile should be
combined on top of.
#+begin_src dockerfile :tangle ./musl/profile-x/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD docker-profile/x/docker-profile var/db/docker-profile
ADD docker-profile/base/binrepos-multi.conf etc/portage/binrepos.conf/multi.conf

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src
** user
#+name: &musl-build-user
#+begin_src screen
docker build \
--tag tgbugs/musl:user \
--file musl/user/Dockerfile musl/user
#+end_src

# FIXME this is sufficient to create the default set of files and directories for the user
# however it is not able to deal with the fact that groupadd and useradd still must be run
# on the host system, which leads me to think that the only composability we are going to
# get here is via noweb :/ the primary issue is /etc/groups and other similar things

#+name: &run-user-noskel
#+begin_src bash :eval never
groupadd -g ${UID} ${USER_NAME} \
&& useradd -M -u ${UID} -g ${UID} ${USER_NAME}
#+end_src


Block to be nowebbed for the user creation portion of the images.
Should be +followed+ preceded? by a =COPY --from= that was built by
layering on top of the image we build below.

#+name: &musl-file-user-base
#+begin_src dockerfile
ARG UID=1000
ARG USER_NAME=user

RUN \
<<&run-user-noskel>>

USER $USER_NAME

WORKDIR /home/${USER_NAME}

ENV PATH="/home/${USER_NAME}/.local/bin:${PATH}"
#+end_src

#+name: &musl-user-skel-common
#+begin_src dockerfile
ARG UID=1000
ARG USER_NAME=user

RUN \
groupadd -g ${UID} ${USER_NAME} \
&& useradd -m -k /etc/skel -u ${UID} -g ${UID} -d /build/home/${USER_NAME} ${USER_NAME}

RUN \
mkdir -p home/${USER_NAME}/.local/bin

RUN \
chown -R ${UID}:${UID} home/${USER_NAME}
#+end_src

#+begin_src dockerfile :tangle ./musl/user/Dockerfile
FROM gentoo/stage3:amd64-musl-hardened as builder

WORKDIR /build

<<&musl-user-skel-common>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

** portage-maven
Hack to make it possible to install from maven using portage.
*** build
#+name: &musl-build-portage-maven
#+begin_src screen
docker build \
--tag tgbugs/musl:portage-maven \
--file musl/portage-maven/Dockerfile musl/portage-maven
#+end_src

*** file
The UID for portage is static so it is ok to hard code it [fn::
https://api.gentoo.org/uid-gid.txt
https://wiki.gentoo.org/wiki/Project:Quality_Assurance/UID_GID_Assignment].

#+name: &portage-maven-settings
#+begin_src xml :tangle ./musl/portage-maven/settings.xml :mkdirp yes
<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd">
  <localRepository>/var/tmp/portage/.m2/repository</localRepository>
</settings>
#+end_src

#+name: &run-portage-maven-1
#+begin_src bash :eval never :noweb yes
# mkdir -p var/lib/portage/home/.m2 \
chown -R 250:250 var/lib/portage \
&& mkdir -p var/tmp/portage/.m2/repository \
&& chown -R 250:250 var/tmp/portage
#+end_src

#+begin_src dockerfile :tangle ./musl/portage-maven/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD settings.xml var/lib/portage/home/.m2/settings.xml

RUN \
<<&run-portage-maven-1>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

** eselect-repo
This is where everything starts. The profile has to be set here etc.
*** run
#+begin_src screen
docker run \
--volumes-from local-portage-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-it tgbugs/musl:eselect-repo
#+end_src

# debug
#+begin_src screen :exports none
docker run -it tgbugs/musl:eselect-repo
#+end_src

# debug tgbugs/repos:latest
#+begin_src screen
docker run \
--volumes-from local-repos-snap \
-it tgbugs/musl:eselect-repo
#+end_src

*** build
#+name: &musl-build-eselect-repo
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:eselect-repo \
--file musl/eselect-repo/Dockerfile musl/eselect-repo
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/eselect-repo/Dockerfile
FROM gentoo/stage3:amd64-musl-hardened

<<&gentoo-file-eselect-repo-common-1>>

COPY --from=tgbugs/musl:profile / /

<<&gentoo-file-eselect-repo-common-2>>

RUN \
eselect profile set docker-profile:tgbugs/musl

<<&gentoo-file-eselect-repo-common-3>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
eselect repository enable musl
#+end_src

#+name: &gentoo-file-eselect-repo-common-1
#+begin_src dockerfile
ARG ARCHIVE
#+end_src

#+name: &gentoo-file-eselect-repo-common-2
#+begin_src dockerfile
RUN \
# FIXME tgbugs-overlay symlinks
ln -s /var/db/repos/gentoo /usr/portage

RUN \
eselect news read all \
&& eselect news purge

# XXX these are retained to avoid crossdev and other issues where
# portage needs these to be folders and are expected to error if
# the profile in question creates a ./profile file in these folders
RUN \
   mkdir /etc/portage/package.accept_keywords > /dev/null 2>&1 \
;  mkdir /etc/portage/package.env             > /dev/null 2>&1 \
;  mkdir /etc/portage/package.mask            > /dev/null 2>&1 \
;  mkdir /etc/portage/package.unmask          > /dev/null 2>&1 \
;  mkdir /etc/portage/package.use             > /dev/null 2>&1 \
;  mkdir /etc/portage/repos.conf              > /dev/null 2>&1 \
|| true
#+end_src

#+name: &gentoo-file-eselect-repo-common-3
#+begin_src dockerfile
# FIXME MAKEOPTS_LOCAL
RUN \
echo "MAKEOPTS=\"-j$(nproc)\"" >> /etc/portage/make.conf
# XXX setting PORTAGE_BINHOSTS has to come later? maybe as an envar?

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge --info 2>&1 | { grep Invalid\ atom && exit 1; exit 0; }

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q \
   --getbinpkg \
   dev-vcs/git \
   app-eselect/eselect-repository \
<<&archive-or-rm>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
eselect repository add tgbugs-overlay git https://github.com/tgbugs/tgbugs-overlay.git \
&& eselect repository enable lisp
#+end_src
# TODO should we be adding the mount points here as well or is that not necessary?

** updated
*** file
Produce an up-to-date base image for =amd64-hardened-musl= from the
latest stage3 image including the
[[https://github.com/gentoo/musl][musl overlay]] as noted on the
[[https://wiki.gentoo.org/wiki/Project:Hardened_musl#Working_with_musl][wiki]].

At the moment the docker images are generated far more frequently than
the underlying stage3 tarballs are updated, so there are two docker
files, one for building the first time and another for running routine
emerge updates until a new stage3 is released.

Alternately, one way to avoid rebuilds is to build packages and store
them across rebuilds. This will take more work, but ultimately might
be a bit more reproducible since we would avoid the issues with having
an image building =FROM= a prior version of itself.

#+name: &musl/updated
#+begin_src dockerfile :tangle ./musl/updated/Dockerfile
FROM tgbugs/musl:eselect-repo

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN @system @world \
   --getbinpkg \
   --keep-going \
   --exclude sys-process/procps \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

# fail if emerge fails but for buildkit ensure that we do it in such a
# way that we can truncate further steps and create a debug image
RUN \
test ! -e /emerge-fail

RUN \
eselect gcc set $(eselect gcc list | tail -n 1 | awk '{ print $2 }')
#+end_src

*** build
#+name: &musl-build-updated
#+begin_src screen
docker build \
--tag tgbugs/musl:updated \
--network host \
--add-host local.binhost:127.0.0.1 \
--file musl/updated/Dockerfile musl/updated
#+end_src

*** rebuild
#+begin_src bash
docker build \
--tag tgbugs/musl:updated-remerge \
--file musl/updated/remerge.Dockerfile musl/updated

# check that everything works as expected (and that there were changes at all)
docker run -it tgbugs/musl:updated-remerge

# rename the image
docker image tag tgbugs/musl:updated-remerge tgbugs/musl:updated
#+end_src

*** run
#+name: &musl-run-updated
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:updated
#+end_src
** updated-user
An example of how to compose user images to minimize size.
*** run
#+begin_src bash
docker run -it tgbugs/musl:updated-user
#+end_src

*** build
#+name: &musl-build-updated-user
#+begin_src bash
docker build \
--tag tgbugs/musl:updated-user \
--build-arg UID=${UID} \
--file musl/updated-user/Dockerfile musl/updated-user
#+end_src

*** file
#+begin_src dockerfile yes :tangle ./musl/updated-user/Dockerfile
FROM tgbugs/musl:updated

# change this line to copy from whatever user image you need
COPY --from=tgbugs/musl:user / /

<<&musl-file-user-base>>
#+end_src

** pypy3
*** run
#+name: &musl-run-pypy3
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:pypy3
#+end_src
*** build
#+name: &musl-build-pypy3
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:pypy3 \
--file musl/pypy3/Dockerfile musl/pypy3
#+end_src
*** file
#+name: &python-targets-common
#+begin_src dockerfile
ARG USE_PYTHON_TARGETS  # use if there are issues with mismatched python targets
# can't use PYTHON_TARGETS directly because ARG PYTHON_TARGETS is the same
# as export PYTHON_TARGETS= which means that portageq results will be affected

# we defer changing python targets until after eselect-repo to avoid
# issues bootstrapping pypy3
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
USE_PYTHON_TARGETS=${USE_PYTHON_TARGETS:-"$(portageq envvar PYTHON_TARGETS) pypy3"} \
&& [[ -z ${USE_PYTHON_TARGETS} ]] || \
   echo "*/* PYTHON_TARGETS: -* ${USE_PYTHON_TARGETS}" >> /etc/portage/package.use/00-base
#+end_src

#+begin_src dockerfile :tangle ./musl/pypy3/Dockerfile
FROM tgbugs/musl:updated
# FIXME python targets to include pypy3 needs to be in its own derived environment
# starting from package builder or something like that
<<&python-targets-common>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN @system @world eselect-python \
   --getbinpkg \
   --keep-going \
   --exclude sys-process/procps \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

# fail if emerge fails but for buildkit ensure that we do it in such a
# way that we can truncate further steps and create a debug image
RUN \
test ! -e /emerge-fail
#+end_src

#+begin_comment
Trying to bootstrap pypy3 at this phase of the build when you don't have
a pypy3 free environment yet can be a massive pain to debug. The solution
is to set =USE_PYTHYON_TARGETS= explicitly to override the default pypy3,
bootstrap everything until you can run =builder-debug= and then build the
binary pypy3 in an environment where you can debug.
#+end_comment

#+begin_comment
FIXME I think that we really have to make the pypy3 environment its
own branch because bootstrapping it is beyond terrifying when you have
to use the same images and the builder can deposit pyp3, otherwise you
wind up building pypy3 in an environment where binpkgs are not being
generated until the whole image is repackaged (!!!!)  SIGH

so here is the issue that we run into, we have multiple different
profiles that we construct for each base image and we keep those
profiles separate so that we don't impact all images when only a
derived layer changes, basically we want to have a single profile, but
we don't want docker to stupidly rebuild everything just becuase some
file that is irrelevant to the current image lineage changed,
unfortunately we need our base profile in order to build a pypy3
environment correctly so the base profile has to be added directly
after updated in order for this to work, maybe we can get it to go

XXX ignore the rant above, eselect-profile already sets our base
profile!  so we don't have to worry about any of this and can just add
an interposting layer
#+end_comment

*** patches
If you load up =builder-debug= you can emerge pypy3 by adding patches
manually, the right thing to do is to update the musl overlay build,
but for now, if you can manage to manually build in the builder you
will wind up with a binpkg that can be reused.

A number of relevant issues
- https://bugs.python.org/issue21622
- https://github.com/python/cpython/pull/18380
- https://bugs.python.org/issue43112
- https://github.com/gentoo/musl/issues/451#issuecomment-1017102775

**** cpython 2.7 patch
Sourced from https://git.alpinelinux.org/aports/plain/main/python3/musl-find_library.patch
If in =builder-debug= rebuild the python:2.7 binpkg =emerge -g n -k n python:2.7=.
#+begin_src diff :tangle ./docker-profile/base/musl-find_library.patch
diff -ru Python-2.7.12.orig/Lib/ctypes/util.py Python-2.7.12/Lib/ctypes/util.py
--- Python-2.7.12.orig/Lib/ctypes/util.py	2016-06-26 00:49:30.000000000 +0300
+++ Python-2.7.12/Lib/ctypes/util.py	2016-11-03 16:05:46.954665040 +0200
@@ -204,6 +204,41 @@
         def find_library(name, is64 = False):
             return _get_soname(_findLib_crle(name, is64) or _findLib_gcc(name))
 
+    elif True:
+
+        # Patched for Alpine Linux / musl - search manually system paths
+        def _is_elf(filepath):
+            try:
+                with open(filepath, 'rb') as fh:
+                    return fh.read(4) == b'\x7fELF'
+            except:
+                return False
+
+        def find_library(name):
+            from glob import glob
+            # absolute name?
+            if os.path.isabs(name):
+                return name
+            # special case for libm, libcrypt and libpthread and musl
+            if name in ['m', 'crypt', 'pthread']:
+                name = 'c'
+            elif name in ['libm.so', 'libcrypt.so', 'libpthread.so']:
+                name = 'libc.so'
+            # search in standard locations (musl order)
+            paths = ['/lib', '/usr/local/lib', '/usr/lib']
+            if 'LD_LIBRARY_PATH' in os.environ:
+                paths = os.environ['LD_LIBRARY_PATH'].split(':') + paths
+            for d in paths:
+                f = os.path.join(d, name)
+                if _is_elf(f):
+                    return os.path.basename(f)
+
+                prefix = os.path.join(d, 'lib'+name)
+                for suffix in ['.so', '.so.*']:
+                    for f in glob('{0}{1}'.format(prefix, suffix)):
+                        if _is_elf(f):
+                            return os.path.basename(f)
+
     else:
 
         def _findSoname_ldconfig(name):
#+end_src

**** pypy3-exe sys time patch
The patch is a version of the below patch that will apply correctly to later versions of pypy3.
<https://raw.githubusercontent.com/gentoo/musl/master/dev-python/
pypy3-exe/files/pypy3-exe-7.3.0-musl-compat-include-sys-time.patch>

#+begin_src diff :tangle ./docker-profile/base/musl-include-sys-time.patch :mkdirp yes
diff -r 9ef55f6fc369 pypy/module/cpyext/include/pytime.h
--- a/pypy/module/cpyext/include/pytime.h
+++ b/pypy/module/cpyext/include/pytime.h
@@ -2,6 +2,10 @@
 #ifndef Py_PYTIME_H
 #define Py_PYTIME_H
 
+#ifndef MS_WINDOWS
+#include <sys/time.h>
+#endif
+
 #include <pyconfig.h> /* include for defines */
 #include "object.h"
 
#+end_src

**** pypy3-exe stdio patch
The patch is a version of the below patch that will apply correctly to later versions of pypy3.
<https://raw.githubusercontent.com/gentoo/musl/master/dev-python/
pypy3-exe/files/pypy3-exe-7.3.0-musl-compat-fix-stdio-defs.patch>

#+begin_src diff :tangle ./docker-profile/base/musl-fix-stdio-defs.patch :mkdirp yes
--- a/rpython/rlib/rfile.py
+++ b/rpython/rlib/rfile.py
@@ -123,11 +123,11 @@
 c_ferror = llexternal('ferror', [FILEP], rffi.INT)
 c_clearerr = llexternal('clearerr', [FILEP], lltype.Void)
 
-c_stdin = rffi.CExternVariable(FILEP, 'stdin', eci, c_type='FILE*',
+c_stdin = rffi.CExternVariable(FILEP, 'stdin', eci, c_type='FILE* const',
                                getter_only=True, declare_as_extern=False)
-c_stdout = rffi.CExternVariable(FILEP, 'stdout', eci, c_type='FILE*',
+c_stdout = rffi.CExternVariable(FILEP, 'stdout', eci, c_type='FILE* const',
                                 getter_only=True, declare_as_extern=False)
-c_stderr = rffi.CExternVariable(FILEP, 'stderr', eci, c_type='FILE*',
+c_stderr = rffi.CExternVariable(FILEP, 'stderr', eci, c_type='FILE* const',
                                 getter_only=True, declare_as_extern=False)
 
 
#+end_src

**** pypy3 json string patch
Not all instance of string have =__radd__= methods that make uncasted
string concatenation safe. This results in divergent behavior compared
to the cypthon json implementation.
#+begin_src diff :tangle ./docker-profile/base/pypy3-json-str-subclass-safety.patch :mkdirp yes
diff -r 05fbe3aa5b08 lib-python/3/json/encoder.py
--- a/lib-python/3/json/encoder.py	Tue Mar 29 08:15:20 2022 +0300
+++ b/lib-python/3/json/encoder.py	Fri Apr 29 15:19:41 2022 -0700
@@ -371,8 +371,10 @@
                 first = False
             else:
                 buf = separator
-            if isinstance(value, str):
+            if type(value) == str:
                 yield buf + '"' + self.__encoder(value) + '"'
+            elif isinstance(value, str):
+                yield buf + '"' + str(self.__encoder(value)) + '"'
             elif value is None:
                 yield buf + 'null'
             elif value is True:
@@ -448,8 +450,10 @@
                 yield item_separator
             yield '"' + self.__encoder(key) + '"'
             yield self.key_separator
-            if isinstance(value, str):
+            if type(value) == str:
                 yield '"' + self.__encoder(value) + '"'
+            elif isinstance(value, str):
+                yield '"' + str(self.__encoder(value)) + '"'
             elif value is None:
                 yield 'null'
             elif value is True:
#+end_src

** xorg
# FIXME why is this not being built from binpkg only? is it for layer
# efficiency?
*** run
#+name: &musl-run-xorg
#+begin_src screen
# -v ~/files/binpkgs/musl:/var/cache/binpkgs \
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:xorg
#+end_src
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:xorg
#+end_src
*** build
#+name: &musl-build-xorg
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:xorg \
--file musl/xorg/Dockerfile musl/xorg
#+end_src

*** file
The really good news here is that portage ignores packages that were
built with mismatched use flags, so at the end of the day what we will
wind up with is a case where only packages with mismatched flags will
be built and deposited into musl-x. The less good news is that this is
not fully implemented yet as noted in <https://wiki.gentoo.org/wiki/
Binary_package_guide#Pulling_packages_from_a_binary_package_host>.

#+begin_src dockerfile :tangle ./musl/xorg/Dockerfile
ARG PROFILE_IMAGE=tgbugs/musl:profile-x
ARG START_IMAGE=tgbugs/musl:pypy3

FROM ${PROFILE_IMAGE} as profile_image

FROM ${START_IMAGE}

COPY --from=profile_image / /

ARG PROFILE=docker-profile:tgbugs/musl/x

RUN \
eselect profile set $PROFILE

# FIXME I think we have to update binhosts here

# FIXME this rebuild is bad because it results in duplication of
# rebuilt packages between layers, probably need updated-x
# XXX install freetype without harfbuzz first to avoid the circular dependency (sigh)
# also have to install harfbuzz -freetype as well https://bugs.gentoo.org/830966#c5
# XXX NOTE when harfbuzz and freetype are installed from binpkgs sometimes fontconfig
# will scream about missing libs, this is because the good harfbuzz is installed after
# fontconfig, confusing and scary, but apparently not fatal
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -1q \
   --getbinpkgonly \
   media-libs/freetype \
   media-libs/harfbuzz \
# FIXME these do not get repackaged correctly
|| USE="-harfbuzz -truetype" emerge -j4 -1q \
   --getbinpkg \
   media-libs/freetype \
   media-libs/harfbuzz \
# remind me again why were we using -j1 here? old gcc issues?
&& emerge -j4 -q -uDN @world \
   --getbinpkg \
   --exclude sys-process/procps \
   --keep-going \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

RUN \
test ! -e /emerge-fail

RUN \
eselect fontconfig disable 10-hinting-slight.conf \
&& eselect fontconfig enable \
   10-no-sub-pixel.conf \
   57-dejavu-sans.conf \
   57-dejavu-sans-mono.conf
#+end_src

# FIXME 10-hinting-slight.conf no longer exists now ???

The issues with freetype hinting are partially dealt with in the
profile because so many packages pull in freetype, we have to deal
with the issue globally. We deal with some lingering issues here.

Only enabling dejavu sans and disabling any and all hinting matters.
There isn't a way to disable antialiasing using the gentoo fontconfig
and even if you do the disabled hinting engine has different and ugly
behavior compared to =-cleartype-hinting= so not sure what is going on
for even further insanity if you enable =10-hinting-none.conf= OR
=10-unhinted.conf= *YOU WILL GET HINTING !?!?!??! WAT!?* or at least
maybe AA is enabled which does not maybe ANY sense. Probably there is
some logic which is that in order to disable some feature there is
some default that is enabled so there winds up being a difference
between there being no reference to a feature and a reference to it to
explicitly disable it. Sigh.

** package-builder
*** populate 0
Yes it is kind of annoying to fully split the packages here when many of them don't actually
change, but I don't have an easy way to detect when it is safe to symlink a nox build into
the X build, though I think we can create a processes that would check the packages and to
see whether they have identical metadata and then remove one and symlink the other ....


A brief note on various =bindist= warnings that may appear during this step.

For =openssh= and =openssl=, the issue is related to various patents on ECC and RC5.
As far as I can tell from https://en.wikipedia.org/wiki/ECC_patents and the reference
in https://en.wikipedia.org/wiki/RC5, these patents have all expired, so redistribution
of packages compiled with =-bindist= is not an issue.

For =freetype= it seems that most of the patents https://freetype.org/patents.html
have expired as well. The latest ebuild in the tree has removed bindist entirely.

# it is safe to use --include-config here becauseit is done before any modifications are made
# FIXME TODO need a way to ignore existing exact matches unless we override
#+name: &musl-run-xorg-quickpkg
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v "$(pwd)"/bin/quickpkg-new:/tmp/quickpkg-new \
--rm \
tgbugs/musl:xorg \
/bin/sh -c 'quickpkg $(/tmp/quickpkg-new)'
#+end_src

**** quickpkg dedupe
This more or less works to avoid duplicate packages in a binhost multi
instance setup.
#+header: :shebang "#!/usr/bin/env python" :tangle-mode (or #o0755)
#+begin_src jupyter-python :session pys :tangle ./bin/quickpkg-new :mkdirp yes
import portage
from portage.versions import _pkg_str

def atoms_to_package():
    eroot = portage.settings['EROOT']
    trees = portage.db[eroot]
    bintree = trees['bintree']
    vartree = trees['vartree']
    vardb = vartree.dbapi

    installed = vartree.dbapi.cpv_all()
    packaged, not_packaged, misses = [], [], {}
    for i in installed:
        bt, bi, use = vardb.aux_get(i, ['BUILD_TIME', 'BUILD_ID', 'USE'])
        bt = int(bt) if bt else -1
        bi = int(bi) if bi else -1
        # yes build id has issues for some reason that I don't entirely understand
        matches = [a for a in bintree.dbapi.match(i) if
                   (a.build_time == bt and
                    #a.build_id == bi and
                    a._metadata['USE'] == use)]
        if matches:
            packaged.append(i)
        else:
            misses[i] = [a for a in bintree.dbapi.match(i) if not
                         (a.build_time == bt and
                          #a.build_id == bi and
                          a._metadata['USE'] == use)]
            not_packaged.append(i)
            #[[l.build_id for l in [k] + v] for k, v in misses.items()]
            #[[l.build_time for l in [k] + v] for k, v in misses.items()]
            #[[l._metadata['USE'] if hasattr(l, '_metadata') else None
              #for l in [k] + v] for k, v in misses.items()]

    return sorted([f'={a}' for a in not_packaged])

if __name__ == '__main__':
    atp = atoms_to_package()
    if atp:
        print(*atoms_to_package())
    else:
        print('-h')  # keep quickpkg happy since it doesn't like no args
#+end_src

*** run
#+begin_src bash
function build_package () {
echo docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
--rm \
tgbugs/musl:package-builder \
$@
}
#+end_src


#+begin_src bash
build_package sh -c "USE=-harfbuzz emerge -1q freetype"
# and here we see why I keep harfbuzz out of the nox profile
build_package sh -c "emerge -1q freetype"
#+end_src

# TODO it is almost certainly worth keeping these containers around
# and stashing them because they can be used to build more packages
# without having to do a full reinstall, which still takes awhile

# TODO figure out how to properly archive distfiles and binpkgs

# FIXME there is a nasty issue here with composability for use flag
# changes in the profile, in all likelihood we would be better off
# maintaining a stack layers on the builder to update the use flags
# independent of the profile until we we know that we have to do a
# full rebuild, simply because rebuilding build images from scratch
# every time is still slow and adding new packages will almost
# inevitably reveal issues that require such use changes many should
# go in the profile because we know that we are always going to need
# those in the future, it should be fairly straight forward to create
# a /var/db/docker-profile -> /etc/portage translator for the builder

I suggest adding all the =_path_= variables below (and the repo name)
to your shell rc file if you use any of the docker run commands during
development so that you can do so in a new shell. These values are
usually stable per system.
#+name: &builder-vars
#+begin_src bash :noweb yes
export \
_path_binpkgs_root=${_path_root_binpkgs:-<<&host-binpkgs-root-path()>>}
_binpkgs_repo_name=${_binpkgs_repo_name:-<<&host-binpkgs-repo-name()>>}
_path_binpkgs=${_path_binpkgs:-${_path_binpkgs_root}/${_binpkgs_repo_name}}
_path_distfiles=${_path_distfiles:-<<&host-distfiles-path()>>}
_path_distcc_hosts=${_path_distcc_hosts:-<<&host-distcc-hosts-path()>>}
_path_ssh=${_path_ssh:-<<&host-ssh-path()>>}

export \
_tm_pb=${_tm_pb:-tgbugs/musl:package-builder}
_tm_s_pb=${_tm_s_pb:-tgbugs/musl:static-package-builder}

_tm_pbs=${_tm_pbs:-${_tm_pb}-snap} \
_tm_s_pbs=${_tm_s_pbs:-${_tm_s_pb}-snap} \
#+end_src

#+name: &builder-resnap
#+begin_src bash
function builder-resnap () {
docker run ${_tm_pb}
docker commit $(docker ps -lqf ancestor=${_tm_pb}) ${_tm_pbs}
}
# FIXME SIGH SIGH SIGH why is this easier than doing the right thing
function static-builder-resnap () {
docker run ${_tm_s_pb}
docker commit $(docker ps -lqf ancestor=${_tm_s_pb}) ${_tm_s_pbs}
}
#+end_src

#+name: &container-check
#+begin_src bash
function container-check () {
docker container inspect local-repos-snap > /dev/null || \
docker create -v /var/db/repos --name local-repos-snap tgbugs/repos:latest /bin/true

# FIXME need to check that the cross image exists sigh make
docker container inspect cross-sbcl > /dev/null || \
docker create -v /sbcl --name cross-sbcl tgbugs/musl:cross-sbcl /bin/true
}
#+end_src

# FIXME currently the host sets /etc/distcc/hosts and mounts it
# host discovery for distcc will take more work ... in particular
# port mapping via ssh, the other possibility is that we just
# add a utility that can configure a container image to update
# itself with current settings or something
# FIXME FEATURES and MAKEOPTS are also set assuming the host is gentoo

#+name: &builder-args
#+begin_src bash
--volumes-from local-repos-snap \
--volumes-from cross-sbcl \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v ${_path_ssh}:/var/lib/portage/home/.ssh \
-v ${_path_distcc_hosts}:/etc/distcc/hosts \
--env FEATURES="$(portageq envvar FEATURES | grep -o distcc)" \
--env MAKEOPTS="$(portageq envvar MAKEOPTS)" \
#+end_src
# --network host \
# network host is required to get distcc working on here due to the port forwarding
# hilariously or depressingly network host is still the only sane solution
# https://stackoverflow.com/q/17770902

#+name: &builder-bootstrap
#+begin_src bash :noweb yes
function builder-bootstrap () {
container-check

docker run \
<<&builder-args>>
${_tm_pbs} \
emerge  --color=y --with-bdeps=y -j4 -q --keep-going --getbinpkg \
sys-devel/distcc \
sys-devel/crossdev

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}

for target in {x86_64-pc-linux-gnu,x86_64-pc-linux-musl,x86_64-gentoo-linux-musl}; do
docker run \
<<&builder-args>>
${_tm_pbs} \
crossdev --stage4 --stable --portage --getbinpkg --target ${target}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
done

}
#+end_src

# TODO distcc test
#+begin_src bash
function test_distcc () {
local test_host
for test_host in $(distcc --show-hosts); do
echo ${test_host}
DISTCC_HOSTS=${test_host} distcc x86_64-gentoo-linux-musl-gcc -c test.c -o test.o -v
echo
done
}
#+end_src

#+name: distcc-test-file
#+begin_src c
#include <stdio.h>
int main(void)
{
	printf("Hello world\n");
	return 0;
}
#+end_src

# TODO crossdev aarch64-unknown-linux-gnu-emerge
#+name: &builder-world
#+begin_src bash :noweb yes
function builder-world () {
container-check
cat ./musl/package-builder/world | xargs \
docker run \
<<&builder-args>>
${_tm_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going -uDN
local OUT=$?

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
return $OUT
}

# FIXME SIGH code dupe
function static-builder-world () {
container-check
cat ./musl/static-package-builder/world | xargs \
docker run \
<<&builder-args>>
${_tm_s_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going -uDN

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src

#+name: &builder-arb
#+begin_src bash :noweb yes
function builder-arb () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
<<&builder-args>>
${_tm_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
# XXX FIXME code dupe
function static-builder-arb () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
<<&builder-args>>
${_tm_s_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src

# XXX seems like cross emerge really does not work at all as desired ???
# well this is somewhat annoying https://wiki.gentoo.org/wiki/Cross_build_environment
# grrr the system should be able to use the host packages, yes I know that there are
# surely many build tools that have bad assumptions baked in about the host environment
# matching the target environment ... but sigh
# XXX LOL the answer was simple, --nodeps DUH!
# the other part of the solution is to add ** to ACCEPT_KEYWORDS
# but it may need to be se in the cross env make.conf
# yeah ... unfortunately for things like sbcl ... there is no way
# because the ebuild authors would have had to anticipate this
# and it is insanely hard to test stuff like this, I make the modification
# in sbcl.env that is needed to get it to work, but still ...
# just symlink it to the cross env portage/env, and then we are to our
# usual determine-endianness issues with host vs target
#+name: &cross-builder-arb
#+begin_src bash :noweb yes
function cross-aarch64-gnu-builder-arb () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
<<&builder-args>>
--env USE='-*' \
--env ACCEPT_KEYWORDS='**' \
${_tm_pbs} \
aarch64-unknown-linux-gnu-emerge --color=y --with-bdeps=y -j4 -q --keep-going \
--usepkg=n --nodeps --buildpkgonly \
${@}

}
#+end_src

There are some packages such as =dev-lang/go= and some cross compiles
that require elevated privs in order to build otherwise they try to
call =process_vm_readv= then die.

See https://github.com/gentoo/gentoo-docker-images/issues/98 and
https://github.com/moby/moby/issues/1916.

#+name: &builder-arb-priv
#+begin_src bash :noweb yes
function builder-arb-priv () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
--security-opt seccomp=unconfined \
<<&builder-args>>
${_tm_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
# FIXME code dupe
function static-builder-arb-priv () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
--security-opt seccomp=unconfined \
<<&builder-args>>
${_tm_s_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src
# dev-lisp/sbcl cross compile

# ah the irony of docker dependencies needing ISE:do_peekstr:process_vm_readv
# due to using go-md2man and thus being unsafe to build in a sandboxed docker container
#+name: &musl-run-build-need-priv
#+begin_src bash
builder-arb-priv -1 -uN --getbinpkg \
dev-lang/go \
dev-go/go-md2man \
app-containers/runc \
app-containers/containerd \
app-containers/docker-cli
#+end_src

# --network host \
#+name: &builder-debug
#+begin_src bash :noweb yes
function builder-debug () {
container-check
docker run \
--privileged \
<<&builder-args>>
-it ${_tm_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
# XXX FIXME code dupe
function static-builder-debug () {
container-check
docker run \
--privileged \
<<&builder-args>>
-it ${_tm_s_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src

#+begin_src bash
# --nodeps # potentially useful

@live-rebuild

app-misc/screen
dev-lisp/sbcl


# to debug issues
docker run \
--volumes-from local-repos-snap \
--rm \
-it \
tgbugs/musl:package-builder-snap

# too many issues, just merge and get on with it
# the lack of separation between build time dependencies and runtime is quite annoying
# that or the dependency trees are even worse than I thought
# emerge --color=y -j4 -q --keep-going --onlydeps
# emerge --color=y -j4 -q --keep-going --buildpkgonly
#+end_src

*** build
# FIXME cp -r is a hack for the time being, patches should be source more sanely
# cp -r patches/ musl/package-builder/
#+name: &musl-build-package-builder
#+begin_src screen
docker build \
--tag tgbugs/musl:package-builder \
--file musl/package-builder/Dockerfile musl/package-builder
#+end_src

*** file
# TODO distcc
# COPY patches /etc/portage/patches
#+name: &musl-package-builder-common
#+begin_src dockerfile
COPY --from=tgbugs/musl:portage-maven / /

ADD repo_name /var/db/crossdev/profiles/repo_name
ADD layout.conf /var/db/crossdev/metadata/layout.conf
ADD crossdev.conf /etc/portage/repos.conf/crossdev.conf
ADD sbcl.env /etc/portage/env/dev-lisp/sbcl

RUN \
echo 'FEATURES="${FEATURES} buildpkg"' >> /etc/portage/make.conf \
&& echo 'EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --usepkg"' >> /etc/portage/make.conf
#+end_src

We don't add distcc until we get to the builder here to avoid issues
during bootstrap. Usually we don't have too many packages to rebuild
to get to a sane world state.

#+begin_src dockerfile :tangle ./musl/package-builder/Dockerfile
FROM tgbugs/musl:xorg

<<&musl-package-builder-common>>
#+end_src

*** sbcl bootstrap
The gentoo ebuilds for sbcl retrieve an existing binary for bootstrapping.
Due to the fact that the current EAPI (?) is not libc aware for precompiled
binaries we would have to create and maintain a binary for the musl overlay.
Modifying =src_unpack= is a more expedient solution.
#+begin_src ebuild :tangle ./musl/package-builder/sbcl.env
src_unpack() {
	unpack ${A}
	[ -d /sbcl ] && {
		einfo "Using /sbcl for bootstrap"
		cp -r /sbcl sbcl-binary || die;
		cp -a ${S}/run-sbcl.sh sbcl-binary/ || die;
	} || {
	command -v sbcl && {
		einfo "Using local sbcl found at $(command -v sbcl) for bootstrap"
		local bin_core_home;
		IFS=',' read -r -a bin_core_home <<< $(sbcl --noinform --no-sysinit --no-userinit --eval \
		'(progn (format t "~a,~a,~a" sb-ext:*runtime-pathname* sb-ext:*core-pathname* (sb-int:sbcl-homedir-pathname)))' --quit) || die;
		mkdir -p sbcl-binary/src/runtime || die;
		mkdir -p sbcl-binary/output || die;
		mkdir -p sbcl-binary/obj/sbcl-home || die;
		cp -a ${bin_core_home[0]} sbcl-binary/src/runtime/ || die;
		cp -a ${bin_core_home[1]} sbcl-binary/output/ || die;
		cp -a ${bin_core_home[2]}/contrib sbcl-binary/obj/sbcl-home/contrib || die;
		cp -a ${S}/run-sbcl.sh sbcl-binary/ || die;
	} } ||
	mv sbcl-*-* sbcl-binary || die
	cd "${S}"
}
#+end_src
*** crossdev
In order to fix
#+begin_example
 * Missing digest for '/var/db/docker-profile/cross-x86_64-pc-linux-gnu/binutils/binutils-2.34-r2.ebuild'
 * Missing digest for '/var/db/docker-profile/cross-x86_64-pc-linux-gnu/binutils/binutils-2.33.1-r1.ebuild'
#+end_example

This works around the fact that musl uses thin manifests.  See
https://wiki.gentoo.org/wiki/Custom_ebuild_repository#Crossdev.
#+begin_src conf :tangle ./musl/package-builder/repo_name
crossdev
#+end_src

#+begin_src conf :tangle ./musl/package-builder/layout.conf
masters = gentoo
thin-manifests = true
#+end_src

#+begin_src conf :tangle ./musl/package-builder/crossdev.conf
[crossdev]
location = /var/db/crossdev
priority = 10
masters = gentoo
auto-sync = no
#+end_src

But even with that fix there is an issue with linking the core runtime libs.
#+begin_example
/usr/libexec/gcc/x86_64-pc-linux-gnu/ld: cannot find crti.o: No such file or directory
#+end_example

For reasons I do not fully understand we have to use the gentoo repo
as the source for the gcc ebuild, the two are virtually identical, so
maybe the toolchain eclass is silently different? Unknown.
#+begin_src bash
crossdev --stage4 --stable --target x86_64-pc-linux-gnu --ov-gcc /var/db/repos/gentoo
#+end_src

At this point we can attempt to emerge sbcl, but =src_config= will fail.
#+begin_src bash
x86_64-pc-linux-gnu-emerge -q -j4 sbcl
#+end_src

As a result, I reworked the profile so that it can support whatever
libc we want and do the cross build from gnu to musl since there are
distributed sbcl-binaries for gnu but not for musl. The way that
multiple libcs are implemented in gentoo right now seems to add
significant maintenance overhead due to ebuild duplication.

*** world
#+name: world-package-builder
#+begin_src conf :tangle ./musl/package-builder/world
<<ident((dedupe-lines "world-package-builder-dupes"))>>
#+end_src

#+name: world-package-builder-dupes
#+begin_src conf
<<world-package-builder-nox>>
<<world-kg-release>>
<<world-kg-dev>>
<<world-docker>>
<<world-interlex>>
<<world-sparcur>>
<<world-package-builder-common>>
x11-base/xorg-server
x11-libs/gtk+
#+end_src

#+name: world-package-builder-common
#+begin_src conf
app-portage/smart-live-rebuild
app-editors/gvim
#+end_src

#+begin_src conf
media-libs/freetype
media-libs/fontconfig
media-fonts/dejavu
#+end_src

** package-builder-nox
*** populate 0
#+name: &musl-run-updated-quickpkg
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v "$(pwd)"/bin/quickpkg-new:/tmp/quickpkg-new \
--rm \
tgbugs/musl:updated \
/bin/sh -c 'quickpkg $(/tmp/quickpkg-new)'
#+end_src

#+name: &musl-run-pypy3-quickpkg
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v "$(pwd)"/bin/quickpkg-new:/tmp/quickpkg-new \
--rm \
tgbugs/musl:pypy3 \
/bin/sh -c 'quickpkg $(/tmp/quickpkg-new)'
#+end_src
*** run
#+begin_src bash
cat ./musl/package-builder/nox.world | xargs \
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
--rm \
tgbugs/musl:package-builder-nox \
emerge --color=y -j4 -q --keep-going
#+end_src
*** world
If there is a new package that one of your images needs add it here.
Yes, there are going to be issues with keywording that are likely going
to require updates to the profile followed by a rebuild here. I can't quite
remember whether binpkgs check use flags.
#+name: world-package-builder-nox
#+begin_src conf :tangle ./musl/package-builder/nox.world
<<world-debug>>
<<world-emacs>>
<<world-dynapad-base>>
<<world-python>>
<<world-schemes>>
<<world-package-builder-common>>
dev-lisp/sbcl
#+end_src

# requires a crossdev environment for this to work
#+name: world-lisp
#+begin_src conf
dev-lisp/sbcl
dev-lisp/clozurecl
dev-lisp/clisp
#+end_src

#+name: world-schemes
#+begin_src conf
dev-scheme/chicken
dev-scheme/guile
dev-scheme/gambit
#+end_src
# TODO build Chez from the Racket repo for unencumbered boot files
#+name: world-xemacs
#+begin_src conf
app-editors/xemacs
app-xemacs/xemacs-packages-all
#+end_src

*** build
#+name: &musl-build-package-builder-nox
#+begin_src screen
docker build \
--tag tgbugs/musl:package-builder-nox \
--file musl/package-builder/nox.Dockerfile musl/package-builder
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/package-builder/nox.Dockerfile
FROM tgbugs/musl:pypy3

<<&musl-package-builder-common>>
#+end_src

** package-binhost
** binpkg-only
*** run
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
--rm \
-it tgbugs/musl:binpkg-only
#+end_src

*** build
#+name: &musl-build-binpkg-only
#+begin_src bash
docker build \
--tag tgbugs/musl:binpkg-only \
--file musl/binpkg-only/Dockerfile musl/binpkg-only
#+end_src

*** file
# wow parallel-install -ebuild-locks speeds things up quite a bit
# unfortunately they break acct-group and acct-user packages
# due to /etc/gshadow.lock contention which I think happends due
# to the -ebuild-locks feature because setting that allows
# unsandboxed steps to install concurrently
#+name: &musl-binpkg-only-common
#+begin_src dockerfile

RUN \
echo 'EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --usepkgonly --getbinpkgonly"' >> /etc/portage/make.conf \
&& echo 'FEATURES="${FEATURES} parallel-install -ebuild-locks"' >> /etc/portage/make.conf
#+end_src

#+begin_src dockerfile :tangle ./musl/binpkg-only/Dockerfile
FROM tgbugs/musl:xorg
<<&musl-binpkg-only-common>>
#+end_src

** binpkg-only-nox
*** build
#+name: &musl-build-binpkg-only-nox
#+begin_src screen
docker build \
--tag tgbugs/musl:binpkg-only-nox \
--file musl/binpkg-only/nox.Dockerfile musl/binpkg-only
#+end_src

*** file
# FIXME not quite right, this is the vanilla, which leaves X enabled for some things
#+begin_src dockerfile :tangle ./musl/binpkg-only/nox.Dockerfile
FROM tgbugs/musl:pypy3
<<&musl-binpkg-only-common>>
#+end_src

** debug
*** world
#+name: world-debug
#+begin_src conf
app-editors/vim
app-portage/eix
sys-devel/gdb::musl
#+end_src

** docker :bootstrap:
This image provides one route to bootstrap an environment that can
execute this file. Other routes also exist.

This route requires the following dependencies.
1. This =source.org= file.
2. Emacs 27 or later (earlier might work but not tested)
3. A posix shell
4. docker version 20 or later
5. Access to a gentoo stage 3 musl image.

It does not require git to be installed on the host so =source.org=
could be retrieved via curl or from a backup or similar.

With a bit of wrangling the bootstrap might also be able to drop the
Emacs dependency.

A second phase bootstrap is used to provide a stable starting point
for the rest of the process. This second phase does use git.

*** run
Reminder that this gives access to the host docker system.
#+begin_src bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-it tgbugs/musl:docker
#+end_src

Version that works with existing package host folders.

#+begin_src bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-v ~/files/binpkgs:/binpkgs \
-it tgbugs/musl:docker
#+end_src

After quite a bit of exploration it seems that passing =docker.sock=
is the sanest way to achieve what we want, though it does create a
strange warping of perspective because all containers run on the host
docker server. This is unfortunate because it causes the semantics to
differ between running the bootstrap outside of docker or trying to
run it "inside" of docker. See the dind heading above for more.
*** build
#+name: &musl-build-docker
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:docker \
--file musl/docker/Dockerfile musl/docker
#+end_src

*** entrypoints
0th
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/docker/entrypoint-0.sh :mkdirp yes
pushd dockerfiles
./source.org ${@}
#+end_src

1st
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/docker/entrypoint-1.sh :mkdirp yes
git clone https://github.com/tgbugs/dockerfiles.git
pushd dockerfiles
./source.org ${@}
#+end_src

*** file
# TODO daemon.json
#+begin_src dockerfile :tangle ./musl/docker/Dockerfile
<<&build-world>>
ADD source.org /dockerfiles/source.org
ADD entrypoint-0.sh /etc/entrypoint-0.sh
ENTRYPOINT /etc/entrypoint-0.sh
#+end_src

#+begin_src dockerfile :tangle ./musl/docker/nox.Dockerfile
<<&build-world-nox>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
NOTE =dev-lang/go= is pulled in by =app-emulation/docker= and must be
built using ref:&builder-arb-priv to avoid =process_vm_readv= being
blocked by the container.

#+name: world-docker
#+begin_src conf :tangle ./musl/docker/world
app-editors/emacs
app-containers/docker
app-containers/docker-cli
#+end_src

** testing-python
Python testing.
*** world
# gentoo no longer has 3.6 in the main tree, going to be a pain test back there
# dev-lang/python:3.6
#+name: world-python
#+begin_src conf :tangle ./musl/testing-python/world
dev-lang/python:3.7
dev-lang/python:3.8
dev-lang/python:3.9
dev-lang/python:3.10
dev-python/pypy3
dev-python/pip
#+end_src
# XXX pipenv continues to be a toxic waste dump of insanity and brokeness
# https://bugs.gentoo.org/717666 really really bad call on my part for
# picking it back in 2018 because Pipfile seemed useful
# LOL PYTHON pipenv bundles tomli but apparently has a hard upper version limit in the ebuild? wat
# dev-python/pipenv
** testing-emacs
Emacs testing.
*** world
#+begin_src conf :tangle ./musl/testing-emacs/world
app-editors/emacs:18
app-editors/emacs:23
app-editors/emacs:24
app-editors/emacs:25
app-editors/emacs:26
app-editors/emacs:27
app-editors/emacs:28
app-editors/emacs:29-vcs
#+end_src
** emacs
Emacs using the athena 3d toolkit to avoid pulling in gtk.
*** bugs
If you quickpkg emacs and then try to install it you can encounter
#+begin_example
mv: cannot stat '/var/tmp/portage/app-editors/emacs-27.2-r5/image/usr/share/info/emacs-27/dir.orig': No such file or directory
#+end_example
This is somewhat concerning since the failure is during preinst and it
definitely should not be looking in /var/tmp/portage for that orig
file. It seems that forcing a rebuild with builder-arb fixes the issue.
*** run
#+begin_src screen
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:emacs
#+end_src

debug run
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:emacs
#+end_src

If you see the following error you somehow forgot/are missing the musl overlay.
#+begin_example
Error loading shared library libbsd.so.0: No such file or directory (needed by /usr/lib/libICE.so.6)
Error loading shared library libbsd.so.0: No such file or directory (needed by /usr/lib/libXdmcp.so.6)
Error relocating /usr/lib/libICE.so.6: arc4random_buf: symbol not found
Error relocating /usr/lib/libXdmcp.so.6: arc4random_buf: symbol not found
#+end_example

*** build
#+name: &musl-build-emacs
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:emacs \
--file musl/emacs/Dockerfile musl/emacs
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/emacs/Dockerfile
<<&build-world>>
#+end_src

#+begin_src dockerfile :tangle ./musl/emacs/nox.Dockerfile
<<&build-world-nox>>
#+end_src

*** world
# FIXME I think something in the emacs ebuild is broken because sometimes it fails to pull in libbsd???
#+name: world-emacs
#+begin_src conf :tangle ./musl/emacs/world
app-emacs/vterm
app-editors/emacs
#+end_src

** icedtea
*** build
#+name: &musl-build-icedtea
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:icedtea \
--file musl/icedtea/Dockerfile musl/icedtea
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/icedtea/Dockerfile
<<&build-world>>
#+end_src
*** world
# FIXME BROKEN
#+name: world-icedtea-broken
#+begin_src conf :tangle ./musl/icedtea/world :tangle no
dev-java/icedtea-bin::musl
#+end_src

Backup.
#+name: world-icedtea
#+begin_src conf :tangle ./musl/icedtea/world
dev-libs/nss
x11-libs/libXcomposite
x11-libs/libXtst
dev-java/icedtea-bin::musl
#+end_src
# back to musl since somehow my local setup is broken for the package builder
# and the musl repo is fixed again and I managed to pull everything down this time
# dev-java/icedtea-bin::local

# note the lack of tangle
#+name: world-icedtea-nox
#+begin_src conf
dev-libs/nss
dev-java/icedtea-bin::local
#+end_src

*** legacy
The musl overlay installs icedtea-bin correctly now so this is
+thankfully no longer needed+ only needed periodically.
#+name: &musl/icedtea/legacy
#+begin_src dockerfile :tangle ./musl/icedtea/legacy.Dockerfile
FROM tgbugs/musl:xorg

ARG ARCHIVE

ARG BASE="https://github.com/tgbugs/musl/releases/download/icedtea-bin-3.18.0-alpine-helper-0/"

ARG TMCH=34581ad0f14b5898abfb8d0a7ad89d560270a2e5

RUN \
eselect repository create local /usr/local/portage

# FIXME this is an evil hack that WILL expire
RUN \
mkdir -p /usr/local/portage/dev-java/icedtea-bin \
&& pushd /usr/local/portage/dev-java/icedtea-bin \
&& ln -s /var/db/repos/musl/dev-java/icedtea-bin/files \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/icedtea-bin-3.18.0.ebuild" \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/Manifest"

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q nss \
<<&archive-or-rm>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q dev-java/icedtea-bin::local --onlydeps \
<<&archive-or-rm>>

ARG SIGH="icedtea-bin-3.18.0-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-dbg-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-doc-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-base-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-lib-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-libjpeg-x86_64-musl.tar.gz"

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
pushd /var/cache/distfiles \
&& for SI in ${SIGH}; do curl -L -o "${SI}" "${BASE}${SI/-musl/}"; done \
&& popd \
&& emerge -j4 -q dev-java/icedtea-bin::local \
<<&archive-or-rm>>
#+end_src

# export failure=$(docker ps -lq)
# docker start $failure
# docker attach $failure

** protege
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:protege
#+end_src

*** build
#+name: &musl-build-protege
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:protege \
--build-arg UID=${UID} \
--file musl/protege/Dockerfile musl/protege
#+end_src

Due to the fact that protege needs X11 running in order to create
config files.  Run the following command, change the default reasoner
to ELK, make any other changes that are needed, and then quit protege.
The second command will run automatically and commit the changes.

NOTE you must run the =protege= command manually to prevent the commit
from changing the default behavior of the container from changing its
entry point to run =protege=.

#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:protege && \
docker commit $(docker ps -lq) tgbugs/musl:protege
#+end_src

*** world
#+name: world-protege
#+begin_src conf :tangle ./musl/protege/world
<<world-icedtea>>
dev-python/pip
#+end_src
*** file
We install pip during this step because any builds that =FROM
tgbugs/musl:protege= default to =protegeuser=.
# TODO FIXME we should be able to install protege as root
#+name: &musl/protege
#+begin_src dockerfile :tangle ./musl/protege/Dockerfile
FROM tgbugs/musl:icedtea as builder

ARG ARCHIVE
ARG PROTEGE_VERSION="5.5.0"

WORKDIR /build

<<&musl-user-skel-common>>

USER ${USER_NAME}

ARG HOME=/build/home/${USER_NAME}

WORKDIR $HOME

# phase two protege and reasoners
ARG URL_PROTEGE="https://github.com/protegeproject/protege-distribution/releases/download/v5.5.0/Protege-5.5.0-linux.tar.gz"
ARG URL_ELK="https://github.com/liveontologies/elk-reasoner/releases/download/v0.4.3/elk-distribution-0.4.3-protege-plugin.zip"
ARG URL_FACT="https://bitbucket.org/dtsarkov/factplusplus/downloads/uk.ac.manchester.cs.owl.factplusplus-P5.x-v1.6.5.jar"

RUN \
cd ~/ \
&& curl -L -O ${URL_PROTEGE} \
&& tar xvzf Protege-${PROTEGE_VERSION}-linux.tar.gz \
&& pushd Protege-${PROTEGE_VERSION} \
&& rm jre/ -r \
&& sed -i 's/^jre\/bin\/java/\/usr\/bin\/java/' run.sh \
&& sed -i 's/500M/12G/' run.sh \
&& sed -i 's/200M/5G/' run.sh \
&& sed -i 's/16M/160M/' run.sh \
&& pushd plugins \
&& curl -L -O ${URL_FACT} \
&& curl -L -O ${URL_ELK} \
&& unzip -p elk-distribution-0.4.3-protege-plugin.zip \
   elk-distribution-0.4.3-protege-plugin/org.semanticweb.elk.jar \
   > org.semanticweb.elk-0.4.3.jar \
&& rm elk-distribution-0.4.3-protege-plugin.zip \
&& popd; popd \
&& mkdir -p ~/.local/share ~/.local/bin \
&& mv Protege-${PROTEGE_VERSION} ~/.local/share/ \
&& pushd ~/.local/bin \
&& ln -s ../share/Protege-${PROTEGE_VERSION}/run.sh protege \
&& popd \
&& rm Protege-${PROTEGE_VERSION}-linux.tar.gz

# paths to preferences files
ARG PATH_CFU_1=_\!\&\!\!\`g\"\>\!\&@\!\[@\"\(\!%\`\!\|w\"@\!\&\)\!\[@\"\'\!%\`\!\`g\"\&\!%4\!@w\"\&\!\&:=
ARG PATH_CFU_2=_\!\'%\!c\!\"w\!\'w\!a@\"j\!\'%\!d\!\"p\!\'8\!bg\"f\!\(\!\!cg\"l\!\'\}\!~@\"y\!\'\`\!bg\"j\!\'\`\!cw==
ARG PATH_CFU_3=_\!\'8\!cg\"n\!#4\!c\!\"y\!\'8\!d\!\"l\!\'c\!~@\!u\!\'\`\!~\!\"p\!\(@\!bw\"y\!#4\!\}w\"v\!\(\)\!~@\!u\!\(\`\!c\!\"k\!\'%\!d\!\"l\!#4\!\`\!\"s\!\(\`\!~w\"p\!\'4\!\^@\"h\!\'4\!\}@\"n\!\'\`\!cg==
ARG PATH_CFU="${PATH_CFU_1}/${PATH_CFU_2}/${PATH_CFU_3}"

# set preferences so that protege starts in the right state the first time
# protege doesn't create this prefs file by default so we would have to do this regardless
# this helps because it prevents the search for plugins on first run so that goes faster
RUN \
pushd ~/ \
&& mkdir -p ".java/.userPrefs/${PATH_DRI_1}" \
&& chmod 0700 ".java/.userPrefs" \
&& mkdir -p ".java/.userPrefs/${PATH_CFU}" \
&& echo '<?xml version="1.0" encoding="UTF-8" standalone="no"?>' > ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '<!DOCTYPE map SYSTEM "http://java.sun.com/dtd/preferences.dtd">' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '<map MAP_XML_VERSION="1.0">' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '  <entry key="CheckForUpdates" value="false"/>' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '</map>' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& popd

FROM tgbugs/musl:icedtea

<<&build-world-common>>

COPY --from=builder /build /

<<&musl-file-user-base>>
#+end_src

Sadly this approach does not work because protege dies before the
reasoner prefs file is written.  Therefore we have to run the image
manually and commit before release. Sigh.
#+begin_src dockerfile
# start protege to generate settings files, have to sleep becuase the
# protege sh wrapper breaks $!
RUN \
protege \
& sleep 6 \
&& kill $(ps | grep java | awk '{ printf $1 }')

# on first run protege doesn't check to see if there is already
# something in this prefs.xml file and appends to it automatically
RUN \
find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q DEFAULT_REASONER_ID {} \; \
-exec sed -i 's/org.protege.editor.owl.NoOpReasoner/org.semanticweb.elk.elk.reasoner.factory/' {} \;

# must use absolute path otherwise command form won't work
WORKDIR /home/${USER_NAME}
#+end_src

In order to get paths that point to the prefs.xml files that we can
embed in the docker file you need the following commands.
#+begin_src bash
printf '%q' $(find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q CheckForUpdates {} \; -print0)
#+end_src

A useful find command for debugging whether the correct reasoner has been set.
#+begin_src bash
find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q DEFAULT_REASONER_ID {} \; -exec cat {} \;
#+end_src

** NIF-Ontology
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:NIF-Ontology
#+end_src

*** build
# TODO progress prints to stderr
#+name: &musl-build-NIF-ontology
#+begin_src bash
docker build \
--tag tgbugs/musl:NIF-Ontology \
--file musl/NIF-Ontology/Dockerfile musl/NIF-Ontology
#+end_src

*** file
# FIXME composition with protege user issues I think the right way to
# do this is to move to having a single container user image that we
# build and then use COPY --from on that?
#+name: &musl/NIF-Ontology
#+begin_src dockerfile :tangle ./musl/NIF-Ontology/Dockerfile
FROM tgbugs/musl:protege

# phase three ontology
RUN \
pushd ~/ \
;   mkdir git \
;   pushd git \
;       git clone https://github.com/SciCrunch/NIF-Ontology.git \
;       pushd NIF-Ontology \
;           pushd ttl \
;           cp catalog-v001.xml.example catalog-v001.xml \
;       popd \
;   popd
#+end_src

** neurondm
*** run
#+begin_src bash
# to allow the container access to the local x session you have to run the following
xhost local:docker
# use xhost -local:docker to remove

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:neurondm

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:neurondm \
protege
#+end_src

*** build
#+begin_src bash
docker build \
--tag tgbugs/musl:neurondm \
--build-arg ONTOLOGY_GITREF=neurons \
--file musl/neurondm/Dockerfile musl/neurondm
#+end_src

*** file
#+name: &musl/neurondm
#+begin_src dockerfile :tangle ./musl/neurondm/Dockerfile
FROM tgbugs/musl:NIF-Ontology

ARG ONTOLOGY_GITREF=neurons

# phase three ontology
RUN \
pushd ~/git/NIF-Ontology \
;   git checkout ${ONTOLOGY_GITREF} \
;   popd

# phase four python tools
RUN \
pushd ~/ \
;   pushd git \
;       git clone https://github.com/tgbugs/pyontutils.git \
;       pushd pyontutils \
;           pip install --user -e . \
;           pushd neurondm \
;               pip install --user -e . \
;           popd \
;       popd \
;   popd
#+end_src

** npo-1.0
*** run
#+begin_src bash
xhost local:docker

docker pull tgbugs/musl:npo-1.0

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0 \
sh -c 'protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src
**** macos notes
#+begin_src bash
brew install virtualbox  # there are some system level persmissions that you will need to set
brew install --cask docker
open -a Docker\ Desktop
# You will need to go to Docker Desktop > Preferences > Resources
# and increase the memory limit to 8 gigs
# otherwise oom killer will end Protege while trying to load npo.ttl

brew install xquartz
open -a XQuartz
# You will need to go to XQuartz > Preferences > Security
# and enable Allow connections from network clients
xhost +localhost
export DISPLAY=:0
# test to make sure everything still works e.g. by running xeyes

docker pull tgbugs/musl:npo-1.0
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=host.docker.internal$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0 \
sh -c 'protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src

Run the block above and once protege starts type =Control R= to run
the reasoner. The docker image is running the Linux version of Protege
so the key bindings use Control instead of Command. You can then run
OWL DL queries in the tab. Note that if you are using the ELK reasoner
(enabled by default in the image) then you will have to click through
a number of warning dialogues, this is normal.

*** build
#+begin_src bash
docker build \
--tag tgbugs/musl:npo-1.0 \
--build-arg ONTOLOGY_GITREF=npo-1.0 \
--file musl/neurondm/Dockerfile musl/neurondm
#+end_src

** npo-1.0-neurondm-build
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0-neurondm-build \
sh -c 'git stash && protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src
*** build
Build using the SciCrunch SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:npo-1.0-neurondm-build \
--build-arg NEURONS_BRANCH=npo-1.0 \
--build-arg NUID=${UID} \
--secret id=scigraph-api-key,src=<(echo export SCIGRAPH_API_KEY=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api-key"))')) \
--file musl/npo-1.0-neurondm-build/Dockerfile musl/npo-1.0-neurondm-build
#+end_src

Build using an alternate SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:npo-1.0-neurondm-build \
--build-arg NEURONS_BRANCH=npo-1.0 \
--build-arg NUID=${UID} \
--build-arg SCIGRAPH_API=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api"))') \
--secret id=scigraph-api-key,src=<(echo) \
--file musl/npo-1.0-neurondm-build/Dockerfile musl/npo-1.0-neurondm-build
#+end_src
# --build-arg SCIGRAPH_API=http://192.168.1.207:9000/scigraph \

*** file
# FIXME should probably be using a multi source file here instead of
# noweb but I'm not sure we can really do that because the output
# depends on the state of the ontology repo
#+name: &musl/neurondm-build
#+begin_src dockerfile :tangle ./musl/npo-1.0-neurondm-build/Dockerfile
FROM tgbugs/musl:npo-1.0
<<&-base-musl/neurondm-build>>
#+end_src

*** save
This is the image that will be archived to Zenodo for the paper. Note
that the dl queries will not run as expected on this unless you first
stash the changes in =~/git/NIF-Ontology=.

#+begin_src bash
docker save tgbugs/musl:npo-1.0-neurondm-build | gzip > /tmp/npo-1.0-neurondm-build.tar.gz
#+end_src

To restore from the archive run
#+begin_src bash
docker load --input npo-1.0-neurondm-build.tar.gz
#+end_src

The sha256 checksum for npo-1.0-neurondm-build.tar.gz on Zenodo at
doi:10.5281/zenodo.5033493 is
=8e0bb1c684ca8a28f1abeb01ef7aa2597388b8011244f097a92bdd2a523db102=.

** neurondm-build
This image runs the neurondm build process.
*** run
*** build
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:neurondm-build \
--build-arg NUID=${UID} \
--secret id=scigraph-api-key,src=<(echo export SCIGRAPH_API_KEY=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api-key"))')) \
--file musl/neurondm-build/Dockerfile musl/neurondm-build
#+end_src

Build using an alternate SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:neurondm-build \
--build-arg NUID=${UID} \
--build-arg SCIGRAPH_API=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api"))') \
--secret id=scigraph-api-key,src=<(echo) \
--file musl/neurondm-build/Dockerfile musl/neurondm-build
#+end_src

*** file
#+name: &musl/neurondm-build
#+begin_src dockerfile :tangle ./musl/neurondm-build/Dockerfile
FROM tgbugs/musl:neurondm
<<&-base-musl/neurondm-build>>
#+end_src

#+name: &-base-musl/neurondm-build
#+begin_src dockerfile
# phase five build
# XXX FIXME we can't run this for the demonstrator because the lack of
# npokb identifiers causes the queries to fail we probably want two
# separate images for this
ARG SCIGRAPH_API
ARG NEURONS_BRANCH
ARG NUID=11741
# FIXME waiting on https://github.com/moby/buildkit/issues/815
#RUN --mount=type=secret,id=scigraph-api-key,uid=${NUID} \
RUN --mount=type=secret,id=scigraph-api-key,uid=1000 source /run/secrets/scigraph-api-key \
; python -m neurondm.models.allen_cell_types \
; python -m neurondm.models.huang2017 \
; python -m neurondm.models.ma2015 \
; git -C ~/git/NIF-Ontology status
#+end_src

** interlex
*** run
WARNING! If you mount your postgres data directory like this make sure
the host system is NOT also running postgres on top of that directory
otherwise you will have a BAD TIME.
#+begin_src screen
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/files/docker-postgres/interlex-dev:/var/lib/postgresql \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:interlex
#+end_src

*** build
#+name: &musl-build-interlex
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:interlex \
--file musl/interlex/Dockerfile musl/interlex
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/interlex/Dockerfile
FROM tgbugs/musl:binpkg-only

<<&build-world-common>>
#+end_src
*** world
# app-misc/elasticsearch  # XXX license issues, likely must handle separately
# so that we don't taint the profile, probably want a license builder image
# or something, this would allow us to build license tainted software and
# then individual images that want to use it could set the license before
# emerging the binpkg
#+name: world-interlex
#+begin_src conf :tangle ./musl/interlex/world
dev-python/interlex
dev-libs/redland
#+end_src

** blazegraph
*** run
#+begin_src bash
docker run \
-v /var/lib/blazegraph:/var/lib/blazegraph \
-p 9999:9999 \
-it tgbugs/musl:blazegraph
#+end_src

*** build
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:blazegraph \
--file musl/blazegraph/Dockerfile musl/blazegraph
#+end_src

*** file
#+name: &musl/blazegraph
#+begin_src dockerfile :tangle ./musl/blazegraph/Dockerfile
<<&build-world-nox>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
#+name: world-blazegraph
#+begin_src conf :tangle ./musl/blazegraph/world
<<world-icedtea-nox>>
dev-db/blazegraph-bin
#+end_src

*** entrypoint
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/blazegraph/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
rc-service blazegraph start
#+end_src

** scigraph
*** run
#+begin_src bash
docker run \
-v /var/lib/scigraph:/var/lib/scigraph \
-p 9000:9000 \
tgbugs/musl:scigraph
#+end_src

*** build
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:scigraph \
--file musl/scigraph/Dockerfile musl/scigraph
#+end_src

*** file
#+name: &musl/scigraph
#+begin_src dockerfile :tangle ./musl/scigraph/Dockerfile
<<&build-world>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
#+name: world-scigraph
#+begin_src conf :tangle ./musl/scigraph/world
<<world-icedtea>>
dev-java/scigraph-bin
#+end_src

*** entrypoint
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/scigraph/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
rc-service scigraph start
#+end_src

** kg-release
Base environment for knowledge graph distribution and interaction.
Combines both server and client functionalities into a single image.
In principle this could be split into multiple images, but for the
sake of simplicity and reproducibility it is a single image.

*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-release
#+end_src

*** build
#+name: &musl-build-kg-release
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:kg-release \
--file musl/kg-release/Dockerfile musl/kg-release
#+end_src

*** file
# when deriving from multiple parent worlds docker does not compose
# well at all, so we have to pick a primary world line so to speak
#+name: &musl/kg-release
#+begin_src dockerfile :tangle ./musl/kg-release/Dockerfile
FROM tgbugs/musl:emacs

<<&build-world-common>>
#+end_src

*** world
#+name: world-kg-release
#+begin_src conf :tangle ./musl/kg-release/world
<<world-emacs>>
<<world-icedtea>>
dev-db/blazegraph-bin
dev-java/scigraph-bin
media-gfx/graphviz
dev-python/ipykernel
dev-python/pip
#+end_src
# TODO consider including for the python bits in queries
# dev-python/pyontutils-9999
# dev-python/nifstd-tools-9999

** kg-release-user
*** run
#+begin_src screen
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-release-user
#+end_src

with configuration for xdg-open forwarding
#+begin_src screen
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src

debug with network in bridge mode
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--add-host local.binhost:127.0.0.1 \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src

debug with host network
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--add-host local.binhost:127.0.0.1 \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
--network=host \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src

*** build
#+name: &musl-build-kg-release-user
#+begin_src screen
unset _devel _docd _sckand _docsfsc
_devel=
_docd=(queries.org)
_docsf="https://raw.githubusercontent.com/SciCrunch/sparc-curation/master/docs/"
_sckand=(welcome.org tutorial.org overview.org examples.org scratch.org README.org)
_docsfsc="${_docsf}sckan/"
pushd ./musl/kg-release-user
rm queries.org welcome.org tutorial.org overview.org examples.org scratch.org
if [ -n "${_devel}" ]; then
  cp -aL ~/git/sparc-curation/docs/sckan/*.org . ;
else
  for fn in ${_docd[@]};   do curl -O ${_docsf}${fn}  ; done
  for fn in ${_sckand[@]}; do curl -O ${_docsfsc}${fn}; done
fi
chmod +x ./queries.org
popd

<<&musl-build-kg-release-user-min>>
#+end_src

#+name: &musl-build-kg-release-user-min
#+begin_src screen
docker build \
--tag tgbugs/musl:kg-release-user \
--build-arg UID=${UID} \
--file musl/kg-release-user/Dockerfile musl/kg-release-user
#+end_src

*** entrypoints
Default interactive entrypoint.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
su user -c 'emacs -geometry 120x40 -eval "(find-file-noselect (pop argv))" ~/welcome.org'
/etc/init.d/scigraph stop
/etc/init.d/blazegraph stop
#+end_src

Entrypoint to start services and run in the background.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/services.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
#+end_src
*** file
# FIXME we should be able to stash the builder in this image
# and reuse it without having to rerun over and over ...
#+name: &musl/kg-release-user
#+begin_src dockerfile :tangle ./musl/kg-release-user/Dockerfile
FROM tgbugs/musl:kg-release as builder

WORKDIR /build

<<&musl-user-skel-common>>

ARG HOME=/build/home/${USER_NAME}

WORKDIR $HOME

ADD --chown=${UID}:${UID} queries.org queries.org

USER ${USER_NAME}

RUN \
./queries.org

ADD --chown=${UID}:${UID} welcome.org welcome.org
ADD --chown=${UID}:${UID} tutorial.org tutorial.org
ADD --chown=${UID}:${UID} overview.org overview.org
ADD --chown=${UID}:${UID} examples.org examples.org
ADD --chown=${UID}:${UID} scratch.org scratch.org
ADD --chown=${UID}:${UID} README.org README.org

RUN \
emacs -batch -eval \
"(let ((user-init-file (pop argv))) (package-initialize) (while argv (let ((f (pop argv))) (orgstrap-whitelist-file f) (kill-buffer (find-file-noselect f)))) (ow-use-packages evil undo-tree))" \
$HOME/.emacs.d/init.el queries.org welcome.org examples.org scratch.org

FROM tgbugs/musl:kg-release

COPY --from=builder /build /

ADD services.sh /etc/services.sh
ADD entrypoint.sh /etc/entrypoint.sh

<<&musl-file-user-base>>

USER 0

RUN \
usermod -a -G blazegraph user \
;  usermod -a -G scigraph user \
;  usermod -a -G wheel user

RUN \
echo 'root:sparcSCKAN-2021' | chpasswd

# make it easier to use portage inside a container
RUN \
echo 'EMERGE_DEFAULT_OPTS=""' >> /etc/portage/make.conf \
&& echo 'FEATURES=""' >> /etc/portage/make.conf

# TODO when running this you will have to set the right mounts
# unless you bake a new kg-dev-with-data release
ENTRYPOINT /etc/entrypoint.sh
#+end_src

** kg-dev
*** run
# scigraph-build-local
# scigraph-deploy-local
# TODO package ontree server so that the updated local scigraph can be seen
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev
#+end_src

#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v /tmp/scigraph-build:/tmp/scigraph-build \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev \
echo TODO secrets, apinat build and more!
#+end_src

debug
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--network host \
--add-host local.binhost:127.0.0.1 \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev
#+end_src

*** build
#+name: &musl-build-kg-dev
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:kg-dev \
--build-arg UID=${UID} \
--file musl/kg-dev/Dockerfile musl/kg-dev
#+end_src

*** world
#+name: world-kg-dev
#+begin_src conf :tangle ./musl/kg-dev/world
<<world-kg-release>>
app-misc/screen
dev-scheme/racket
net-libs/nodejs
app-arch/zip
app-misc/yq
dev-java/robot-bin
dev-node/apinat-converter
dev-python/nifstd-tools
dev-python/pennsieve
dev-python/sparcur
#+end_src

# we include pennsieve in world here because
# it cannot be installed via pip due to a completely
# braindead handling of 2.7 vs 3.0 issues

*** file
#+name: &musl/kg-dev
#+begin_src dockerfile :tangle ./musl/kg-dev/Dockerfile
FROM tgbugs/musl:kg-release
<<&build-world-common>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
eselect racket set cs
#+end_src

** kg-dev-user
# FIXME somehow msising blazegraph user?
*** run
# TODO -v /var/lib/scigraph:/var/lib/scigraph \
#+begin_src screen
# docker create -v /var/lib/blazegraph -v /var/lib/scigraph --name sckan-data tgbugs/sckan:latest /bin/true
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev-user
#+end_src

#+begin_src screen
docker run \
-v /var/lib/blazegraph:/var/lib/blazegraph \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev-user
#+end_src

*** build
#+name: &musl-build-kg-dev-user
#+begin_src screen
docker build \
--tag tgbugs/musl:kg-dev-user \
--build-arg UID=${UID} \
--file musl/kg-dev-user/Dockerfile musl/kg-dev-user
#+end_src

*** entrypoint
#+begin_src bash
if [ -d /tmp/blazegraph ]; then
    cp /tmp/blazegraph/blazegraph.jnl /var/lib/blazegraph/
    cp /tmp/blazegraph/prefixes.conf /var/lib/blazegraph/
    chown -R blazegraph:blazegraph /var/lib/blazegraph
fi
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-dev-user/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
su user -c 'emacs -visit ~/git/sparc-curation/docs/queries.org'
/etc/init.d/scigraph stop
/etc/init.d/blazegraph stop
#+end_src

*** file
# XXX note the using builder means that the command history
# that is used to create the /build/ directory are lost
# sigh bad trade offs for multi stage builds
# HOORAY pip install --user -e and /build/ are incompatable! >_<
#+begin_src dockerfile :tangle ./musl/kg-dev-user/Dockerfile
FROM tgbugs/musl:kg-dev as builder

<<&musl-user-skel-common>>

USER ${USER_NAME}

#ARG HOME=/build/home/${USER_NAME}
ARG HOME=/home/${USER_NAME}

WORKDIR $HOME

ARG INIT_URL=https://raw.githubusercontent.com/tgbugs/orgstrap/master/init-simple.el

RUN \
emacs --batch --quick --eval \
"(progn (url-handler-mode 1) (find-file (pop argv)) (eval-buffer))" \
"${INIT_URL}"

RUN \
pushd ~/.emacs.d \
&& ln -s reval/cache/*/*-ow.el ow.el \
&& ln -s reval/cache/*/*-reval.el reval.el \
&& ln -s reval/cache/*/*-init-content.el init-content.el \
&& echo "(load (expand-file-name \"ow.el\" user-emacs-directory))" >> init.el \
&& echo "(load (expand-file-name \"reval.el\" user-emacs-directory))" >> init.el \
&& echo "(load (expand-file-name \"init-content.el\" user-emacs-directory))" >> init.el \
&& popd

RUN \
mkdir ~/git

# FIXME that is going to need to go in .bashrc or something
ENV PYTHONPYCACHEPREFIX=${HOME}/.cache/pycache/

# FIXME break these into their own images to avoid serial dependencies

# FIXME pip install --user -e . fails when run in /build/ due to change in $HOME
# because it uses an expanded directory of course pip doesn't have any only-deps
# option

RUN \
pushd git \
&&     git clone https://github.com/tgbugs/pyontutils.git \
&&     git clone https://github.com/SciCrunch/sparc-curation.git \
&& popd

RUN \
pushd git \
&&     pushd pyontutils \
&&         pushd nifstd \
&&             pip install --user -e . \
&&             python setup.py --release || true \
&&         popd \
&&     popd \
&&     pushd sparc-curation \
&&         pip install --user -e . \
&&         python setup.py --release || true \
&&     popd \
&& popd \
&& ln -s ../../git/sparc-curation/docs/apinatomy.org ~/.local/bin/apinat-build \
&& rm -r ~/.cache/pip

RUN \
./git/sparc-curation/docs/queries.org

RUN \
./git/sparc-curation/docs/apinatomy.org

RUN \
emacs -batch -eval \
"(let ((user-init-file (pop argv))) (package-initialize) (while argv (orgstrap-whitelist-file (pop argv))))" \
$HOME/.emacs.d/init.el \
./git/sparc-curation/docs/queries.org \
./git/sparc-curation/docs/apinatomy.org

#FROM tgbugs/musl:kg-dev

#COPY --from=builder /build /

ADD entrypoint.sh /etc/entrypoint.sh

ENV PATH="/home/${USER_NAME}/.local/bin:${PATH}"

# XXX somehow this induces ~10MB of new content !??!
#RUN \
#pip install --user --no-deps -e \
#git/pyontutils/nifstd \
#git/sparc-curation \
#&& rm -r ~/.cache/pip

USER 0

RUN \
usermod -a -G blazegraph user \
;  usermod -a -G scigraph user

# TODO when running this you will have to set the right mounts
# unless you bake a new kg-dev-with-data release
ENTRYPOINT /etc/entrypoint.sh
#+end_src
** racket
*** build
#+name: &musl-build-racket
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:racket \
--file musl/racket/Dockerfile musl/racket
#+end_src

Build debug workflow.
#+begin_src bash
# if you have not done so already
docker create \
-v /var/db/repos/gentoo \
--name local-portage-snap \
gentoo/portage:latest \
/bin/true

# if you have you have to clear the container with
# docker rm local-portage-snap

# then
docker run \
--volumes-from local-portage-snap \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:racket
#+end_src

*** file
#+name: &musl/racket
#+begin_src dockerfile :tangle ./musl/racket/Dockerfile
FROM tgbugs/musl:emacs
<<&build-world-common>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
eselect racket set cs
#+end_src

*** world
#+name: world-racket
#+begin_src conf :tangle ./musl/racket/world
<<world-emacs>>
dev-scheme/racket
#+end_src
** racket-user
*** run
#+begin_src bash
# to allow the container access to the local x session you have to run the following
xhost local:docker
# use xhost -local:docker to remove

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:racket-user
#+end_src

*** build
#+name: &musl-build-racket-user
#+begin_src bash
docker build \
--tag tgbugs/musl:racket-user \
--build-arg UID=${UID} \
--file musl/racket-user/Dockerfile musl/racket-user
#+end_src

*** file
#+name: &musl/racket-user
#+begin_src dockerfile :tangle ./musl/racket-user/Dockerfile
FROM tgbugs/musl:racket

COPY --from=tgbugs/musl:user / /

<<&musl-file-user-base>>
#+end_src

** dynapad-base
*** build
#+name: &musl-build-dynapad-base
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:dynapad-base \
--file musl/dynapad-base/Dockerfile musl/dynapad-base
#+end_src
*** file
#+name: &musl/dynapad-base
#+begin_src dockerfile :tangle ./musl/dynapad-base/Dockerfile
FROM tgbugs/musl:racket
<<&build-world-common>>
#+end_src

*** world
#+name: world-dynapad-base
#+begin_src conf :tangle ./musl/dynapad-base/world
<<world-racket>>
dev-libs/libconfig
sys-libs/db
dev-lang/tk
media-gfx/imagemagick
app-text/poppler
#+end_src
** dynapad-user
*** build
#+name: &musl-build-dynapad-user
#+begin_src bash
docker build \
--tag tgbugs/musl:dynapad-user \
--build-arg UID=${UID} \
--file musl/dynapad-user/Dockerfile musl/dynapad-user
#+end_src

*** file
#+name: &musl/dynapad-user
#+begin_src dockerfile :tangle ./musl/dynapad-user/Dockerfile
FROM tgbugs/musl:dynapad-base

COPY --from=tgbugs/musl:user / /

<<&musl-file-user-base>>
#+end_src

** dynapad
*** run
Once you have created the =tgbugs/musl:dynapad= image (see the build
section below) you can use this command to run it and commit on close
each time so as not to lose any work. You will probably want to mount
any additional directories you will need .e.g for images using =-v=.

**** linux
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:dynapad \
sh -c 'pushd ~/git/dynapad && racketcgc -it apps/paddraw/paddraw.rkt'

# docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src
**** macos
See [[#macos-notes][macos notes]] for notes on getting docker working
with XQuartz.  Assuming everything is set up correctly you can the run
the following.
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-e DISPLAY=host.docker.internal:0 \
-it tgbugs/musl:dynapad \
sh -c 'pushd ~/git/dynapad && racketcgc -it apps/paddraw/paddraw.rkt'

# docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src

#+begin_src bash
xattr -d -r -s com.apple.quarantine /Applications/Docker.app
#+end_src

*** build
Since we need to mount the git directory from outside the image we
can't use a docker file. Commit the image after these steps are
finished (the commands above do that automatically).

If your UID is something other than 1000 you will probably want to
rebuild =tgbugs/musl:dynapad-user= so that your UID matches.

#+begin_src bash
docker pull tgbugs/musl:dynapad-user

docker run \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-it tgbugs/musl:dynapad-user
docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src

In the image run the following and then exit, the commit will be made
automatically. *NOTE* You may need to remove =build_musl= if it
already exists.
#+begin_src bash
pushd ~/git/dynapad
    mkdir build_musl
    pushd build_musl
        cmake .. -G Ninja
        ninja
    popd
    SUBPATH=$(racketcgc -e "(display (path->string (system-library-subpath)))")
    SO_SUFFIX=$(racketcgc -e "(display (bytes->string/utf-8 (system-type 'so-suffix)))")
    mkdir -p dynapad/compiled/bc/native/${SUBPATH}
    racocgc ctool --cgc \
            ++ldf -Wl,-rpath,"${PWD}/build_musl/" \
            --ld dynapad/compiled/bc/native/${SUBPATH}/libdynapad_rkt${SO_SUFFIX} \
            "${PWD}/build_musl/libdynapad${SO_SUFFIX}"
    racocgc pkg install collects/ dynapad/
    racocgc make apps/paddraw/paddraw.rkt
    racocgc make apps/uberapp/uberapp.rkt
#+end_src

** sparcur
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:sparcur
#+end_src

*** build
#+name: &musl-build-sparcur
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:sparcur \
--file musl/sparcur/Dockerfile musl/sparcur
#+end_src

*** file
# when deriving from multiple parent worlds docker does not compose
# well at all, so we have to pick a primary world line so to speak
#+name: &musl/sparcur
#+begin_src dockerfile :tangle ./musl/sparcur/Dockerfile
FROM tgbugs/musl:emacs

<<&build-world-common>>

RUN \
eselect python set pypy3
#+end_src

*** world
# probably don't need pip anymore except for debug?
#+name: world-sparcur
#+begin_src conf :tangle ./musl/sparcur/world
dev-db/redis
net-misc/rabbitmq-server
dev-python/pip
dev-python/sparcur
#+end_src

** sparcur-user
*** run
# FIXME SIGH yes indeed chown modifies the parent system permissions
# somehow this doesn't surprise me given how janky docker is in here
To run as a daemon use =-d= option in then =docker ps= to get the
container id, and then =docker logs -f= the container.

Development =docker run= example.
#+begin_src screen
_f=$(basename ~/ni/dev/sparc-curation-*.json)
_h=protocols-io-api-token-rw.pickle
docker run \
-v /var/lib/sparc/files:/var/lib/sparc/files \
-v /var/lib/sparc/.local/share/sparcur:/var/lib/sparc/.local/share/sparcur \
-v /var/lib/sparc/.cache:/var/lib/sparc/.cache \
-v /var/lib/sparc/.config/sparcur/docker-config.yaml:/var/lib/sparc/.config/sparcur/config.yaml \
-v ~/ni/dev/secrets-sparcron.yaml:/var/lib/sparc/.config/orthauth/secrets.yaml \
-v ~/ni/dev/${_f}:/var/lib/sparc/.config/orthauth/${_f} \
-v ~/ni/dev/${_h}:/var/lib/sparc/.config/orthauth/${_h} \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-e SCIGRAPH_API=http://192.168.1.207:9000/scigraph \
-it tgbugs/musl:sparcur-user
#+end_src

Production =docker run= example. Must be run as root.
#+name: &run-sparcron
#+begin_src screen
function docker-run-sparcron () {
_f=$(su sparc -c 'basename /var/lib/sparc/.config/pyontutils/sparc-curation-*.json')
_h=protocols-io-api-token-rw.pickle
docker run \
-d \
-v /var/lib/sparc/files:/var/lib/sparc/files \
-v /var/lib/sparc/.local/share/sparcur:/var/lib/sparc/.local/share/sparcur \
-v /var/lib/sparc/.cache:/var/lib/sparc/.cache \
-v /var/lib/sparc/.config/sparcur/docker-config.yaml:/var/lib/sparc/.config/sparcur/config.yaml \
-v /var/lib/sparc/.config/pyontutils/secrets.yaml:/var/lib/sparc/.config/orthauth/secrets.yaml \
-v /var/lib/sparc/.config/pyontutils/${_f}:/var/lib/sparc/.config/orthauth/${_f} \
-v /var/lib/sparc/.config/pyontutils/${_h}:/var/lib/sparc/.config/orthauth/${_h} \
-e SCIGRAPH_API=https://scigraph.olympiangods.org/scigraph \
-it tgbugs/musl:sparcur-user
}
#+end_src

Production image upgrade.
#+begin_src bash
function upgrade-sparcron () {
_image=tgbugs/musl:sparcur-user
_image_date=$(date -I --date $(docker inspect ${_image} --format '{{.Created}}'))
_cid_old=$(docker ps -lqf ancestor=${_image})
docker tag ${_image} ${_image}-${_image_date}
docker pull ${_image}
docker stop ${_cid_old}
docker-run-sparcron
_cid_new=$(docker ps -lqf ancestor=${_image})
docker logs -f ${_cid_new}
}
#+end_src

*** build
#+name: &musl-build-sparcur-user
#+begin_src screen
docker build \
--tag tgbugs/musl:sparcur-user \
--file musl/sparcur-user/Dockerfile musl/sparcur-user
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/sparcur-user/Dockerfile
FROM tgbugs/musl:sparcur

ADD --chown=836:836 idlib-config.yaml /var/lib/sparc/.config/idlib/config.yaml
ADD --chown=836:836 sparcur-config.yaml /var/lib/sparc/.config/sparcur/config.yaml

ARG HOME=/var/lib/sparc

WORKDIR $HOME

ADD entrypoint.sh /etc/entrypoint.sh

ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** configs
This config provides sane defaults, if you need to add a section (such
as a =datasets-no:=) then use =-v= in docker run to mount over the
location of this file.
#+begin_src yaml :tangle ./musl/sparcur-user/sparcur-config.yaml
auth-stores:
  secrets:
    path: '{:user-config-path}/orthauth/secrets.yaml'
auth-variables:
  google-api-service-account-file-readonly:
    path: google api saro
  hypothesis-api-key: hypothesis api default-user
  hypothesis-group: hypothesis group sparc-curation
  remote-organization: N:organization:618e8dd9-f8d2-4dc4-9abb-c6aaab2e78a0
#+end_src

# TODO
#+begin_src yaml :tangle ./musl/sparcur-user/idlib-config.yaml
auth-stores:
  secrets:
    path: '{:user-config-path}/orthauth/secrets.yaml'
auth-variables:
  protocols-io-api-creds-file:
    path: protocols-io api creds-file
  protocols-io-api-store-file:
    path: protocols-io api store-file
#+end_src

*** entrypoint
# https://forums.gentoo.org/viewtopic-t-1014086-start-0.html
# sigh this really doesn't need the net admin cap just to start rabbit
Slowly inching toward being able to run this via a service manager.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/sparcur-user/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/redis start
/etc/init.d/rabbitmq start

# testing and ensure that there is an existing cache on first run
su sparc -c 'pypy3 -m sparcur.sparcron'

su sparc -c 'PYTHONBREAKPOINT=0 celery --app sparcur.sparcron worker -n wcron -Q cron,default --concurrency=1 --beat --schedule-filename ./sparcur-cron-schedule --loglevel=INFO' &

su sparc -c 'PYTHONBREAKPOINT=0 celery --app sparcur.sparcron worker -n wexport -Q export --loglevel=INFO'
# FIXME missing rmeta stuff ?

#/etc/init.d/redis stop
#/etc/init.d/rabbitmq stop
#+end_src

** protc
*** world
#+name: world-protc
#+begin_src conf
dev-libs/redland
#+end_src
* musl static
Same metadata as musl except with =static-libs= in order to produce
statically linked binaries.
** profile-static-x
*** build
#+name: &musl-build-profile-static-x
#+begin_src screen
docker build \
--tag tgbugs/musl:profile-static-x \
--file musl/profile-x/static.Dockerfile .
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/profile-x/static.Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD docker-profile/x/docker-profile var/db/docker-profile
ADD docker-profile/static/docker-profile var/db/docker-profile
ADD docker-profile/base/binrepos-multi.conf etc/portage/binrepos.conf/multi.conf

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src
** static-xorg
*** run
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ~/files/binpkgs/multi:/var/cache/binpkgs \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:static-xorg
#+end_src
*** build
#+name: &musl-build-static-xorg
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:static-xorg \
--build-arg PROFILE='docker-profile:tgbugs/musl/static/x' \
--build-arg PROFILE_IMAGE='tgbugs/musl:profile-static-x' \
--build-arg START_IMAGE='tgbugs/musl:updated' \
--file musl/xorg/Dockerfile musl/xorg
#+end_src
# --build-arg START_IMAGE='tgbugs/musl:xorg' \
** static-package-builder
*** populate 0
#+name: &musl-run-static-xorg-quickpkg
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v "$(pwd)"/bin/quickpkg-new:/tmp/quickpkg-new \
--rm \
tgbugs/musl:static-xorg \
/bin/sh -c 'quickpkg $(/tmp/quickpkg-new)'
#+end_src
*** run
#+begin_src bash
docker run tgbugs/musl:static-package-builder
docker commit $(docker ps -lq) tgbugs/musl:static-package-builder-snap

cat ./musl/package-builder/world | xargs \
docker run \
--volumes-from local-repos-snap \
--volumes-from cross-sbcl \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
tgbugs/musl:static-package-builder-snap \
emerge --color=y -j4 -q --keep-going -uDN

docker commit $(docker ps -lq) tgbugs/musl:static-package-builder-snap
#+end_src
# FIXME racket failing with mkostemp failures during raco make or
# something !? what the fuck?  how was this not caught before ?!
*** build
#+name: &musl-build-static-package-builder
#+begin_src screen
docker build \
--tag tgbugs/musl:static-package-builder \
--file musl/package-builder/static.Dockerfile musl/package-builder
#+end_src
*** file
#+begin_src dockerfile :tangle ./musl/package-builder/static.Dockerfile
FROM tgbugs/musl:static-xorg

<<&musl-package-builder-common>>
#+end_src
*** world
#+name: world-static-package-builder
#+begin_src conf :tangle ./musl/static-package-builder/world
<<world-sbcl>>
<<world-static-sbcl-c-libs>>
#+end_src

#+name: world-static-sbcl-c-libs
#+begin_src conf
dev-libs/openssl
dev-libs/gmp
dev-libs/capstone
dev-libs/mpfr
dev-libs/redland
#+end_src
** static-binpkg-only
*** build
#+name: &musl-build-static-binpkg-only
#+begin_src bash
docker build \
--tag tgbugs/musl:static-binpkg-only \
--file musl/binpkg-only/static.Dockerfile musl/binpkg-only
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/binpkg-only/static.Dockerfile
FROM tgbugs/musl:static-xorg
<<&musl-binpkg-only-common>>
#+end_src

** sbcl
*** build
#+name: &musl-build-sbcl
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:sbcl \
--file musl/sbcl/Dockerfile musl/sbcl
#+end_src
*** file
#+begin_src dockerfile :tangle ./musl/sbcl/Dockerfile
FROM tgbugs/musl:static-binpkg-only
<<&build-world-common>>
#+end_src
*** world
#+name: world-sbcl
#+begin_src conf :tangle ./musl/sbcl/world
<<world-emacs>>
dev-lisp/uiop
dev-lisp/asdf
dev-lisp/sbcl
#+end_src
** sbcl-user
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:sbcl-user
#+end_src

*** build
#+name: &musl-build-sbcl-user
#+begin_src screen
docker build \
--tag tgbugs/musl:sbcl-user \
--build-arg UID=${UID} \
--file musl/sbcl-user/Dockerfile musl/sbcl-user
#+end_src

*** file
# TODO emacs setup etc.
#+begin_src dockerfile :tangle ./musl/sbcl-user/Dockerfile
FROM tgbugs/musl:sbcl

COPY --from=tgbugs/musl:user / /

<<&musl-file-user-base>>
#+end_src

* gnu
may not need this if we can use crossdev to build glibc sbcl on musl that that seems a stretch
** profile
*** build
#+name: &gnu-build-profile
#+begin_src screen
docker build \
--tag tgbugs/gnu:profile \
--file gnu/profile/Dockerfile .
#+end_src

*** file
#+begin_src dockerfile :tangle ./gnu/profile/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

# we don't put this in var/db/repos because repos is managed via tgbugs/repos:latest
ADD docker-profile/base/docker-profile var/db/docker-profile
ADD docker-profile/base/docker-profile.conf etc/portage/repos.conf/docker-profile.conf
ADD docker-profile/base/binrepos-multi.conf etc/portage/binrepos.conf/multi.conf

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src
** eselect-repo
*** build
#+name: &gnu-build-eselect-repo
#+begin_src screen
docker build \
--tag tgbugs/gnu:eselect-repo \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/eselect-repo/Dockerfile gnu/eselect-repo
#+end_src

*** file
#+begin_src dockerfile :tangle ./gnu/eselect-repo/Dockerfile
FROM gentoo/stage3:hardened

<<&gentoo-file-eselect-repo-common-1>>

COPY --from=tgbugs/gnu:profile / /

<<&gentoo-file-eselect-repo-common-2>>

RUN \
eselect profile set docker-profile:tgbugs/gnu

<<&gentoo-file-eselect-repo-common-3>>
#+end_src

** sbcl-cross
*** run
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/gnu:sbcl-cross
#+end_src

Test that the cross compiled version is working as expected.
#+begin_src bash
docker run \
-it tgbugs/gnu:sbcl-cross \
/usr/x86_64-pc-linux-musl/usr/bin/sbcl --core /usr/x86_64-pc-linux-musl/usr/lib/sbcl/sbcl.core
#+end_src
*** build
#+begin_src screen
docker build \
--tag tgbugs/gnu:sbcl-cross \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/sbcl-cross/Dockerfile gnu/sbcl-cross
#+end_src
*** file
#+begin_src dockerfile :tangle ./gnu/sbcl-cross/Dockerfile
FROM tgbugs/gnu:eselect-repo

#emerge -j4 -q -uDN \  # yeahno
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   sys-devel/crossdev \
<<&archive-or-rm>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge --usepkg --getbinpkgonly \
   cross-x86_64-pc-linux-musl/musl \
   cross-x86_64-pc-linux-musl/linux-headers \
   cross-x86_64-pc-linux-musl/gcc \
   cross-x86_64-pc-linux-musl/binutils \
;  crossdev --stable --target x86_64-pc-linux-musl --stage4 \
<<&archive-or-rm>>

# sbcl crossdev build looks in the wrong place for asdf and uiop
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   dev-lisp/asdf \
   dev-lisp/uiop \
   dev-lisp/sbcl \
<<&archive-or-rm>>

ADD alt-ld.patch /etc/portage/patches/dev-lisp/sbcl/alt-ld.patch
ADD alt-ld.patch /usr/x86_64-pc-linux-musl/etc/portage/patches/dev-lisp/sbcl/alt-ld.patch
ADD 99-sbcl /usr/x86_64-pc-linux-musl/etc/portage/package.use/99-sbcl

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
x86_64-pc-linux-musl-emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   sys-libs/musl \
   sys-libs/zlib \
<<&archive-or-rm>>

RUN \
ln -s /usr/x86_64-pc-linux-musl/usr/lib/libc.so /lib/ld-musl-x86_64.so.1

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
x86_64-pc-linux-musl-emerge -j4 -q \
   dev-lisp/asdf \
   dev-lisp/uiop \
   dev-lisp/sbcl \
<<&archive-or-rm>>
#+end_src

Until we can figure out how to get the cross build to link this
correctly we leave it out.  We don't really need it since this build
is only for a bootstrapping sbcl on musl. There are native ways to do
this inside of the sbcl toolset itself, but for now this is easier.
# */* static-libs static
#+begin_src conf :tangle ./gnu/sbcl-cross/99-sbcl
dev-lisp/sbcl -zlib  # crossdev compile reference errors
#+end_src

#+begin_src diff :tangle ./gnu/sbcl-cross/alt-ld.patch
diff --git a/make-target-contrib.sh b/make-target-contrib.sh
index 217b5b2e0..45406f506 100755
--- a/make-target-contrib.sh
+++ b/make-target-contrib.sh
@@ -29,8 +29,12 @@ if [ -z "$CC" ]; then
     fi
 fi
 
+if [ -z "${LD}" ]; then
+    LD=ld
+fi
+
 unset EXTRA_CFLAGS # avoid any potential interference 
-export CC LANG LC_ALL
+export CC LD LANG LC_ALL
 
 # Load our build configuration
 . output/build-config
diff --git a/src/runtime/GNUmakefile b/src/runtime/GNUmakefile
index 0543c1244..284755e5c 100644
--- a/src/runtime/GNUmakefile
+++ b/src/runtime/GNUmakefile
@@ -24,7 +24,6 @@ SBCL_PAXCTL ?= :
 LINKFLAGS += -g
 DEPEND_FLAGS = -MM
 GREP = grep
-LD = ld
 
 # By default, don't make and use a library, just use the object files.
 LIBSBCL = $(OBJS)
#+end_src

#+begin_src bash
git clone https://github.com/sbcl/sbcl.git
pushd sbcl
git remote add daewok https://github.com/daewok/sbcl.git
git fetch daewok
git checkout daewok/static-executable
#+end_src

** musl/cross/sbcl
*** build
#+begin_src screen
docker build \
--tag tgbugs/musl:cross-sbcl \
--file musl/cross/sbcl/Dockerfile musl/cross/sbcl

docker rm cross-sbcl
docker create -v /sbcl --name cross-sbcl tgbugs/musl:cross-sbcl /bin/true
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/cross/sbcl/Dockerfile
FROM busybox:latest

WORKDIR /

COPY --from=tgbugs/gnu:sbcl-cross /usr/x86_64-pc-linux-musl/usr/lib/sbcl /sbcl
COPY --from=tgbugs/gnu:sbcl-cross /usr/x86_64-pc-linux-musl/usr/bin/sbcl /sbcl/src/runtime/sbcl

RUN \
mkdir -p /sbcl/obj/sbcl-home \
&& ln -s /sbcl/contrib /sbcl/obj/sbcl-home/contrib \
&& mkdir -p /sbcl/output \
&& ln -s /sbcl/sbcl.core /sbcl/output/sbcl.core

VOLUME /sbcl
#+end_src

* other
** alpine bootstrap
Barely working and incomplete bootstrap in alpine.
Might be useful for CI depending on how well the
tgbugs/musl:docker work progresses.

# this is cute but just git clone because there are a couple of legacy
# cases where git is needed in the host environment (unfortunately)
#+name: &aboot
#+begin_src elisp
(let ((u (pop argv)) (p (pop argv)) (enable-local-eval t)) (mkdir (file-name-directory p) t) (org-babel-do-load-languages 'org-babel-load-languages '((screen . t))) (url-handler-mode 1) (find-file u) (write-file p) (chmod p #o755) (find-file p) (org-sbe workflow))
#+end_src

#+begin_src screen
SHELL=/bin/bash screen -dmS org-session
# emacs -batch -eval "<<&aboot>>" https://raw.githubusercontent.com/tgbugs/dockerfiles/master/source.org ~/git/dockerfiles/source.org
#+end_src

# unfortunate for the builder mount ...
#+begin_src bash
docker run -v /var/run/docker.sock:/var/run/docker.sock -u ${UID} -it tgbugs/other:alpine-bootstrap
#+end_src

#+begin_src screen
<<&docker-build>>
--build-arg DUID=$(getent group docker | cut -d: -f3) \
--tag tgbugs/other:alpine-bootstrap \
--file other/alpine-bootstrap/Dockerfile other/alpine-bootstrap
#+end_src

#+begin_src dockerfile :tangle other/alpine-bootstrap/Dockerfile
FROM alpine:latest

ARG DUID=48

RUN  \
addgroup -g ${DUID} docker

RUN \
apk add bash docker emacs-nox git screen

ARG UID=1000
ARG USER_NAME=user

RUN \
addgroup -g ${UID} ${USER_NAME} \
&& adduser -HD -u ${UID} -G ${USER_NAME} ${USER_NAME} \
&& adduser ${USER_NAME} docker

USER $USER_NAME

WORKDIR /home/${USER_NAME}

RUN \
git clone https://github.com/tgbugs/dockerfiles.git

RUN \
dockerfiles/source.org setup

# RUN \
# mkdir -p ~/files/binpkgs/multi
#+end_src
** ubuntu-genera-base
*** file
#+begin_src dockerfile :tangle ./other/ubuntu-genera-base/Dockerfile
FROM ubuntu:18.04

RUN apt update

RUN apt install -y \
curl \
inetutils-inetd \
vim \
telnet \
nfs-common \
nfs-kernel-server \
iproute2 \
libx11-6 \
xserver-xephyr \
x11-xserver-utils \
iputils-ping
#+end_src

*** build
# docker pull ubuntu:18.04
# docker run -it ubuntu:18.04

#+begin_src bash
docker build \
--tag tgbugs/other:ubuntu-genera-base \
--file other/ubuntu-genera-base/Dockerfile other/ubuntu-genera-base
#+end_src

** genera
A docker file that specifies and image that can run Open Genera 2.0.

We can't distribute the final image for a variety of reasons, however
the configured base image can be distributed and is a valuable
resource as a result.

Useful as a starting point for debugging why it won't work on other systems.

Nearly everything is working except that docker and NFS exports seem
to be fighting with each other.  Old comments on the web mention
issues with exporting overlayfs mounts to NFS, but this commit from
2017 <https://patchwork.kernel.org/project/linux-fsdevel/patch/
1508258671-10800-15-git-send-email-amir73il@gmail.com/> seems to have
fixed that issue.

Three entry points.
https://www.reddit.com/r/lisp/comments/lhsltk/lisp_implementations_similiar_to_old_lisp_machines/
https://gist.github.com/oubiwann/1e7aadfc22e3ae908921aeaccf27e82d
https://archives.loomcom.com/genera/genera-install.html
*** exploration
This will eventually become a docker file, but right now it is still
too experimental so the workflow is run and commit rather than build.

#+begin_src bash
xhost local:docker

# NET_ADMIN apparently needed for tuntap creation (bsd jails and vnets looking really good right now)
# SYS_ADMIN apparently needed to get NFS exports to work (bsd jails looking even better!?)
# generally though this is ok because we are really only using this docker image as a way to get
# an environment where genera will run

docker run -it \
-v ~/files/tmp/genera:/files \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--device /dev/net/tun \
--cap-add NET_ADMIN \
--cap-add SYS_ADMIN \
tgbugs/other:ubuntu-genera-base
#+end_src

In the docker shell (will become the docker file or a script run in the docker file)
#+begin_src bash
#mkdir -p /dev/net
#mknod /dev/net/tun c 10 200

# tunnel creation
# ip tuntap delete dev tap0 mode tap  # to remove since it fights with the host
ip tuntap add dev tap0 mode tap
ip addr add 192.168.2.1/24 dev tap0
ip link set dev tap0 up

# inetd

echo "time      stream  tcp  nowait root internal" >> /etc/inetd.conf
echo "time      dgram   udp  wait   root internal" >> /etc/inetd.conf
echo "daytime   stream  tcp  nowait root internal" >> /etc/inetd.conf
echo "daytime   dgram   udp  wait   root internal" >> /etc/inetd.conf

service inetutils-inetd restart

# retrieve genera files TODO snapshot these to reduce redownload

mkdir genera
pushd genera
curl -LO https://archives.loomcom.com/genera/genera
chmod a+x genera
curl -L -O https://archives.loomcom.com/genera/worlds/Genera-8-5-xlib-patched.vlod
curl -L -O https://archives.loomcom.com/genera/worlds/VLM_debugger
curl -L -O https://archives.loomcom.com/genera/worlds/dot.VLM
mv dot.VLM .VLM
mkdir lib
pushd lib
curl -L -O https://archives.loomcom.com/genera/var_lib_symbolics.tar.gz
tar xvf var_lib_symbolics.tar.gz
chown -R root:root symbolics
ln -s /genera/lib/symbolics /var/lib/symbolics  # may fail
popd

sed -i 's,/home/seth,,' .VLM
echo "192.168.2.1    genera-vlm" >> /etc/hosts
echo "192.168.2.2    genera" >> /etc/hosts

# nfs XXX TODO broken

echo 'RPCNFSDCOUNT="--nfs-version 2 8"' >> /etc/default/nfs-kernel-server
echo 'RPCMOUNTDOPTS="--nfs-version 2 --manage-gids"' >> /etc/default/nfs-kernel-server
echo "/files genera(rw,sync,no_subtree_check,all_squash,anonuid=1000,anongid=1000)" >> /etc/exports
# we really want to export / but I'm seeing the following error
# exportfs: / does not support NFS export
#echo "/ genera(rw,sync,no_subtree_check,all_squash,anonuid=1000,anongid=1000)" >> /etc/exports

# I think rpcbind needs be be started, otherwise nfs-kernel-server may fail to start
# and/or NFS will not work at all
service rpcbind start

service nfs-kernel-server restart

# start genera using host X server

DISPLAY=:0.0; ./genera -coldloadgeometry 640x480+0+0 -geometry 1280x1024+0+0 &

# start genera using Xephyr (a bit more stable/predictable)

DISPLAY=:0.0; Xephyr -br -reset -terminate -ac -noreset -screen 1280x1024 :3 &
DISPLAY=:3.0; ./genera -coldloadgeometry 640x480+0+0 -geometry 1280x1024+0+0 &

#+end_src
* sckan
=base= must be built before =services=, obvious from errors or from
reading the docker files but doesn't jump out and is the inverse of
the order of specification (because services is rebuilt more
frequently).
** save
To save a gzipped archive run
#+name: &sckan-save-image
#+begin_src bash
# first run the following to find the latest build, then
docker image ls tgbugs/sckan:data-*
_datetime=$(docker image ls tgbugs/sckan:data-* | sort | tail -n 1 | awk '{ print $2 }')
docker save tgbugs/sckan:${_datetime} | gzip > /tmp/docker-sckan-${_datetime}.tar.gz
#+end_src

To restore from the archive run
#+begin_src bash
docker load --input sckan-data-2021-09-30T232453Z.tar.gz
#+end_src
** services
This combines the raw (data) base image with prefixes.conf and services.yaml.
Note that the image names for these are shifted so that they don't confuse users.
The logic is that base + services = data, but users don't know anything about services.
*** container
Test this with tgbugs/musl:kg-release-user
#+begin_src bash
docker container inspect sckan-data > /dev/null && \
docker rm sckan-data
docker create -v /var/lib/blazegraph -v /var/lib/scigraph --name sckan-data tgbugs/sckan:latest /bin/true
#+end_src

*** build
#+name: &musl-build-sckan-services
#+begin_src screen
mkdir -p ./sckan/services/blazegraph

[ -d ./sckan/services/scigraph ] && rm -r ./sckan/services/scigraph
mkdir -p ./sckan/services/scigraph

pushd ./sckan/services

# blazegraph
_sckanl="$(ls -d /tmp/build/release-*-sckan | sort -u | tail -n 1)"
rsync -a ${_sckanl}/data/prefixes.conf blazegraph/

# scigraph
~/git/pyontutils/nifstd/scigraph/bin/run-build-services-sparc
rsync -a /tmp/scigraph-build/sparc/services.yaml scigraph/
rsync -a /tmp/scigraph-build/sparc/$(head -n 1 scigraph/services.yaml | cut -b3-) scigraph/

popd

docker build \
--tag tgbugs/sckan:data-$(date --utc +%Y-%m-%dT%H%M%SZ) \
--tag tgbugs/sckan:latest \
--file sckan/services/Dockerfile sckan/services
#+end_src

*** file
#+begin_src dockerfile :tangle ./sckan/services/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD --chown=834:834 blazegraph/ /build/var/lib/blazegraph
ADD --chown=835:835 scigraph/ /build/var/lib/scigraph

FROM tgbugs/sckan:base-latest
COPY --from=builder /build /
#+end_src

** base
*** build
# TODO release snapshots for these images

# FIXME scigraph log folder ownership is still fucked after all these years ffs
#+name: &musl-build-sckan-base
#+begin_src screen
mkdir -p ./sckan/base/blazegraph

[ -d ./sckan/base/scigraph ] && rm -r ./sckan/base/scigraph
mkdir -p ./sckan/base/scigraph

pushd ./sckan/base

_sckanl="$(ls -d /tmp/build/release-*-sckan | sort -u | tail -n 1)"
rsync -a ${_sckanl}/data/blazegraph.jnl blazegraph/

# TODO run-load-graph-sparc-sckan
_zip=$(realpath /tmp/scigraph-build/sparc-sckan/LATEST)
_path="${_zip%.*}"
_scigr="${_path##*/}"
rsync -a ${_path} scigraph/
ln -s /var/lib/scigraph/${_scigr} scigraph/graph

popd

docker build \
--tag tgbugs/sckan:base-$(date --utc +%Y-%m-%dT%H%M%SZ) \
--tag tgbugs/sckan:base-latest \
--file sckan/base/Dockerfile sckan/base
#+end_src

*** file
# /build/sckan/ this could include the provenance data, but I think we should probably leave it out?
# TODO also consider splitting blazegraph and scigraph volume images ?
# TODO have a version of this that does the builds itself instead of just copying everything in
#+begin_src dockerfile :tangle ./sckan/base/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD --chown=834:834 blazegraph/ /build/var/lib/blazegraph
ADD --chown=835:835 scigraph/ /build/var/lib/scigraph

FROM scratch
COPY --from=builder /build /
#+end_src

* utils :noexport:
# FIXME --network host is ok for now, but we should probably try to
# switch to using --ssh or something since it is needed for building
# all binpkg-only images
#+name: &docker-build
#+begin_src bash
docker build \
--network host \
--add-host local.binhost:127.0.0.1 \
#+end_src

#+name: &build-world
#+begin_src dockerfile
FROM tgbugs/musl:binpkg-only
<<&build-world-common>>
#+end_src

#+name: &build-world-nox
#+begin_src dockerfile
FROM tgbugs/musl:binpkg-only-nox
<<&build-world-common>>
#+end_src

#+name: &build-world-common
#+begin_src dockerfile

ARG ARCHIVE

ADD world /var/lib/portage/world

# -ebuild locks is so much faster building acct-* ebuilds first is MUCH faster
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
FEATURES=ebuild-locks emerge -1 -j4 -q -uDN $(cat /var/lib/portage/world | xargs emerge -p | grep -o 'acct-.\+$' | sed 's/^/=/') \
;  cat /var/lib/portage/world | xargs emerge -j4 -q -uDN \
<<&archive-or-rm>>
#+end_src

#+name: &archive-or-rm
#+begin_src dockerfile
;  export CODE=$? \
;  echo CODE $CODE \
;  [[ -n ${ARCHIVE} ]] \
|| { rm -r /var/cache/distfiles/* > /dev/null 2>&1 \
   ; rm -r /var/cache/binpkgs/* > /dev/null 2>&1; } \
;  exit $CODE
#+end_src

A build helper for use during development when you need to add
packages you forgot but don't want to rebuild the whole world.
#+name: &build-helper-temp
#+begin_src dockerfile
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN \
#+end_src
* Bootstrap :noexport:

#+name: orgstrap
#+begin_src elisp :results none :lexical yes :noweb yes
(defvar-local refresh      nil)
(defvar-local repos        nil)
(defvar-local sync-gentoo  nil)
(defvar-local resnap       nil)
(defvar-local live-rebuild nil)
(defvar-local no-pkg-bldr  nil)

(defvar-local path-distfiles (expand-file-name "<<&host-distfiles-path()>>"))
(defvar-local path-binpkgs-root (expand-file-name "<<&host-binpkgs-root-path()>>")) ; FIXME multi
(defvar-local path-binpkgs (concat path-binpkgs-root "/" "<<&host-binpkgs-repo-name()>>"))
(defvar-local path-distcc-hosts (expand-file-name "<<&host-distcc-hosts-path()>>"))
(defvar-local path-ssh (expand-file-name "<<&host-ssh-path()>>"))
; FIXME should we only mount the key itself to avoid config issues internally ? probably yes ? also known_hosts issues, the docker build ssh-agent doesn't really help here

(defun make-screen-vars ()
  (apply #'format
         "export _refresh=%s _repos=%s _sync_gentoo=%s _resnap=%s _live_rebuild=%s _nopkgbldr=%s \\
_path_distfiles=%S _path_binpkgs_root=%S _path_binpkgs=%S _path_distcc_hosts=%S _path_ssh=%S;"
         (append
          (mapcar (lambda (b) (if b 1 ""))
                  (list refresh repos sync-gentoo resnap live-rebuild no-pkg-bldr))
          (list path-distfiles path-binpkgs-root path-binpkgs path-distcc-hosts path-ssh))))

(defun run-setup ()
;; docker daemon config ; XXX this can't be done due to bad design of docker (investigate podman)
;; docker client config
;;  remote repo key
;; binpkgs path
;; portage ssh keys
;; distcc hosts file
(make-directory)
)

(defun fix-ocbe ()
  "it would seem that blanking `enable-local-eval' resets this"
  (setq-local
   org-confirm-babel-evaluate
   (lambda (lang body)
     (not (or (and (member lang '("elisp" "emacs-lisp"))
                   (or (string= body "value")
                       (string= body "(make-screen-vars)")))
              (and (member lang '("screen"))
                   (string= (cl-subseq body 0 15) "export _refresh")))))))

(defun dedupe-lines (blockname)
  (let* ((info (save-excursion
                 (org-save-outline-visibility 'use-markers
                   (let ((obs (org-babel-find-named-block blockname)))
                     (if obs (goto-char obs)
                       (error "No block named %s" blockname)))
                   (org-babel-get-src-block-info))))
         (body (org-babel--expand-body info)))
    (string-join (sort (cl-remove-duplicates
                        (split-string body "\n")
                        :test #'string=)
                       #'string<)
                 "\n")))

(fix-ocbe)

(when noninteractive
  (let ((setup (member "setup" argv))
        (build (member "build" argv))
        (tangle (member "tangle" argv)))
    (let ((no-screen    (and build (member "--no-screen" argv)))
          (refresh      (and build (member "--refresh" argv)))
          (repos        (and build (member "--repos" argv)))
          (sync-gentoo  (and build (member "--sync-gentoo" argv)))
          (resnap       (and build (member "--resnap" argv)))
          (live-rebuild (and build (member "--live-rebuild" argv)))
          (no-pkg-bldr  (and build (member "--no-pkg-bldr" argv))))
      (setq argv nil)
      (when setup
        (run-setup))
      (when build
        ;; either use bash internally here (bad) or try to use screen
        ;; currently going with screen since we have a hack for passing vars
        ;;(message "build:\n%s" (make-screen-vars))
        (org-babel-do-load-languages
         'org-babel-load-languages
         '((screen . t)
           (shell . t)))
        ;; check that setup was run correctly, if not, fail
        ;; start screen
        ;; start up the packages server
        ;; run build
        ;; TODO block until build finishes or fails
        (fix-ocbe)
        (save-excursion ; can't use org-sbe because it calls some other random block !?
          (org-babel-goto-named-src-block "workflow-cli")
          (org-babel-execute-src-block)))
      (when tangle
        (unless (fboundp #'dockerfile-mode)
          (define-derived-mode dockerfile-mode prog-mode "Dockerfile"
            "Stub to avoid comment-start issues"
            (set (make-local-variable 'comment-start) "#")))
        (let (enable-local-eval)
          ;; this pattern is required when tangling to avoid infinite loops
          (revert-buffer nil t nil)
          (setq-local find-file-literally nil))
        (fix-ocbe)
        (org-babel-tangle)))))
#+end_src

Helper block to make it easier to use elisp functions as noweb inputs.
#+name: ident
#+begin_src elisp :var value=""
value
#+end_src

Helper blocks to pass variables to screen from cli.
#+name: &screen-pass-vars
#+begin_src elisp
(make-screen-vars)
#+end_src

Note that all screen blocks have an implicit eval.
#+name: &screen-set-vars
#+begin_src screen
<<&screen-pass-vars()>>
#+end_src
** Local Variables :ARCHIVE:
# close powershell comment #>
# Local Variables:
# eval: (progn (setq-local orgstrap-min-org-version "8.2.10") (let ((actual (org-version)) (need orgstrap-min-org-version)) (or (fboundp #'orgstrap--confirm-eval) (not need) (string< need actual) (string= need actual) (error "Your Org is too old! %s < %s" actual need))) (defun orgstrap-norm-func--prp-1\.1 (body) (let (print-quoted print-length print-level) (prin1-to-string (read (concat "(progn\n" body "\n)"))))) (unless (boundp 'orgstrap-norm-func) (defvar orgstrap-norm-func orgstrap-norm-func-name)) (defun orgstrap-norm-embd (body) (funcall orgstrap-norm-func body)) (unless (fboundp #'orgstrap-norm) (defalias 'orgstrap-norm #'orgstrap-norm-embd)) (defun orgstrap-org-src-coderef-regexp (_fmt &optional label) (let ((fmt org-coderef-label-format)) (format "\\([:blank:]*\\(%s\\)[:blank:]*\\)$" (replace-regexp-in-string "%s" (if label (regexp-quote label) "\\([-a-zA-Z0-9_][-a-zA-Z0-9_ ]*\\)") (regexp-quote fmt) nil t)))) (unless (fboundp #'org-src-coderef-regexp) (defalias 'org-src-coderef-regexp #'orgstrap-org-src-coderef-regexp)) (defun orgstrap--expand-body (info) (let ((coderef (nth 6 info)) (expand (if (org-babel-noweb-p (nth 2 info) :eval) (org-babel-expand-noweb-references info) (nth 1 info)))) (if (not coderef) expand (replace-regexp-in-string (org-src-coderef-regexp coderef) "" expand nil nil 1)))) (defun orgstrap--confirm-eval-portable (lang _body) (not (and (member lang '("elisp" "emacs-lisp")) (let* ((body (orgstrap--expand-body (org-babel-get-src-block-info))) (body-normalized (orgstrap-norm body)) (content-checksum (intern (secure-hash orgstrap-cypher body-normalized)))) (eq orgstrap-block-checksum content-checksum))))) (unless (fboundp #'orgstrap--confirm-eval) (defalias 'orgstrap--confirm-eval #'orgstrap--confirm-eval-portable)) (let (enable-local-eval) (vc-find-file-hook)) (let ((obs (org-babel-find-named-block "orgstrap"))) (if obs (unwind-protect (save-excursion (setq-local orgstrap-norm-func orgstrap-norm-func-name) (setq-local org-confirm-babel-evaluate #'orgstrap--confirm-eval) (goto-char obs) (org-babel-execute-src-block)) (org-set-startup-visibility)) (warn "No orgstrap block."))))
# End:
