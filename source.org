# -*- orgstrap-cypher: sha256; orgstrap-norm-func-name: orgstrap-norm-func--dprp-1-0; orgstrap-block-checksum: cfd996247cf8665c7dbc72b71c00ec97f4a97155bdf09f8e9b94b1cc158aff2f; -*-
# [[orgstrap][jump to the orgstrap block for this file]]
#+title: Literate source for docker files

#+property: header-args :eval no-export
#+property: header-args:bash :var BUILDKIT_PROGRESS="plain"
#+property: header-args:conf :mkdirp yes :noweb yes
#+property: header-args:dockerfile :noweb yes :mkdirp yes :comments link
#+property: header-args:screen :session org-session :cmd sh :noweb no-export

#+name: orgstrap-shebang
#+begin_src bash :eval never :results none :exports none
set -e "-C" "-e" "-e"
{ null=/dev/null;} > "${null:=/dev/null}"
{ args=;file=;MyInvocation=;__p=$(mktemp -d);touch ${__p}/=;chmod +x ${__p}/=;__op=$PATH;PATH=${__p}:$PATH;} > "${null}"
$file = $MyInvocation.MyCommand.Source
{ file=$0;PATH=$__op;rm ${__p}/=;rmdir ${__p};} > "${null}"
emacs -batch -no-site-file -eval "(let (vc-follow-symlinks) (defun orgstrap--confirm-eval (l _) (not (memq (intern l) '(elisp emacs-lisp)))) (let ((file (pop argv)) enable-local-variables) (find-file-literally file) (end-of-line) (when (eq (char-before) ?\^m) (let ((coding-system-for-read 'utf-8)) (revert-buffer nil t t)))) (let ((enable-local-eval t) (enable-local-variables :all) (major-mode 'org-mode)) (require 'org) (org-set-regexps-and-options) (hack-local-variables)))" "${file}" -- ${args} "${@}"
exit
<# powershell open
#+end_src

* Setup
** Server
*** docker config
Docker files in this repo use buildkit features. To enable it include
the following in [[/etc/docker/daemon.json]].
#+name: docker-daemon-config
#+begin_src json :tangle /etc/docker/daemon.json :tangle no
{"experimental": true,
 "features": {"buildkit": true}}
#+end_src
*** portage ssh keys
Make sure that =/var/lib/portage/home/.ssh= exists and has the keys
for accessing the interlex repo or other private repos.
*** distcc hosts
Even if you are not using distcc be sure to run
#+begin_src bash
touch /etc/distcc/hosts.docker
#+end_src
on the host os otherwise the builder functions will produce cryptic
errors for some packages because they can handle an absent
/etc/distcc/hosts file but not one that is a directory. Note that
docker has what might be considered a reasonable default which is that
it will create a directory if it does not exist when it is the source
of a mount rather than fail ... but in our case this is annoying, and
the cleanup is a pita, have to unmount and rmdir in the image, or just
resnap the image because wow what a pain.

** Client
Building the precursor images in =gentoo/stage3= for this repo from
[[https://github.com/gentoo/gentoo-docker-images][scratch]] requires the =buildx= extension which requires experimental
features to be enabled in the client.

If you want to push the images to a remote docker repository add the
auths section as well (and fill it in with your credentials).
#+name: docker-client-config
#+begin_src json :tangle ~/.docker/config.json :tangle no
{"experimental": "enabled",
 "auths": {
   "https://index.docker.io/v1/": {
     "auth": "XXX NOT A REAL KEY FILL ME IN XXX"}}}
#+end_src

** Package host
Prepare package host folders. The server will be started automatically
below if it is not already up.
#+begin_src screen
mkdir -p ~/files/binpkgs/multi
mkdir -p ~/files/binpkgs/cross/gnu/x86_64-pc-linux-musl
mkdir -p ~/files/binpkgs/cross/gnu/x86_64-gentoo-linux-musl
#+end_src
*** prepare all binpkg repos
We have to prepare all the binpkg repos so that during a first build
they have some basic metadata, otherwise trying to emerge binpkgs will
fail with strange errors in strange ways.
#+name: &run-quickpkg-first-time
#+begin_src screen
for stage3 in {hardened,amd64-musl-hardened}; do
    docker pull gentoo/stage3:${stage3}
    docker run \
    -v ~/files/binpkgs/multi:/var/cache/binpkgs \
    -e FEATURES=binpkg-multi-instance \
    -e QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022" \
    --rm \
    gentoo/stage3:${stage3} \
    quickpkg "virtual/ssh";
done
#+end_src

** Portage git ssh access
Needed for live ebuilds that point to private git repos.
Eventually this should be baked into the docker in docker top level image.

You will need to generate ssh keys for the host system if they do not
already exist, and you will need to register them with the git remote.

This is similar to what we do for [[#portage-maven][portage-maven]].

The default location for the portage home directory is now
=/var/lib/portage/home/.ssh= which means that the ssh config and
private keys can be stored there persistently and safely without
violating the sandbox during package fetch.

In the even that you have to deal with some strange legacy case you
may want to symlink a path outside the sandbox to a path inside the
sandbox due to the change in home directory from =/var/tmp/portage= ->
=/var/lib/portage/home=. Inside the images we have to run
=ln -s /var/tmp/portage/.ssh /var/lib/portage/home/.ssh=.

If =/var/tmp/portage= is still the portage home folder and it is a
ramdisk that is wiped on reboot you will want the following.
#+begin_src bash :tangle /su::/etc/local.d/20portage-symlinks.start :tangle-mode 0755 :tangle no
# relink .ssh across restarts
ln -s /mnt/str/portage/.ssh /var/tmp/portage/
chown -h portage:portage /var/tmp/portage/.ssh
#+end_src

#+begin_src bash
runuser -u portage -- ssh -T git@github.com
#+end_src

** git ignore
This takes care of itself.
#+begin_src conf :tangle .gitignore
.gitignore
docker-profile/*
repos/*
musl/*
gnu/*
other/*
sckan/*
bin/*
helper-repos/*
#+end_src
* Ops
** CLI
The standard way to use this file to build is to run the following block
WARNING: never run this command from inside the =org-session= screen, input
will be severely broken
#+begin_src bash
./source.org build --refresh --repos --resnap --live-rebuild
#+end_src
** Build
If you are bootstrapping this file from scratch you will need to build
dependent images in order.

To prepare a fresh cycle of images.
# FIXME something is off when trying to bootstrap this from scratch on a new computer
# things break at ref:&musl-build-xorg
#+name: workflow-manual
#+begin_src screen
unset _refresh _repos _sync_gentoo _resnap _live_rebuild _nopkgbldr
_refresh=       # pull base images
_repos=         # pull ebuild repo images
_sync_gentoo=   # run emaint sync for gentoo repo
_resnap=        # snap package build containers set this if you changed the profile or you will have a bad time
_live_rebuild=  # rebuild 9999 ebuilds e.g. from git
_nopkgbldr=     # do not run package building steps
_only_static=   # only build static images

<<&workflow-vars>>
<<&workflow-common>>
#+end_src

#+name: &workflow-vars
#+begin_src bash
# XXX NOTE that these are embedded in the docker files right now
_img_portage=${_img_portage:-gentoo/portage:latest}

_musl_img_stage3=${_musl_img_stage3:-gentoo/stage3:amd64-musl-hardened}

__is3_0=${_img_stage3/\//-}
__is3_1=${__is3_0/:/-}
__src_from_img=${__is3_1/gentoo/latest}
_musl_src_stage3=${__src_stage3:-${__src_from_img}}
unset __is3_0 __is3_1 __src_from_img

_gnu_img_stage3=${_gnu_img_stage3:-gentoo/stage3:amd64-hardened-openrc}

# FIXME DRY
__is3_0=${_gnu_img_stage3/\//-}
__is3_1=${__is3_0/:/-}
__src_from_img=${__is3_1/gentoo/latest}
_gnu_src_stage3=${__gnu_src_stage3:-${__src_from_img}}
unset __is3_0 __is3_1 __src_from_img
#+end_src

#+name: workflow-cli
#+begin_src screen
HISTFILE=~/.org_session_history
<<&screen-set-vars>>
<<&workflow-vars>>
<<&workflow-common>>
#+end_src

Source =./bin/workflow-funs.sh= on changes after tangle.
#+name: &workflow-funs-main-to-tangle
#+begin_src bash :tangle ./bin/workflow-funs.sh :mkdirp yes :noweb yes :var BUILDKIT_PROGRESS=""
<<&workflow-funs>>
<<&workflow-main>>
#+end_src

Note that we can't =source ./bin/workflow-funs.sh= in this context
because tangle is called inside =run-main=. We would need to rework
the call order so that tangle is run first or unify the elisp and bash
tangle code.
#+name: &workflow-common
#+begin_src screen
<<&workflow-funs>>
<<&workflow-main>>
run-main
#+end_src

#+name: &workflow-main
#+begin_src screen
function run-main () {
package-server || return $?
pull musl
pull gnu
pushd ~/git/dockerfiles  # FIXME hardcoded path
tangle && {
  # FIXME popd sigh ... unwind-protect when
  run-profile || return $?
  run-common || return $?
  run-gnu || return $?
  run-musl || return $?
}
# package host
# build a bunch of packages
popd
}
#+end_src

# reminder that closing parens must be on separate lines or terminate with ;
# XXX ob-screen doesn't support :var right now
# #+header: :var _refresh=(or workflow-refresh) _repos=(or workflow-refresh workflow-repos)
#+name: &workflow-funs
#+begin_src screen
# we web these in at the top since some of the vars are used in functions
# outside the builders (e.g. package-server)

<<&builder-vars>>

function package-server () {
# FIXME needs to run in another terminal, container, or daemon
# but for now it blocks other commands which is ok
curl --fail --head http://localhost:8089/${_binpkgs_repo_name}/Packages || {
    _error=$?
    # curl returns a 22 if the server is up but there is some other issue e.g. 404
    # that we might hit during first run when the repo doesn't exist
    if [ ${_error} -ne 22 ]; then
        pushd ${_path_binpkgs_root}
        python -m http.server 8089 --bind 127.0.0.1
        popd
        return 1  # indicate that package server was not and now is not running
    fi
}
}

function pull () {
# FIXME abstract _src_stage3 and _img_stage3 for gnu vs musl
local _src_stage3 _img_stage3
if [ "${1}" == "gnu" ]; then
    _src_stage3=${_gnu_src_stage3}
    _img_stage3=${_gnu_img_stage3}
elif [ "${1}" == "musl" ]; then
    _src_stage3=${_musl_src_stage3}
    _img_stage3=${_musl_img_stage3}
else
    echo unknown libc "${1}"
    return 1
fi
# echo src img ${_src_stage3} ${_img_stage3}
if [ -n "${_refresh}" ]; then  # FIXME implicit global variable when it is hard to set the variable in some contexts :/
    # even when refresh is set avoid spurious pulls where the underlying stage3 has not changed
    local DIST="https://distfiles.gentoo.org/releases/amd64/autobuilds"
    local STAGE3_LATEST="$(curl --fail --silent "${DIST}/${_src_stage3}.txt" |\
        tail -n 1 | cut -f 1 -d'/' | sed -r 's/(....)(..)(..)T(..)(..)(..)/\1-\2-\3T\4:\5:\6/')"
    local LOCDOC_LATEST="$(docker image inspect ${_img_stage3} --format '{{.Created}}' || date --utc +%Y-%m-%dT%H:%M:%SZ --date @0)"
    local S3_DATE=$(date -In --utc --date "${STAGE3_LATEST}")
    local LD_DATE=$(date -In --utc --date "${LOCDOC_LATEST}")
    # XXX there is technically a narrow window between the release of
    # a stage3 and the building of a docker image where this might fail
    # have to use double square brackets for this to work correctly
    [[ ${S3_DATE} < ${LD_DATE} ]] || \
    docker pull ${_img_stage3}
fi

# TODO make pull-portage its own function to avoid rerun?
if [ -n "${_refresh}" ] || [ -n "${_repos}" ]; then
    # these are updated more or less in sync with the upstream snapshot source
    local BEFORE="$(docker image inspect ${_img_portage} --format '{{.Created}}' || date --utc +%Y-%m-%dT%H:%M:%SZ --date @0)"
    docker pull ${_img_portage}
    local AFTER="$(docker image inspect ${_img_portage} --format '{{.Created}}' || date --utc +%Y-%m-%dT%H:%M:%SZ --date @0)"
    local A_DATE=$(date -In --utc --date "${AFTER}")
    local B_DATE=$(date -In --utc --date "${BEFORE}")
    { [[ ${B_DATE} < ${A_DATE} ]] || { docker container inspect local-portage-snap > /dev/null && false;};} && {
    docker rm local-portage-snap
    docker create -v /var/db/repos/gentoo --name local-portage-snap ${_img_portage} /bin/true
    }
fi
}

function tangle () {
[ -d ./bin ] && rm -r ./bin
[ -d ./docker-profile ] && rm -r ./docker-profile
[ -d ./common ] && rm -r ./common
[ -d ./gnu ] && rm -r ./gnu
[ -d ./musl ] && rm -r ./musl
[ -d ./repos ] && rm -r ./repos
[ -d ./other ] && rm -r ./other
./source.org tangle
return $?
}

<<&container-check>>

<<&quickpkg-image>>

<<&builder-resnap>>

<<&builder-bootstrap>>

<<&builder-world>>

<<&builder-arb>>

<<&builder-arb-priv>>

<<&builder-debug>>

<<&cross-bootstrap-sbcl>>

function run-profile () {
<<&build-profile-base>> || return $?;
<<&build-profile-gnu>> || return $?;
<<&build-profile-musl>> || return $?;
<<&build-profile-x>> || return $?;
<<&build-profile-nox>> || return $?;
<<&build-profile-pypy3>> || return $?;
<<&build-profile-static>> || return $?;
}

function run-common () {
local REPOS="${_repos}"
<<&build-user>> || return $?;
<<&build-portage-maven>> || return $?;

# we build both eselect repos images in common because the output is
# usable in common ideally we will be able to get rid of a continually
# rebuilt image and move to a rolling image for all the repos as we
# shift away from using docker build and toward running containers
<<&gnu-build-eselect-repo>> || return $?
<<&musl-build-eselect-repo>> || return $?;
  [ -z $REPOS ] || {
  <<&repos-build-repos>> || return $?;
  docker container inspect local-repos-snap > /dev/null &&
  docker rm local-repos-snap;
  docker create -v /var/db/repos --name local-repos-snap tgbugs/repos:latest /bin/true || return $?;
  echo repos done;
  }

}

function run-gnu () {
local REPOS="${_repos}"
local SYNC_GENTOO="${_sync_gentoo}"
local RESNAP="${_resnap}"
local LIVE_REBUILD="${_live_rebuild}"
local NOBUILD="${_nopkgbldr}"
local ONLY_STATIC="${_only_static}"
echo gnu start bootstrap
gnu-container-check
<<&gnu-build-package-builder>> || return $?
<<&gnu-run-package-builder-quickpkg>> || return $?
echo gnu builder start
[ -z $RESNAP ] || gnu-builder-resnap
# FIXME this is where BINPKG_FORMAT is not set correctly
[ ! -z $NOBUILD ] || gnu-builder-bootstrap
[ ! -z $NOBUILD ] || gnu-builder-world
[ ! -z $NOBUILD ] || gnu-cross-musl-sbcl
}

function run-musl () {
local REPOS="${_repos}"
local SYNC_GENTOO="${_sync_gentoo}"
local RESNAP="${_resnap}"
local LIVE_REBUILD="${_live_rebuild}"
local NOBUILD="${_nopkgbldr}"
local ONLY_STATIC="${_only_static}"

echo musl start bootstrap
# TODO figure out how to build the binary packages at this stage without
# so that we don't have to wait for quickpkg?
container-check
<<&musl-build-updated>> || return $?; echo mbu;
  <<&musl-build-updated-user>> || return $?; echo mbuu;
  <<&musl-run-updated-quickpkg>> || return $?; echo mruq;

  # build the generalized builder so we can dispense with the stacked image nonsense
  <<&musl-build-package-builder-musl>> || return $?; echo mbpbm;

  # TODO conditional to speed things up
  # <<&musl-run-free-harf-nonsense>> || return $?; echo mrfhn;

  <<&musl-build-nox>> || return $?; echo mbnox;
  <<&musl-run-nox-quickpkg>> || return $?; echo mrnoxq;

  <<&musl-build-openjdk-nox>> || return $?; echo mbnoxjdk;
    <<&musl-run-openjdk-nox-quickpkg>> || return $?; echo mrnoxjdkq;

  <<&musl-build-package-builder-nox>> || return $?; echo mbpbn;
  <<&musl-build-binpkg-only-nox>> || return $?; echo mbbon;

  <<&musl-build-pypy3>> || return $?; echo mbpypy3;
    <<&musl-run-pypy3-quickpkg>> || return $?; echo mrpypy3q;

    # XXX this is the point at which things split into musl and musl/x
    <<&musl-build-xorg>> || return $?; echo mbx;
    <<&musl-run-xorg-quickpkg>> || return $?; echo mrxq;

    <<&musl-build-openjdk>> || return $?; echo mbjdk;
      <<&musl-run-openjdk-quickpkg>> || return $?; echo mrjdkq;

    <<&musl-build-package-builder>> || return $?; echo mbpb;
    <<&musl-build-binpkg-only>> || return $?; echo mbpo;

    # XXX split to musl/static/x
    <<&musl-build-static-xorg>> || return $?; echo mbsx;
    <<&musl-run-static-xorg-quickpkg>> || return $?; echo mrsxp;

    <<&musl-build-static-package-builder>> || return $?; echo mbspb;
    <<&musl-build-static-binpkg-only>> || return $?; echo mbsbo;

# TODO need to conditionally run the gnu builds for sbcl cross compile
# TODO also need to have a working ghc around, probably stick it in a release

if [ -z $ONLY_STATIC ]; then

# TODO build any new packages
echo musl builder start
[ -z $RESNAP ] || builder-resnap
# FIXME autodetect the --no-build case
[ ! -z $NOBUILD ] || builder-bootstrap || return $?
[ ! -z $NOBUILD ] || musl-bootstrap-sbcl || return $?
# FIXME this needs to run with --getbinpkg
[ ! -z $NOBUILD ] || \
<<&musl-run-build-need-priv>>
[ ! -z $NOBUILD ] || builder-world || return $?
# TODO smart-live-rebuild
[ -z $LIVE_REBUILD ] || builder-smart-live-rebuild || return $?

fi

echo musl static builder start
[ -z $RESNAP ] || static-builder-resnap
# TODO static-builder-bootstrap
# TODO see if we need to musl-bootstrap-sbcl here too
# FIXME static-builder-world fails but static-builder-debug running the same works? with @world and _then_ @docker?
[ ! -z $NOBUILD ] || static-builder-world || return $?  # FIXME if this is not run once at the start then something fails above
[ -z $LIVE_REBUILD ] || static-builder-smart-live-rebuild || return $?  # no live builds right now


echo musl nox builder start
[ -z $RESNAP ] || nox-builder-resnap
# TODO nox-builder-bootstrap
# FIXME static-builder-world fails but static-builder-debug running the same works? with @world and _then_ @docker?
[ ! -z $NOBUILD ] || nox-builder-world || return $?  # FIXME if this is not run once at the start then something fails above
# [ -z $LIVE_REBUILD ] || nox-builder-smart-live-rebuild || return $?  # no live builds right now

# TODO consider whether we need to rebuild baselayout openrc sgml-common due to config issues with quickpkg

# image builds

echo start static image builds

## sbcl
<<&musl-build-sbcl>> || return $?; echo mbsbcl;
<<&musl-build-sbcl-user>> || return $?; echo mbsbclu;

if [ -z $ONLY_STATIC ]; then

echo start image builds

## emacs
<<&musl-build-emacs>> || return $?; echo mbe;  # XXX fail on stale profile is very confusing

## kg
<<&musl-build-kg-release>> || return $?; echo mbkgr;
<<&musl-build-kg-release-user>> || return $?; echo mbkgru;
<<&musl-build-kg-dev>> || return $?; echo mbkgd;
<<&musl-build-kg-dev-user>> || return $?; echo mbkgdu;

## services
<<&musl-build-blazegraph>> || return $?; echo mbb;

## sbcl
<<&musl-build-sbcl>> || return $?; echo mbsbcl;
<<&musl-build-sbcl-user>> || return $?; echo mbsbclu;

## racket
<<&musl-build-racket>> || return $?; echo mbrac;
<<&musl-build-racket-user>> || return $?; echo mbracu;

## dynapad
<<&musl-build-dynapad-base>> || return $?; echo mbdb;
<<&musl-build-dynapad-user>> || return $?; echo mbdbu;
#<<&musl-build-dynapad>> || return $?; # needs to be done by hand

## NIF-ontology
<<&musl-build-protege>> || return $?; echo mbp;
<<&musl-build-NIF-ontology>> || return $?; echo mbno;

## interlex
<<&musl-build-interlex>> || return $?; echo mbilx;

## sparcron
<<&musl-build-sparcron>> || return $?; echo mbsp;
<<&musl-build-sparcron-user>> || return $?; echo mbspu;

fi

}
#+end_src

# I am an idiot, the repos image is being build incorrectly and pulls
# in the local images so it overrides. DUH.

#+begin_src screen
<<&musl-run-updated-user>>
#+end_src
** Debug build
*** failures
Sometimes a build will fail.
As long as you aren't using buildkit features such as mount you can
rerun a build command with ~DOCKER_BUILDKIT=0~ prepended which will
keep the intermediate containers around so you can attach to the last
known good layer and try to run things yourself.

Alternately, it may be a better approach to simply truncate the docker
file directly after the last known good step
*** binpkg quirks
Sometimes may have to rebuild individual packages when they depend on a specific slot
e.g. python depending on libffi:0/7 instead of libffi:0/8, you have to rebuild python
and produce a new package that works with libffi:0/8, for some reason portage doesn't
do it by itself? Possibly missing =--with-bdeps=y= or something?
** Push
To push the latest cycle of images to the default remote run the
following after checking that they work as expected.

# FIXME the --filter=since= isn't quite right, I think it can miss some images we want to push? not entirely sure?
#+begin_src bash
for _image in $(docker images \
--filter=reference="tgbugs/musl:*" \
--filter=since='tgbugs/musl:eselect-repo' \
--format "{{.Repository}}:{{.Tag}}" | grep -v snap);
do
    echo docker push "${_image};\\"
done
#+end_src

Other things images we don't push right now.
#+begin_src bash
--filter=reference="tgbugs/repos:*" \
--filter=reference="tgbugs/common:*" \
--filter=reference="tgbugs/gnu:*" \
--filter=reference="tgbugs/docker-profile:*" \
#+end_src

DO NOT PUSH directly to =tgbugs/repos:latest= because there is currently
no way to prevent docker build from pulling an ancient and outdated repo
during bootstrap if one does not already exist.

** Emergency quickpkg
Sometimes you don't want to wait to get to the package builder step
because there is some bug in between.
#+name: &docker-quickpkg
#+begin_src bash
function docker-quickpkg () {
# FIXME TODO pass the image to package
docker run \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-e FEATURES=binpkg-multi-instance \
-e QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022" \
--rm \
tgbugs/musl:static-xorg \
quickpkg \
${@}
}
#+end_src
** Cleanup
#+name: &docker-cleanup
#+begin_src screen
docker container prune --force
docker volume    prune --force
docker image     prune --force
docker builder   prune --force
#+end_src
** package maint
sometimes you might have a case where a package gets renamed and
the old package keeps getting pulled in the solution is as follows
(example was for setuptools_scm when it was renamed to setuptools-scm)
it might be possible with the new gpkg format to rewrite the embedded metadata
but for now doing a full rebuild is guaranteed safe
# consider eclean packages ??? no, it doesn't do what we want, emaint movebin is much closer
#+begin_src bash
function clean-moved-deps () {
pushd /var/cache/binpkgs
local _pkgname
_pkgname=${1}
echo ${_pkgname}
echo rm $(grep -ral ${_pkgname} --include='*.xpak' --include='*.gpkg.tar')
echo emaint binhost
# make sure it looks right
echo emaint binhost --fix
echo emaint movebin
echo emaint movebin --fix
popd
}
#+end_src
* Default variables
Default variable values that will eventually have cli overrides.
# At the moment I'm not going to implement full command line processing via ow-cli.
#+name: &host-binpkgs-root-path
: ~/files/binpkgs

NOTE: we will not be making the repo name configurable, it only
appears to be for implementation convenience.
#+name: &host-binpkgs-repo-name
: multi

#+name: &host-distfiles-path
: /mnt/str/portage/distfiles

#+name: &host-distcc-hosts-path
: /etc/distcc/hosts.docker

#+name: &host-ssh-path
: /var/lib/portage/home/.ssh

#+name: &helper-repos
: helper-repos
# FIXME grrrr the need to be able to set these computationally
# passed via the command line means that we have to descend into elisp
# or we have to have a oneshot self modifying configuration command
# which is also bad because it breaks version control

# ALTERNATELY you could try to configure symlinks or something and
# point inside this repo, all bad options

# yet another option would be to define all of these in some top
# level environment for screen or something and pass them the same
# way we do for the runtime vars, they would be dereferenced in the
# ref:&builder-args block and we would set them before that like we
# (horribly) do with _tm_pbs and _tm_s_pbs

# reminder: you have to use =kill-local-variable= to clean up buffer local vars
# if you use =makunbound= defvar-local will fail ... and even then there are issues
# so sometimes you just have to kill and reopen the buffer (sigh)
* Next
** TODO proper process for consistent behavior in nearly all conditions
for the builder track it seems that sequential updates starting from
stage3 and running uDN world or similar for each profile are likely to
be the simplest to understand and the least likely to fall into weird
stage3 vs portage mismatch issues

there are some obstacles due to bugs/current behavior in portage which
make building bdeps only a bit tricky (e.g. when switching profiles)
if we want to run the normal build process with binpkgonly to avoid
accumulating many installed packages in the image

1. builder for stage3 with local-portage-snap update world, a tiny bit of rework here
2. git and eselect repo
3. repos
4. profiles
5. iterate through profiles and build/update everything

then to compose images start from ... ??? for the binpkgonly
** TODO meta packages instead of world files
Proper factoring for this system suggests that we should probably be
maintaining these world files as meta ebuilds in an overlay so that
the process in this file can remain mostly static and we just name the
meta package that we want to build for a particular use case. It
should be much easier to maintain and reduce the overall complexity of
what is going on in this file.
** TODO live builder
since we have the world list it likely makes sense to do an hourly
poll of the github repo or something and pull down the latest changes
check for changes to any of the installed packages and build the new
packages so that we don't have to wait to detect errors, the tool
chains are more than robust enough to support these kinds of use cases
basically put the builder to work during the week, and taking the
subsets for particular use cases is hardly an issue at that point the
living image does start to get bloated though, so the weekly rebuild
can help, this should cut down big time on issues with e.g. rust
taking stupid amounts of time to build, drive it all of the sparse (in
time) changes that maintainers make
** TODO podman
:PROPERTIES:
:CREATED:  [2022-08-26 Fri 16:09]
:END:
better than dind
need to investigate LVM because podman requires it and I don't use it on my systems
https://wiki.gentoo.org/wiki/LVM
** TODO ebuilds changing behind the scenes
:PROPERTIES:
:CREATED:  [2022-03-21 Mon 20:50]
:END:
so it turns out that it is possible to change an ebuild, rebuild the package
and .. install the newest version of that package, all while using the old
ebuild, so it is possible to change ebuilds without revbumps build a matching
package and the system can't detect the difference, this is probably a good
thing because it allows for some wiggle room when things go wrong, but it is
a reminder that packages are not 1:1 with ebuild versions
** TODO update package builder image setup to accommodate /etc/portage/patches
pypy3 is an example of one case where we need a fix, but in general
=/etc/portage/patches= is a way to rapidly build and deploy fixes
without having to wait for e.g. a full pull request cycle to finish.
** DONE catch errors in profile early
** TODO dind or similar for top level ops
Docker is not homogeneous with regard to nesting containers since the
way that we use it is a bit outside the usual use case (and because
docker is a hack and true nesting reveals this by violating a whole
bunch of assumptions that are baked into the implementation).

As a result, a hack is required to be able to fake nesting. In this
case the simplest approach seems to be to make the ur-host's docker
process accessible to the top level ops container. Not truly
homogeneous, but better than nothing. This is done by mounting the
socket for the docker daemon when you run the top level build image.

Since this is a build process security considerations are identical
for the true host and the top level image. If we weren't running in
the top level image we would be running on the true host directly so
sandboxing is irrelevant.

An example approach would be to run something like the following.
#+begin_src bash
docker run -v /var/run/docker.sock:/var/run/docker.sock tgbugs/musl:docker
#+end_src

** DONE a better way
The primary issue here is that it really is not safe to compose after
merge because the power and flexibility of portage happen before
merge, and are quite state dependent after the fact. The key then is
to be able to create images that do compose well, and the only at
the very end materialize them by installing all the packages at once.

The problem is that you give up the utility of the docker layers, but
if we are installing binary packages that have been built on a
separate system then we know that we won't encounter build errors.

The final obstacle to full composability in this way is the issue of
incompatible use flags, but I think it is safe to say that it is not
really possible to solve that problem.

This consideration suggests that the layers of docker images, while
useful, are fundamentally at odds with composability when there are
files inside images that track state (e.g. =/var/lib/portage/world=).

** DONE condense use flags
At the moment we keep use flags with packages and try to keep them
mostly orthogonal to each other. However, at a certain point it is
going to be easier to maintain a single shared use flag image that
will be synchronized across all images. Granular control is nice from
a learning and minimal specification point of view, but from an
engineering an maintenance point of view it is vastly easier easier to
maintain a single shared use flag image that will be synchronized
across all images. Granular control is nice from a learning and
minimal specification point of view, but from an engineering an
maintenance point of view it is simpler to unify the individual image
environments into a single file.
** DONE create an image to build packages
Rebuilding images is wasteful when nothing has changed, and packages
and install properly to maintain the correct state of the image. While
=COPY --from= works, it mangles things like =/var/lib/portage/world=,
and if use flags were changed on a dependency by another source image
then unusual and unexpected errors could occur. This is another reason
to move to manage use flags one or two images, one image for cases
where X11 is not needed, and another where it is.

In fact, I'm fairly certain that having a shared use flag environment
is necessary for it to be possible to safely compose packages and
images. Composition across environments requires something like nix
where each package carries around its own environment. It might be
possible to do better than this by allowing composition in cases where
the environments are compatible, but that would still require
computation at composition time, you can't just layer images an expect
things to work.

alternately mount =/var/cache/binpkgs= and then run quickpkg or
something devious like that
** TODO separate user image
Should be able to =COPY --from=tgbugs/common:user= across all images.
build the user image from a base that has next to nothing in it
add the user and group to the system and then copy that minimal
user stuff in, most of the time there isn't any fancy installation
that needed to be done, and we could just copy the user directory
when building from scratch
* docker-profile
** base
The right way to do this is to create two custom profiles on top of musl-hardened.

https://wiki.gentoo.org/wiki/Profile_(Portage)#custom

Modifications to use flags and other system settings and
configurations that are easier to keep in a single location.
# FIXME this may need to be versioned, or we just force rebuild on all
# the images from scratch which we often have to do anyway, though some
# packages may not be affect by profile changes
*** build
#+name: &build-profile-base
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:base \
--file docker-profile/base/Dockerfile .
#+end_src

*** file
# FIXME split these out so they go in their own images and don't cause global rebuilds
#+name: &profile-adds
#+begin_src dockerfile
# we don't put this in var/db/repos because repos is managed via tgbugs/repos:latest
ARG bp=docker-profile/base/

ADD ${bp}docker-profile                          var/db/docker-profile
ADD ${bp}docker-profile.conf                     etc/portage/repos.conf/docker-profile.conf
ADD ${bp}binrepos-multi.conf                     etc/portage/binrepos.conf/multi.conf
ADD ${bp}package.accept_keywords                 etc/portage/package.accept_keywords/profile
ADD ${bp}package.mask                            etc/portage/package.mask/profile
ADD ${bp}package.unmask                          etc/portage/package.unmask/profile
ADD ${bp}emacs.env                               etc/portage/env/app-editors/emacs
ADD ${bp}erlang.env                              etc/portage/env/dev-lang/erlang
ADD ${bp}rabbitmq.env                            etc/portage/env/net-misc/rabbitmq-server
ADD ${bp}no-distcc.env                           etc/portage/env/no-distcc
ADD ${bp}package.env                             etc/portage/package.env/profile
ADD ${bp}musl-find_library.patch                 etc/portage/patches/dev-lang/python:2.7/musl-find_library.patch
ADD ${bp}musl-include-sys-time.patch             etc/portage/patches/dev-python/pypy3_x-exe/musl-include-sys-time.patch
ADD ${bp}musl-fix-stdio-defs.patch               etc/portage/patches/dev-python/pypy3_x-exe/musl-fix-stdio-defs.patch
ADD ${bp}pypy3-json-str-subclass-safety.patch    etc/portage/patches/dev-python/pypy3_x/json-str-subclass-safety.patch
ADD ${bp}patchelf-musl-no-dt-mips-xhash.patch    etc/portage/patches/dev-util/patchelf/patchelf-musl-no-dt-mips-xhash.patch
#+end_src

#+begin_src dockerfile :tangle ./docker-profile/base/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

<<&profile-adds>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

*** etc
**** repos.conf
#+begin_src conf :tangle ./docker-profile/base/docker-profile.conf
[docker-profile]
location = /var/db/docker-profile
#+end_src
**** binrepos.conf
#+begin_src conf :tangle ./docker-profile/base/binrepos-multi.conf
[tgbugs-multi]
priority = 100
sync-uri = http://local.binhost:8089/multi
#+end_src
**** package.accept_keywords
#+begin_src conf :tangle ./docker-profile/base/package.accept_keywords
dev-python/*::tgbugs-overlay
dev-scheme/racket::tgbugs-overlay
dev-haskell/*::tgbugs-overlay **
dev-haskell/*::haskell
dev-haskell/*::gentoo
dev-lang/ghc::gentoo
app-text/pandoc::gentoo
app-admin/haskell-updater::gentoo
dev-util/shellcheck::gentoo
#+end_src
# and they say haskell is a safe language
**** package.mask
#+begin_src conf :tangle ./docker-profile/base/package.mask
dev-scheme/racket::gentoo
dev-haskell/*::haskell
>=dev-lang/rust-1.66  # cc issue https://bugs.gentoo.org/888936
>=dev-lang/rust-bin-1.66
>=virtual/rust-1.66
dev-java/openjdk-bin  # libc linking issues, must compile openjdk
<virtual/jdk-17
<virtual/jre-17
#+end_src
**** package.unmask
#+begin_src conf :tangle ./docker-profile/base/package.unmask
dev-haskell/fgl::haskell
dev-haskell/graphviz::haskell
dev-haskell/hxt-charproperties::haskell
dev-haskell/hxt-regex-xmlschema::haskell
dev-haskell/hxt-unicode::haskell
dev-haskell/hxt::haskell
dev-haskell/polyparse::haskell
dev-haskell/wl-pprint-text::haskell
#+end_src
**** env
***** no distcc
# TODO MAKEOPTS_LOCAL
# FIXME "${FEATURES} -distcc" vs "-distcc" behavior?
# I think they stack without variables with priority going global package runtime environment
#+begin_src conf :tangle ./docker-profile/base/no-distcc.env
FEATURES="-distcc"
#+end_src
***** app-editors/emacs
#+begin_src conf :tangle ./docker-profile/base/emacs.env
NATIVE_FULL_AOT=1
#+end_src
***** dev-lang/erlang
https://bugs.gentoo.org/857099
https://github.com/OpenRC/openrc/blob/master/service-script-guide.md#be-wary-of-need-net-dependencies
#+begin_src conf :tangle ./docker-profile/base/erlang.env
post_src_install() { sed -i '/need/d' "${D}"/etc/init.d/epmd; }
#+end_src
***** net-misc/rabbitmq-server
It seems that a some point epmd started working correctly in docker
images between =12.3.1= and =12.3.2.2=, therefore rabbitmq can't start
its own empd and fails to connect. This removes the depend statement
in the init file that pulls in system epmd, which if started will
cause rabbitmq to fail to start. The correct solution is to figure out
how to correctly configure rabbitmq, but for now this should restore
the old behavior.
#+begin_src conf :tangle ./docker-profile/base/rabbitmq.env
post_src_install() { sed -i '/need/d' "${D}"/etc/init.d/rabbitmq; }
#+end_src
**** package.env
# some continusing nonsense, a manual build in builder-debug is somehow different enough that it works?
# XXX manually setting FEATURES=-distcc worked, but it seems that stacking features in make.conf doesn't?
#+begin_src conf :tangle ./docker-profile/base/package.env
dev-python/pypy3 no-distcc
dev-util/cmake no-distcc
dev-util/colm no-distcc
# cases where the issue disappears in builder-debug
dev-util/lapack no-distcc
dev-python/numpy no-distcc
dev-scheme/racket no-distcc  # somehow cc to compile zuo is broken and produces a segfault
#+end_src
*** profiles
#+begin_src conf :tangle ./docker-profile/base/docker-profile/metadata/layout.conf
masters = gentoo
profile-formats = portage-2
#+end_src

#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/repo_name
docker-profile
#+end_src

# NOTE that tgbugs/musl/x is listed here but not populated until later
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/profiles.desc
amd64 tgbugs                 dev
amd64 tgbugs/x               dev
amd64 tgbugs/nox             dev
amd64 tgbugs/pypy3           dev
amd64 tgbugs/static          dev

amd64 tgbugs/gnu             dev
amd64 tgbugs/gnu/x           dev
amd64 tgbugs/gnu/nox         dev

amd64 tgbugs/musl            dev
amd64 tgbugs/musl/x          dev
amd64 tgbugs/musl/nox        dev

amd64 tgbugs/musl/static     dev
amd64 tgbugs/musl/static/x   dev
amd64 tgbugs/musl/static/nox dev

amd64 tgbugs/musl/pypy3      dev
amd64 tgbugs/musl/pypy3/x    dev
amd64 tgbugs/musl/pypy3/nox  dev
#+end_src
**** packages
Useful to keep these out of file:/var/lib/portage/world so that individual
docker files can just =ADD= their world file and then =emerge @world=. It
also makes it much easier for the package builder to operate based on world files.
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/packages
*dev-vcs/git
*app-eselect/eselect-repository
#+end_src
**** make.defaults
# old, we use INSTALL_MASK for simplicity
#+begin_comment
See warning about https://wiki.gentoo.org/wiki/Localization/Guide#LINGUAS.
We are safe here because this base profile is shared between all our
systems and because we do not redistribute the binary packages.

We restrict =LINGUAS= here to reduce the size of the images that are
produced.  Larger images with localization enabled can be produced by
removing the restriction, but are not included by default. This
approach is likely better than using =INSTALL_MASK=.
#+end_comment

# USE="-doc"
# LINGUAS="en"
# for some reason empty video cards does not actually disable all the flags

# NOTE: the hardened profile sets USE=-cli and USE=-jit and some other stuff
# that changes behavior [[/usr/portage/profiles/features/hardened/make.defaults]]

Normally we don't set =USE== in make.conf, however there is no way to set
global use flags in a profile without doing so.
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/make.defaults
INSTALL_MASK="${INSTALL_MASK}
/usr/share/locale
-/usr/share/locale/en
-/usr/share/locale/en@boldquot
-/usr/share/locale/en@quot
-/usr/share/locale/en@shaw
-/usr/share/locale/en_US"

BINPKG_FORMAT="gpkg"
BINPKG_COMPRESS="zstd"
BINPKG_COMPRESS_FLAGS_ZSTD="--ultra -22"

FEATURES="${FEATURES} binpkg-multi-instance"

EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --binpkg-respect-use=y"  # FIXME portageq shows bru opt twice ??

# icu is needed due to musl collation issues
# jemalloc can improve performance re issues with musl allocator
USE="${USE} icu jemalloc"

USE="${USE} -gstreamer"

VIDEO_CARDS="-*"

# ensure that packages are readable by other users via umask 022
# use unmodified config in case a config file is modified, configs
# should never wind up modified when using package builder images
# see https://bugs.gentoo.org/307455 for more
# FIXME XXX current issues include
# /etc/hosts -> sys-apps/baselayout
# /etc/rc.conf -> sys-apps/openrc
# /etc/sgml/catalog -> app-text/sgml-common
# which seem to have been modified by other merges
QUICKPKG_DEFAULT_OPTS="--include-unmodified-config=y --umask=022"

ACCT_GROUP_BLAZEGRAPH_ID=834
ACCT_USER_BLAZEGRAPH_ID="${ACCT_GROUP_BLAZEGRAPH_ID}"

ACCT_GROUP_SCIGRAPH_ID=835
ACCT_USER_SCIGRAPH_ID="${ACCT_GROUP_SCIGRAPH_ID}"

ACCT_GROUP_SPARC_ID=836
ACCT_USER_SPARC_ID="${ACCT_GROUP_SPARC_ID}"

ACCT_GROUP_PROTCUR_ID=837
ACCT_USER_PROTCUR_ID="${ACCT_GROUP_PROTCUR_ID}"

ACCT_GROUP_SCIBOT_ID=838
ACCT_USER_SCIBOT_ID="${ACCT_GROUP_SCIBOT_ID}"

ACCT_GROUP_INTERLEX_ID=839
ACCT_USER_INTERLEX_ID="${ACCT_GROUP_INTERLEX_ID}"

ACCT_GROUP_NIFSTD_TOOLS_ID=840
ACCT_USER_NIFSTD_TOOLS_ID="${ACCT_GROUP_NIFSTD_TOOLS_ID}"

ACCT_GROUP_METABASE_ID=841
ACCT_USER_METABASE_ID="${ACCT_GROUP_METABASE_ID}"

EGIT_OVERRIDE_REPO_SCIGRAPH_SCIGRAPH=https://github.com/SciCrunch/SciGraph.git
EGIT_OVERRIDE_BRANCH_SCIGRAPH_SCIGRAPH=jvm-17

# temporary commit override until the converter fixes are merged
EGIT_OVERRIDE_BRANCH_OPEN_PHYSIOLOGY_OPEN_PHYSIOLOGY_VIEWER=fix-wrapper
#+end_src

# FIXME the ACCT_ and EGIT_OVERRIDE_ should probably be in env, but we rebuild
# this profile so frequently I think putting it in make.defaults is probably ok

**** mask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.mask
# dynapad
>=media-gfx/imagemagick-7
#+end_src
**** unmask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.unmask
# gtknor
<gnome-base/librsvg-2.41
dev-python/dicttoxml
#+end_src
**** accept_keywords
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.accept_keywords
dev-python/pipenv ~amd64
app-misc/yq ~amd64

# harfbuzz 3.1.2 needs freetype-2.11.1 otherwise build fails
=media-libs/freetype-2.11.1 ~amd64

# tgbugs-overlay
dev-db/blazegraph-bin ~amd64
dev-db/pguri **
dev-java/robot-bin ~amd64
dev-java/scigraph-bin ~amd64
dev-node/apinat-converter **
#dev-scheme/racket ~amd64  # profile can't restrict by repo :(

# tgbugs-overlay python
dev-python/interlex **
dev-python/sparcur **

# sparcur
app-text/xlsx2csv ~amd64
dev-python/semver ~amd64

# gtknor
<gnome-base/librsvg-2.41 **

# emacs
app-emacs/vterm ~amd64
app-emacs/zmq ~amd64

# sbcl
dev-lisp/asdf ~amd64
dev-lisp/uiop ~amd64
dev-lisp/sbcl ~amd64

# pypy3
dev-python/pypy3-exe ~amd64
dev-python/pypy3 ~amd64
dev-python/pypy3_10-exe ~amd64
dev-python/pypy3_10 ~amd64
#+end_src
# probably have to put dev-python/*::tgbugs-overlay in /etc/portage/package.accept_keywords/profile
# dev-python/pyontutils ~amd64
# XXX if we introduce pypy3 this is going to be a mess

# interesting issue with dev-python/interlex ** nominally being completely
# irrelevant and orthognal to the rest of the contstraints on other images
# that will never install it, it technically triggers a rebuild of everything
# because we make the profile a dependency, we mitigate this by using binpkgs
# but really we should be able to put things like this in the package builder
# image and snapshot and then only in the docker files that will actually
# install that package itself ... hrm ... unfortunately that is WAY harder
# for someone to understand and track than it is to stick it in here and
# rebuild everything ... sigh, eventually we will implement this optimization
**** package.use
# TODO consider dev-db/sqlite secure-delete
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/package.use
# setpriv command
sys-apps/util-linux caps

# font rendering
media-libs/freetype -cleartype-hinting -cleartype_hinting

# reduce deps
dev-libs/uriparser -doc

# needed to ensure that -egl doesn't introduce conflicts
x11-base/xorg-server minimal

app-editors/emacs dynamic-loading gmp json threads

# gdb don't pull in the world
sys-devel/gdb -nls -python

# pyzmq
net-libs/zeromq drafts
dev-python/pyzmq drafts

dev-scheme/racket cs bc cgc jit

# graphviz
media-libs/gd truetype fontconfig

# pypy3
dev-python/pypy3-exe jit
dev-python/pypy3 sqlite
dev-python/pypy3_10-exe jit
dev-python/pypy3_10 sqlite

# uwsgi needs at least one backend enabled
www-servers/uwsgi python

# needed for matplotlib apparently
media-gfx/imagemagick jpeg tiff
virtual/imagemagick-tools jpeg tiff
dev-python/pillow webp

# keep ipykernel deps minimal for emacs-jupyter
dev-python/ipython -smp

# needed for scipy
dev-python/numpy lapack

# tgbugs-overlay added the stats keyword to avoid scipy but it works on pypy3 now
dev-python/seaborn stats

# tgbugs-overlay python
app-arch/brotli python  # needed by aiohttp by elasticsearch-py
dev-python/interlex alt database
dev-python/orthauth yaml
dev-python/pint babel uncertainties
dev-python/sparcur cron  # XXX FIXME not all images want to pull in the cron deps, or the dashboard deps
dev-python/sxpyr -cli  # XXX FIXME avoid circular dep on clifun
#+end_src

**** use.mask
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/use.mask
# reduce deps
perl
gtk
cups
postscript

# reduce xorg deps
llvm
egl
gles2
gallium
dbus
vala
introspection
elogind

# allow pypy3 as a python target
-python_targets_pypy3
#+end_src
**** x/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/x/parent
..
#+end_src
**** nox/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/nox/parent
..
#+end_src
**** pypy3/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/pypy3/parent
..
#+end_src
**** static/
intentionally empty
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/static/parent
..
#+end_src
**** gnu/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/parent
gentoo:default/linux/amd64/17.1/hardened
..
#+end_src
**** gnu/x/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/x/parent
..
../../x
#+end_src
**** gnu/nox/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/gnu/nox/parent
..
../../nox
#+end_src
**** musl/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/parent
gentoo:default/linux/amd64/17.0/musl/hardened
..
#+end_src
**** musl/x/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/x/parent
..
../../x
#+end_src
**** musl/nox/
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/nox/parent
..
../../nox
#+end_src
**** musl/pypy3
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/pypy3/parent
..
../../pypy3
#+end_src
**** musl/pypy3/x
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/pypy3/x/parent
..
../../../x
#+end_src
**** musl/pypy3/nox
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/pypy3/nox/parent
..
../../../nox
#+end_src
**** musl/static
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/parent
..
../../static
#+end_src
**** musl/static/x
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/x/parent
..
../../../x
#+end_src
**** musl/static/nox
***** parent
#+begin_src conf :tangle ./docker-profile/base/docker-profile/profiles/tgbugs/musl/static/nox/parent
..
../../../nox
#+end_src
** musl
TODO separate musl and gnu specific stuff
*** build
#+name: &build-profile-musl
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:musl \
--build-arg PROFILE_AXIS=musl \
--file docker-profile/axes.Dockerfile .
#+end_src
*** file
#+begin_src dockerfile :tangle ./docker-profile/axes.Dockerfile
FROM busybox:latest as builder

ARG PROFILE_AXIS=x

WORKDIR /build

ADD docker-profile/${PROFILE_AXIS}/docker-profile var/db/docker-profile

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src
*** profiles
**** package.use
#+begin_src conf :tangle ./docker-profile/musl/docker-profile/profiles/tgbugs/musl/package.use
dev-lang/ghc ghcbootstrap
#+end_src
**** package.use.force
We have a cross compile bootstrap and the clisp build is broken.
Have to use =package.use.force= because the main gentoo musl profile sets it there.

This is no longer needed because we can emerge cross compiled packages
directly and don't have to do the image side loading dance anymore.
#+begin_src conf :tangle ./docker-profile/musl/docker-profile/profiles/tgbugs/musl/package.use.force :tangle no
dev-lisp/sbcl -system-bootstrap
#+end_src
**** package.unmask
#+begin_src conf :tangle ./docker-profile/musl/docker-profile/profiles/tgbugs/musl/package.unmask
dev-lisp/sbcl
#+end_src
** gnu
TODO need the gnu specific tweaks
*** build
#+name: &build-profile-gnu
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:gnu \
--build-arg PROFILE_AXIS=gnu \
--file docker-profile/axes.Dockerfile .
#+end_src
*** profiles
**** keep
FIXME temp until there is actually a gnu specific file to mkdirp on
#+begin_src conf :tangle ./docker-profile/gnu/docker-profile/profiles/tgbugs/gnu/.keep :mkdirp yes
#+end_src
** x
*** build
#+name: &build-profile-x
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:x \
--build-arg PROFILE_AXIS=x \
--file docker-profile/axes.Dockerfile .
#+end_src
*** profiles
**** parent
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/parent
..
#+end_src
**** packages
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/packages
*media-fonts/dejavu
*media-libs/fontconfig
*media-libs/freetype
#+end_src
**** make.defaults
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/make.defaults
USE="${USE} X"
VIDEO_CARDS="-*"
#+end_src
**** package.use
# we might consider including svg and libxml2 because they are already pulled in by racket and some other components
# app-editors/emacs libxml2 svg
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.use
# ,*/* X # FIXME it seems that wildcards are not allowed in here so for now has to be done later

media-libs/freetype harfbuzz

# the mesa ebuilds in the main tree are missing the fact that
# gbm expects egl to be enabled, if it is not build errors
media-libs/mesa -gbm

app-editors/emacs gui jpeg png Xaw3d xft # XXX note that latest reccomendations are to use harfbuzz + cairo for text shaping (or something like that)
app-emacs/emacs-common gui

# avoid extra deps
dev-util/cmake -ncurses

# scigraph
x11-base/xorg-server xvfb

# xdg-utils build time dep pulled in by cups somehow
app-text/xmlto text
#+end_src

**** mask
# Looks like the mesa issue has been fixed.
# The media-libs/mesa-21.1 set fails to build even with all the use flags set correctly.
# Same issue with media-libs/mesa-21.1 https://bugs.gentoo.org/828491. Currently 21.2.6
# is the only one that will compile correctly.
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.mask
#+end_src
**** accept_keywords
#+begin_src conf :tangle ./docker-profile/x/docker-profile/profiles/tgbugs/x/package.accept_keywords
#+end_src
** nox
Explicit nox profile.
*** build
#+name: &build-profile-nox
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:nox \
--build-arg PROFILE_AXIS=nox \
--file docker-profile/axes.Dockerfile .
#+end_src
*** file
*** profiles
**** parent
FIXME see if we actually need this, I think we might due to klobbering by =COPY=?
#+begin_src conf :tangle ./docker-profile/nox/docker-profile/profiles/tgbugs/nox/parent :tangle no
..
#+end_src

**** package.use
#+begin_src conf :tangle ./docker-profile/nox/docker-profile/profiles/tgbugs/nox/package.use
dev-java/icedtea headless-awt
dev-java/openjdk headless-awt
dev-java/openjdk-bin headless-awt
virtual/jdk headless-awt
#+end_src

** pypy3
*** build
#+name: &build-profile-pypy3
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:pypy3 \
--build-arg PROFILE_AXIS=pypy3 \
--file docker-profile/axes.Dockerfile .
#+end_src
*** file
#+begin_src dockerfile
#+end_src
*** profiles
**** package.use
FIXME this is almost certainly not going to produce what we want
because =+pypy3= doesn't just append to existing in the same way that
=-*= removes all existing.
#+begin_src conf :tangle ./docker-profile/pypy3/docker-profile/profiles/tgbugs/pypy3/package.use
*/* PYTHON_TARGETS: +pypy3
#+end_src
** static
*** build
#+name: &build-profile-static
#+begin_src screen
docker build \
--tag tgbugs/docker-profile:static \
--build-arg PROFILE_AXIS=static \
--file docker-profile/axes.Dockerfile .
#+end_src
*** file
#+name: &profile-static-adds
#+begin_src dockerfile
ARG sbp=docker-profile/static/
ARG hr=<<&helper-repos()>>/

# ADD ${sbp}sbcl.env etc/portage/env/dev-lisp/sbcl  # gets klobbered when we make the profile so have to do it differently
ADD ${hr}sbcl/patches/dev-lisp etc/portage/patches/dev-lisp
#+end_src
*** profiles
***** make.defaults
We only set =static-libs= not =static= because =static= statically
links the executable which we rarely want, in which case a positive
static use flag should be added below, rather than turning off nearly
every instance of =static= that we encounter.
#+begin_src conf :tangle ./docker-profile/static/docker-profile/profiles/tgbugs/static/make.defaults
USE="${USE} static-libs"
#+end_src
***** package.use :ARCHIVE:
#+begin_src conf :tangle ./docker-profile/static/docker-profile/profiles/tgbugs/static/package.use :tangle no
# don't build openssh with static because it conflicts with the
# pie use flag for hardened which cannot be unset
net-misc/openssh -static

# bzip2 is completely broken if compiled with either of these use flags ???
# that is, it will compile but will leave the system unable to compress anything
app-arch/bzip2 -static

# trying to build with static causes a configure error due to container projections
# building with security=insecure supposedly can work around this
# cross compile check process_vm_readv # ccc process_vm_readv
# FIXME, further reading seems to suggest that we don't actually want static? just
# static-libs? so going to try that
app-arch/gzip -static
sys-apps/debianutils -static
sys-apps/coreutils -static
sys-devel/patch -static
sys-apps/findutils -static
sys-apps/sed -static
sys-devel/make -static
net-misc/wget -static
sys-apps/diffutils -static
sys-apps/grep -static
app-editors/nano -static
sys-devel/flex -static
sys-devel/bison -static
#+end_src

#+begin_src bash
echo \
sys-devel/bison \
-static >> /etc/portage/package.use/sigh && \
emerge -uDN @world
#+end_src
* profiles
break profiles into its own to level section in hopes of finding a better way to compose images
** debug
#+name: debug-profile
#+begin_src bash :results file :var img="base"
_name=profile-${img}.tar
docker create --name="tmp_$$" tgbugs/docker-profile:${img} true > /dev/null &&
docker export tmp_$$ > ${_name} &&
docker rm tmp_$$ > /dev/null
printf ${_name}
#+end_src

#+call: debug-profile(img="musl")

#+call: debug-profile(img="x")

** axes
*** libc
These are present in the base profile image since the existence and basic structure is present in the base
the actual customization for static, python, and xorg is kept in separate images, if there are actually
some non-orthogonal settings then we'll have to figure out how to handle them, but so far there haven't been
any interactions for e.g. pypy3 xorg that need special treatment.
**** gnu
#+name: &profile-gnu-free
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:gnu / /
#+end_src
**** musl
#+name: &profile-musl-free
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:musl / /
#+end_src
*** python
**** pypy3
#+name: &profile-pypy3
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:pypy3 / /
#+end_src
*** static
**** static
#+name: &profile-static
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:static / /
#+end_src
*** xorg
**** x
#+name: &profile-x
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:x / /
#+end_src
**** nox
#+name: &profile-nox
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:nox / /
#+end_src
** impossible/not meaningful combinations
- gnu static
  - gnu can't statically link
- musl pypy3 static
  - at the moment there is almost no reason to have pypy3 with
    static-libs since pypy3 can't be statically linked, and
    static-libs is primarily used to generate thin images
- gnu pypy3
  - might want this in the future, but for now we don't have a use
    case since gnu images are primarily used to cross compile the few
    packages that don't have musl binaries, pypy3 doesn't help much in those cases
** compose
these profiles are mutually exclusive? well, not quite, for builders
gnu and musl are mutex

so how do we compose these?
do we compose them via noweb with multiple =COPY --from=image= or what?
do we make it possible to parameterize a single docker file to say which
subtrees to pull in for a given concrete image and build all of them?

composing via =COPY= would seem to avoid a duplication of rebuilding
but noweb doesn't have good composability, on the other hand composing
by stacking images causes a proliferation of profile images that require
cascading rebuilds to make sure that everything is up to date, and might
also require a proliferation of dockerfiles if we can't figure out how to
deal with conditional copies in the blank case

in summary, going to start with noweb and see how it plays out

annoyingly there isn't a simple way to validate a profile actually matches
the image it is built from right now ...
*** /
#+name: &profile-base
#+begin_src dockerfile
COPY --from=tgbugs/docker-profile:base / /
#+end_src
*** /gnu
#+name: &profile-gnu
#+begin_src dockerfile
<<&profile-base>>
<<&profile-gnu-free>>
#+end_src
*** /gnu/x
#+name: &profile-gnu-x
#+begin_src dockerfile
<<&profile-gnu>>
<<&profile-x>>
#+end_src
*** /gnu/nox
#+name: &profile-gnu-nox
#+begin_src dockerfile
<<&profile-gnu>>
<<&profile-nox>>
#+end_src
*** /gnu/all
#+name: &profile-gnu-all
#+begin_src dockerfile
<<&profile-gnu>>
<<&profile-x>>
<<&profile-nox>>
#+end_src
*** /musl
#+name: &profile-musl
#+begin_src dockerfile
<<&profile-base>>
<<&profile-musl-free>>
#+end_src
*** /musl/x
#+name: &profile-musl-x
#+begin_src dockerfile
<<&profile-musl>>
<<&profile-x>>
#+end_src
*** /musl/nox
#+name: &profile-musl-nox
#+begin_src dockerfile
<<&profile-musl>>
<<&profile-nox>>
#+end_src
*** /musl/pypy3
#+name: &profile-musl-pypy3
#+begin_src dockerfile
<<&profile-musl>>
<<&profile-pypy3>>
#+end_src
*** /musl/pypy3/x
#+name: &profile-musl-pypy3-x
#+begin_src dockerfile
<<&profile-musl-pypy3>>
<<&profile-x>>
#+end_src
*** /musl/pypy3/nox
#+name: &profile-musl-pypy3-nox
#+begin_src dockerfile
<<&profile-musl-pypy3>>
<<&profile-nox>>
#+end_src
*** /musl/static
#+name: &profile-musl-static
#+begin_src dockerfile
<<&profile-musl>>
<<&profile-static>>
#+end_src
*** /musl/static/x
#+name: &profile-musl-static-x
#+begin_src dockerfile
<<&profile-musl-static>>
<<&profile-x>>
#+end_src
*** /musl/static/nox
#+name: &profile-musl-static-x
#+begin_src dockerfile
<<&profile-musl-static>>
<<&profile-nox>>
#+end_src
*** /musl/all
#+name: &profile-musl-all
#+begin_src dockerfile
<<&profile-musl>>
<<&profile-x>>
<<&profile-nox>>
<<&profile-pypy3>>
<<&profile-static>>
#+end_src
*** all not libc
#+name: &profile-all-not-libc
#+begin_src dockerfile
<<&profile-x>>
<<&profile-nox>>
<<&profile-pypy3>>
<<&profile-static>>
#+end_src
*** static/x
Sometimes we need to add multiple profiles to existing images that already have the base profile.
#+name: &profile-static-x
#+begin_src dockerfile
<<&profile-static>>
<<&profile-x>>
#+end_src

* repos
Overlays can take up quite a bit of space so it is better to mount
them the same way we mount the gentoo repo during build so that we can
keep the images a bit slimmer. We can publish the build images
independently, and it is also worth noting that from a reproducibility
perspective the exact ebuilds are stored in file:/var/db/pkg/.

*** debug
#+begin_src bash
docker create -v /var/db/repos --name portage-snap gentoo/portage:latest /bin/true
docker run \
--volumes-from portage-snap \
--entrypoint /bin/bash \
-it tgbugs/repos:latest
#+end_src
*** build
# FIXME the --no-cache option here means that setting --repos forces a
# rebuild of _everything_ downstream even if repos didn't change
#+name: &repos-build-repos
#+begin_src screen
docker build \
--no-cache \
--build-arg SYNC_GENTOO=$SYNC_GENTOO \
--tag tgbugs/repos:latest \
--file repos/Dockerfile repos
#+end_src
*** file
#+begin_src dockerfile :tangle ./repos/Dockerfile
ARG IMG_REPOS_BUILDER=tgbugs/musl:eselect-repo

FROM ${IMG_REPOS_BUILDER} as builder

COPY --from=gentoo/portage:latest /var/db/repos/gentoo /var/db/repos/gentoo

RUN \
   emaint sync --repo musl \
&& emaint sync --repo lisp \
&& emaint sync --repo haskell \
&& emaint sync --repo tgbugs-overlay

# manual sync in cases where there is a showstopper blocking progress
ARG SYNC_GENTOO

# FIXME if you ever have to fix a broken profile and sync at the same time
# this is horribly inefficient, and we should probably add a separate image
RUN \
   test -z $SYNC_GENTOO \
# WOULD SOMEONE CARE TO EXPLAIN TO ME HOW THIS SOLVES THE ISSUE !??!?!
|| { mv /var/db/repos /var/db/repos-wat; cp -a /var/db/repos-wat /var/db/repos; rm -r /var/db/repos-wat; emaint sync --repo gentoo; }
# why this by itself hangs forever but a simple mv and cp -a resolves the issue we may never know
# || emaint sync --repo gentoo

FROM busybox:latest

WORKDIR /
COPY --from=builder /var/db/repos /var/db/repos
CMD /bin/true
VOLUME /var/db/repos
#+end_src
* common
Functionality shared in common across arch, libc, etc.
Usually built on a specific arch, libc, etc. but output should be reusable on any combination.
** user
#+name: &build-user
#+begin_src screen
docker build \
--tag tgbugs/common:user \
--file common/user/Dockerfile common/user
#+end_src

# FIXME this is sufficient to create the default set of files and directories for the user
# however it is not able to deal with the fact that groupadd and useradd still must be run
# on the host system, which leads me to think that the only composability we are going to
# get here is via noweb :/ the primary issue is /etc/groups and other similar things

#+name: &run-user-noskel
#+begin_src bash :eval never
groupadd -g ${UID} ${USER_NAME} \
&& useradd -M -u ${UID} -g ${UID} ${USER_NAME}
#+end_src


Block to be nowebbed for the user creation portion of the images.
Should be +followed+ preceded? by a =COPY --from= that was built by
layering on top of the image we build below.

#+name: &musl-file-user-base
#+begin_src dockerfile
ARG UID=1000
ARG USER_NAME=user

RUN \
<<&run-user-noskel>>

USER $USER_NAME

WORKDIR /home/${USER_NAME}

RUN \
{ command -v xdg-user-dirs-update && xdg-user-dirs-update;} || true

ENV PATH="/home/${USER_NAME}/.local/bin:${PATH}"
#+end_src

=groupadd= and =useradd= mean that this needs to be built from a gentoo image.
#+name: &user-skel-common
#+begin_src dockerfile
ARG UID=1000
ARG USER_NAME=user

RUN \
groupadd -g ${UID} ${USER_NAME} \
&& useradd -m -k /etc/skel -u ${UID} -g ${UID} -d $(pwd)/home/${USER_NAME} ${USER_NAME}

RUN \
mkdir -p home/${USER_NAME}/.local/bin

RUN \
chown -R ${UID}:${UID} home/${USER_NAME}
#+end_src

On the off chance that we don't have a musl source image around make it possible to use a different builder image.
#+begin_src dockerfile :tangle ./common/user/Dockerfile
ARG IMG_USER_BUILDER=gentoo/stage3:amd64-musl-hardened

FROM ${IMG_USER_BUILDER} as builder

WORKDIR /build

<<&user-skel-common>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

** portage-maven
:PROPERTIES:
:CUSTOM_ID: portage-maven
:END:
Hack to make it possible to install from maven using portage.
*** build
#+name: &build-portage-maven
#+begin_src screen
docker build \
--tag tgbugs/common:portage-maven \
--file common/portage-maven/Dockerfile common/portage-maven
#+end_src

*** file
The UID for portage is static so it is ok to hard code it [fn::
https://api.gentoo.org/uid-gid.txt
https://wiki.gentoo.org/wiki/Project:Quality_Assurance/UID_GID_Assignment].

#+name: &portage-maven-settings
#+begin_src xml :tangle ./common/portage-maven/settings.xml :mkdirp yes
<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
          xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
          xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd">
  <localRepository>/var/tmp/portage/.m2/repository</localRepository>
</settings>
#+end_src

#+name: &run-portage-maven-1
#+begin_src bash :eval never :noweb yes
# mkdir -p var/lib/portage/home/.m2 \
chown -R 250:250 var/lib/portage \
&& mkdir -p var/tmp/portage/.m2/repository \
&& chown -R 250:250 var/tmp/portage
#+end_src

#+begin_src dockerfile :tangle ./common/portage-maven/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD settings.xml var/lib/portage/home/.m2/settings.xml

RUN \
<<&run-portage-maven-1>>

FROM scratch

WORKDIR /
COPY --from=builder /build /
#+end_src

* musl
Pushes to https://hub.docker.com/r/tgbugs/musl. \\
Derived from [[https://hub.docker.com/r/gentoo/stage3/tags?page=1&ordering=last_updated&name=musl-hardened][gentoo/stage3:amd64-musl-hardened]] \\
Further derived from https://ftp-osl.osuosl.org/pub/gentoo/releases/amd64/autobuilds/current-stage3-amd64-musl-hardened/ \\
and from https://gitweb.gentoo.org/proj/releng.git/tree/releases/specs/amd64/musl/stage3-hardened.spec
** eselect-repo
This is where everything starts. The profile has to be set here etc.
*** run
#+begin_src screen
docker run \
--volumes-from local-portage-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-it tgbugs/musl:eselect-repo
#+end_src

# debug
#+begin_src screen :exports none
docker run -it tgbugs/musl:eselect-repo
#+end_src

# debug tgbugs/repos:latest
#+begin_src screen
docker run \
--volumes-from local-repos-snap \
-it tgbugs/musl:eselect-repo
#+end_src

*** build
#+name: &musl-build-eselect-repo
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:eselect-repo \
--file musl/eselect-repo/Dockerfile musl/eselect-repo
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/eselect-repo/Dockerfile
FROM gentoo/stage3:amd64-musl-hardened

<<&gentoo-file-eselect-repo-common-1>>

<<&profile-musl>>

<<&gentoo-file-eselect-repo-common-2>>

RUN \
eselect profile set docker-profile:tgbugs/musl \
&& env-update

<<&gentoo-file-eselect-repo-common-3>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
eselect repository enable musl
#+end_src

#+name: &gentoo-file-eselect-repo-common-1
#+begin_src dockerfile
ARG ARCHIVE
#+end_src

#+name: &gentoo-file-eselect-repo-common-2
#+begin_src dockerfile
RUN \
# FIXME tgbugs-overlay symlinks
ln -s /var/db/repos/gentoo /usr/portage

RUN \
eselect news read all \
&& eselect news purge

# XXX these are retained to avoid crossdev and other issues where
# portage needs these to be folders and are expected to error if
# the profile in question creates a ./profile file in these folders
RUN \
   mkdir /etc/portage/package.accept_keywords > /dev/null 2>&1 \
;  mkdir /etc/portage/package.env             > /dev/null 2>&1 \
;  mkdir /etc/portage/package.mask            > /dev/null 2>&1 \
;  mkdir /etc/portage/package.unmask          > /dev/null 2>&1 \
;  mkdir /etc/portage/package.use             > /dev/null 2>&1 \
;  mkdir /etc/portage/repos.conf              > /dev/null 2>&1 \
|| true
#+end_src

FIXME python version update issue is another problem with using/having
eselect repo in the direct line rather than just as a helper to set up
the repos overlay is a problem, though I'm not sure there is really
any way to work around the issue, we just accept that every once in
awhile we have slightly larger images because for 1 release cycle we
had to update python since upstream gets the images out of sync

#+name: &gentoo-file-eselect-repo-common-3
#+begin_src dockerfile
# FIXME MAKEOPTS_LOCAL
RUN \
echo "MAKEOPTS=\"-j$(nproc)\"" >> /etc/portage/make.conf
# XXX setting PORTAGE_BINHOSTS has to come later? maybe as an envar?

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge --info 2>&1 | { grep Invalid\ atom && exit 1; exit 0; }

# handle updates for python version changes that block further calls to emerge
# these happen periodically when portage and stage3 images have mismached PYTHON_TARGETS
RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
[ $(emerge --info | grep -o 'PYTHON_TARGETS="[^"]\+"') = \
  $(bzgrep -o 'PYTHON_TARGETS="[^"]\+"' /var/db/pkg/dev-python/wheel-*/environment.bz2) ] \
|| emerge -uDN -q -j4 --getbinpkg @world \
<<&archive-or-rm>>

# FIXME shouldn't we be using binhosts for this step as well?
RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q \
   --getbinpkg \
   dev-vcs/git \
   app-eselect/eselect-repository \
<<&archive-or-rm>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
eselect repository add tgbugs-overlay git https://github.com/tgbugs/tgbugs-overlay.git \
&& eselect repository enable lisp \
&& eselect repository enable haskell
#+end_src
# TODO should we be adding the mount points here as well or is that not necessary?

** updated
*** file
Produce an up-to-date base image for =amd64-hardened-musl= from the
latest stage3 image including the
[[https://github.com/gentoo/musl][musl overlay]] as noted on the
[[https://wiki.gentoo.org/wiki/Project:Hardened_musl#Working_with_musl][wiki]].

At the moment the docker images are generated far more frequently than
the underlying stage3 tarballs are updated, so there are two docker
files, one for building the first time and another for running routine
emerge updates until a new stage3 is released.

Alternately, one way to avoid rebuilds is to build packages and store
them across rebuilds. This will take more work, but ultimately might
be a bit more reproducible since we would avoid the issues with having
an image building =FROM= a prior version of itself.

Sometimes this can fail if we try to run updates during the window in
time between tgbugs-overlay updating a Manifest and the gentoo portage
snapshot image catching up with the main tree. I really do not want to
add a sync step when creating the repos image, but it seems like that
is by far the safest and most general solution. Which is exactly what
the =--sync-gentoo= option is for!

# FIXME I think we need to add buildpkg here to limit rebuilds during
# bootstrap in the event of errors? ah except that we can't mount that
# with docker build because of the docker design flaws ... I think we
# just accept that first bootstrap takes longer unless we switch to
# podman or something like that

#+name: &musl/updated
#+begin_src dockerfile :tangle ./musl/updated/Dockerfile
FROM tgbugs/musl:eselect-repo
<<&updated-common>>
#+end_src
#+name: &updated-common
#+begin_src dockerfile
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN @system @world \
   --getbinpkg \
   --keep-going \
   --exclude sys-process/procps \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

# fail if emerge fails but for buildkit ensure that we do it in such a
# way that we can truncate further steps and create a debug image
RUN \
test ! -e /emerge-fail

RUN \
eselect gcc set $(eselect gcc list | tail -n 1 | awk '{ print $2 }')
#+end_src

*** build
#+name: &musl-build-updated
#+begin_src screen
docker build \
--tag tgbugs/musl:updated \
--network host \
--add-host local.binhost:127.0.0.1 \
--file musl/updated/Dockerfile musl/updated
#+end_src

*** rebuild
#+begin_src bash
docker build \
--tag tgbugs/musl:updated-remerge \
--file musl/updated/remerge.Dockerfile musl/updated

# check that everything works as expected (and that there were changes at all)
docker run -it tgbugs/musl:updated-remerge

# rename the image
docker image tag tgbugs/musl:updated-remerge tgbugs/musl:updated
#+end_src

*** run
#+name: &musl-run-updated
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:updated
#+end_src
** updated-user
An example of how to compose user images to minimize size.
*** run
#+begin_src bash
docker run -it tgbugs/musl:updated-user
#+end_src

*** build
#+name: &musl-build-updated-user
#+begin_src bash
docker build \
--tag tgbugs/musl:updated-user \
--build-arg UID=${UID} \
--file musl/updated-user/Dockerfile musl/updated-user
#+end_src

*** file
#+begin_src dockerfile yes :tangle ./musl/updated-user/Dockerfile
FROM tgbugs/musl:updated

# change this line to copy from whatever user image you need
COPY --from=tgbugs/common:user / /

<<&musl-file-user-base>>
#+end_src

** package-builder-musl
*** notes
there are a number of packages that we need to build variants of
before we get our fully configured builder(s) up and running this
should simplify many of the bootstrapping circularity issues that we
have, particularly with pypy3, harfbuzz/freetype, openjdk, and
anything else that has circular dependencies or long build times, it
does mean that flags on the target profile must be known in advance

but those can be calculated quickly by hopping through =eselect
profile docker-profile:*= and running =emerge --info= and then
taking the set intersection between those and the flags on our
troublesome packages ... in some cases we might be able to move
quite a bit of package building to use this process, except for
cases where

we will actually have to create an image that has access to all the
profiles for this because individual profiles do set use flags per
package (the obvious example being nox setting headless-awt on
specific packages) in theory we could try to avoid setting per package
use flags in derived profiles, but that is a very strong constraint
that it is not clear we actually need to follow

this early in the process the cost of having to rebuild due to changes
in the unified profile is low because literally no work has been done
beyond the base update and we would have to build anyway, the good news
is that by doing this after updated we don't have to rebuild updated
so updates to the early builder become more or less free
*** run
#+name: &musl-run-free-harf-nonsense
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v "${_path_binpkgs}":/var/cache/binpkgs \
-v "${PWD}"/bin/quickpkg-new:/tmp/quickpkg-new \
-v "${PWD}"/bin/harfbuzz-freetype-sigh.sh:/etc/entrypoint.sh \
--entrypoint /etc/entrypoint.sh \
-it tgbugs/musl:updated
#+end_src

TODO mount =/tmp/= and =/var/tmp/= to ramdisk to avoid blasting the ssd more than necessary
#+begin_src screen
docker run \
--volumes-from local-repos-snap \
-v "${_path_binpkgs}":/var/cache/binpkgs \
-v "${PWD}"/bin/quickpkg-new:/tmp/quickpkg-new \
-it tgbugs/musl:package-builder-musl
#+end_src
# --volumes-from cross-sbcl \
*** build
#+name: &musl-build-package-builder-musl
#+begin_src screen
docker build \
--tag tgbugs/musl:package-builder-musl \
--file musl/package-builder/musl.Dockerfile musl/package-builder
#+end_src
*** file
1. all profiles
2. emerge settings for building binary packages
#+begin_src dockerfile :tangle ./musl/package-builder/musl.Dockerfile
FROM tgbugs/musl:updated

COPY --from=tgbugs/common:portage-maven / /

<<&profile-all-not-libc>>

ADD entrypoints /etc/entrypoints
ADD repo_name /var/db/crossdev/profiles/repo_name
ADD layout.conf /var/db/crossdev/metadata/layout.conf
ADD crossdev.conf /etc/portage/repos.conf/crossdev.conf
# ADD sbcl.env /etc/portage/env/dev-lisp/sbcl
# TODO need a full combo world file for the docker set here, iirc missing static right now
# FIXME actually can't quite do this, there are packages that must be excluded for base and nox i.e. xorg-server (sigh sigh sigh)
ADD world /etc/portage/sets/docker

RUN \
echo 'FEATURES="${FEATURES} buildpkg"' >> /etc/portage/make.conf \
&& echo 'EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --binpkg-changed-deps=n --usepkg"' >> /etc/portage/make.conf
#+end_src

*** entrypoints
TODO only build if the package has not already been built
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./bin/harfbuzz-freetype-sigh.sh :mkdirp yes
USE="-harfbuzz" emerge -j4 -1q --getbinpkg media-libs/freetype
quickpkg $(/tmp/quickpkg-new)

# have to set -cairo here otherwise harfbuzz -truetype will fail to build
USE="-cairo -truetype" emerge -j4 -1q --getbinpkg media-libs/harfbuzz
quickpkg $(/tmp/quickpkg-new)

USE="harfbuzz" emerge -j4 -1q --getbinpkg media-libs/freetype
quickpkg $(/tmp/quickpkg-new)

USE="cairo truetype" emerge -j4 -1q --getbinpkg media-libs/harfbuzz
quickpkg $(/tmp/quickpkg-new)

# the static-libs variants of freetype
USE="static-libs -harfbuzz" emerge -j4 -1q --getbinpkg media-libs/freetype
quickpkg $(/tmp/quickpkg-new)

USE="static-libs harfbuzz" emerge -j4 -1q --getbinpkg media-libs/freetype
quickpkg $(/tmp/quickpkg-new)
#+end_src

- axes
  - package
  - use flag
    - global (not clear we actually need this even for the static-libs case?, but probably desirable?)
    - package specific
    - python targets (this one is particularly annoying)
  - profile (alternative to use flags)
    should be done separately from the =--onlydeps --only-deps-with-rdeps=n= run

#+begin_src bash
{media-libs/freetype,metia-libs/harfbuzz}
{"harfbuzz"}
{"cairo truetype"}
#+end_src

#+begin_src bash :tangle ./musl/package-builder/entrypoints/builder.sh :mkdirp yes
function build-thing () {
local profile_base variants profiles variant prof profile
profile_base=docker-profile:tgbugs/musl
# TODO can we generate the variants and profiles?
declare -a xorgs=('' '/x' '/nox')  # XXX atm x/nox are the only mutually exclusive use flag cases that break portage (it seems)
declare -a statics=('' '/static')
declare -a pythons=('' 'pypy3')
# TODO likely need to restrict build patterns, or do the composition manually and skip cases we don't deal with/want ???
# or just build them all and don't worry about it?
declare -a profiles=(
''
/x
/nox
/static/x
)
for variant in "${statics[@]}"; do  # have to quote the array unpacking so that empty string isn't skipped
  for prof in "${xorgs[@]}"; do
    profile=${profile_base}${variant}${prof}
    eselect profile set ${profile} # || return $?
    env-update
    source /etc/profile
    echo build package ${@} for ${profile}
    # TODO tweak the options here XXX NOTE usually going to want to use image meta ebuilds or sets to avoid switching profiles between package builds
    # FIXME --buildpkgonly means that --onlydeps --onlydeps-with-rdeps=n probably needs to be run first?
    # ok, this more or less seems to work, it does unpack the binary before checking to see that it came from a binary
    # so it is not 100% efficient, but seems ok?
    emerge -uDNq -j4 --keep-going --onlydeps --onlydeps-with-rdeps=n ${@} # || return $?
    emerge -uDNq -j4 --keep-going --buildpkgonly ${@} # || return $?
  done
done
eselect profile set ${profile_base}
env-update
source /etc/profile
}
#+end_src

TODO deal with needing to exclude whole packages from certain builds, e.g. xorg-server whenever -X is set

** pypy3
*** run
#+name: &musl-run-pypy3
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:pypy3
#+end_src
*** build
#+name: &musl-build-pypy3
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:pypy3 \
--file musl/pypy3/Dockerfile musl/pypy3
#+end_src
*** file
#+name: &python-targets-common
#+begin_src dockerfile
ARG USE_PYTHON_TARGETS  # use if there are issues with mismatched python targets
# can't use PYTHON_TARGETS directly because ARG PYTHON_TARGETS is the same
# as export PYTHON_TARGETS= which means that portageq results will be affected

# we defer changing python targets until after eselect-repo to avoid
# issues bootstrapping pypy3
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
sh -c '\
USE_PYTHON_TARGETS=${USE_PYTHON_TARGETS:-"$(portageq envvar PYTHON_TARGETS) pypy3"} \
&& [[ -z ${USE_PYTHON_TARGETS} ]] || \
   echo "*/* PYTHON_TARGETS: -* ${USE_PYTHON_TARGETS}" >> /etc/portage/package.use/00-base\
'
#+end_src

#+begin_src dockerfile :tangle ./musl/pypy3/Dockerfile
FROM tgbugs/musl:updated
# FIXME python targets to include pypy3 needs to be in its own derived environment
# starting from package builder or something like that
<<&python-targets-common>>

RUN \
ln -s pypy3_x /etc/portage/patches/dev-python/pypy3_10 \
&& ln -s pypy3_x-exe /etc/portage/patches/dev-python/pypy3_10-exe

# FIXME /emerge-fail and &archive-or-rm have a very bad interaction
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN @system @world eselect-python \
   --getbinpkg \
   --keep-going \
   --exclude sys-process/procps \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

# fail if emerge fails but for buildkit ensure that we do it in such a
# way that we can truncate further steps and create a debug image
RUN \
test ! -e /emerge-fail
#+end_src

#+begin_comment
Trying to bootstrap pypy3 at this phase of the build when you don't have
a pypy3 free environment yet can be a massive pain to debug. The solution
is to set =USE_PYTHYON_TARGETS= explicitly to override the default pypy3,
bootstrap everything until you can run =builder-debug= and then build the
binary pypy3 in an environment where you can debug.
#+end_comment

#+begin_comment
FIXME I think that we really have to make the pypy3 environment its
own branch because bootstrapping it is beyond terrifying when you have
to use the same images and the builder can deposit pyp3, otherwise you
wind up building pypy3 in an environment where binpkgs are not being
generated until the whole image is repackaged (!!!!)  SIGH

so here is the issue that we run into, we have multiple different
profiles that we construct for each base image and we keep those
profiles separate so that we don't impact all images when only a
derived layer changes, basically we want to have a single profile, but
we don't want docker to stupidly rebuild everything just becuase some
file that is irrelevant to the current image lineage changed,
unfortunately we need our base profile in order to build a pypy3
environment correctly so the base profile has to be added directly
after updated in order for this to work, maybe we can get it to go

XXX ignore the rant above, eselect-profile already sets our base
profile!  so we don't have to worry about any of this and can just add
an interposting layer
#+end_comment

*** patches
If you load up =builder-debug= you can emerge pypy3 by adding patches
manually, the right thing to do is to update the musl overlay build,
but for now, if you can manage to manually build in the builder you
will wind up with a binpkg that can be reused.

A number of relevant issues
- https://bugs.python.org/issue21622
- https://github.com/python/cpython/pull/18380
- https://bugs.python.org/issue43112
- https://github.com/gentoo/musl/issues/451#issuecomment-1017102775

**** cpython 2.7 patch
Sourced from https://git.alpinelinux.org/aports/plain/main/python3/musl-find_library.patch
If in =builder-debug= rebuild the python:2.7 binpkg =emerge -g n -k n python:2.7=.
#+begin_src diff :tangle ./docker-profile/base/musl-find_library.patch
diff -ru Python-2.7.12.orig/Lib/ctypes/util.py Python-2.7.12/Lib/ctypes/util.py
--- Python-2.7.12.orig/Lib/ctypes/util.py	2016-06-26 00:49:30.000000000 +0300
+++ Python-2.7.12/Lib/ctypes/util.py	2016-11-03 16:05:46.954665040 +0200
@@ -204,6 +204,41 @@
         def find_library(name, is64 = False):
             return _get_soname(_findLib_crle(name, is64) or _findLib_gcc(name))
 
+    elif True:
+
+        # Patched for Alpine Linux / musl - search manually system paths
+        def _is_elf(filepath):
+            try:
+                with open(filepath, 'rb') as fh:
+                    return fh.read(4) == b'\x7fELF'
+            except:
+                return False
+
+        def find_library(name):
+            from glob import glob
+            # absolute name?
+            if os.path.isabs(name):
+                return name
+            # special case for libm, libcrypt and libpthread and musl
+            if name in ['m', 'crypt', 'pthread']:
+                name = 'c'
+            elif name in ['libm.so', 'libcrypt.so', 'libpthread.so']:
+                name = 'libc.so'
+            # search in standard locations (musl order)
+            paths = ['/lib', '/usr/local/lib', '/usr/lib']
+            if 'LD_LIBRARY_PATH' in os.environ:
+                paths = os.environ['LD_LIBRARY_PATH'].split(':') + paths
+            for d in paths:
+                f = os.path.join(d, name)
+                if _is_elf(f):
+                    return os.path.basename(f)
+
+                prefix = os.path.join(d, 'lib'+name)
+                for suffix in ['.so', '.so.*']:
+                    for f in glob('{0}{1}'.format(prefix, suffix)):
+                        if _is_elf(f):
+                            return os.path.basename(f)
+
     else:
 
         def _findSoname_ldconfig(name):
#+end_src

**** pypy3-exe sys time patch
The patch is a version of the below patch that will apply correctly to later versions of pypy3.
<https://raw.githubusercontent.com/gentoo/musl/master/dev-python/
pypy3-exe/files/pypy3-exe-7.3.0-musl-compat-include-sys-time.patch>

#+begin_src diff :tangle ./docker-profile/base/musl-include-sys-time.patch :mkdirp yes
diff -r 9ef55f6fc369 pypy/module/cpyext/include/pytime.h
--- a/pypy/module/cpyext/include/pytime.h
+++ b/pypy/module/cpyext/include/pytime.h
@@ -2,6 +2,10 @@
 #ifndef Py_PYTIME_H
 #define Py_PYTIME_H
 
+#ifndef MS_WINDOWS
+#include <sys/time.h>
+#endif
+
 #include <pyconfig.h> /* include for defines */
 #include "object.h"
 
#+end_src

**** pypy3-exe stdio patch
The patch is a version of the below patch that will apply correctly to later versions of pypy3.
<https://raw.githubusercontent.com/gentoo/musl/master/dev-python/
pypy3-exe/files/pypy3-exe-7.3.0-musl-compat-fix-stdio-defs.patch>

#+begin_src diff :tangle ./docker-profile/base/musl-fix-stdio-defs.patch :mkdirp yes
--- a/rpython/rlib/rfile.py
+++ b/rpython/rlib/rfile.py
@@ -123,11 +123,11 @@
 c_ferror = llexternal('ferror', [FILEP], rffi.INT)
 c_clearerr = llexternal('clearerr', [FILEP], lltype.Void)
 
-c_stdin = rffi.CExternVariable(FILEP, 'stdin', eci, c_type='FILE*',
+c_stdin = rffi.CExternVariable(FILEP, 'stdin', eci, c_type='FILE* const',
                                getter_only=True, declare_as_extern=False)
-c_stdout = rffi.CExternVariable(FILEP, 'stdout', eci, c_type='FILE*',
+c_stdout = rffi.CExternVariable(FILEP, 'stdout', eci, c_type='FILE* const',
                                 getter_only=True, declare_as_extern=False)
-c_stderr = rffi.CExternVariable(FILEP, 'stderr', eci, c_type='FILE*',
+c_stderr = rffi.CExternVariable(FILEP, 'stderr', eci, c_type='FILE* const',
                                 getter_only=True, declare_as_extern=False)
 
 
#+end_src

**** pypy3 json string patch
Not all instance of string have =__radd__= methods that make uncasted
string concatenation safe. This results in divergent behavior compared
to the cypthon json implementation.
#+begin_src diff :tangle ./docker-profile/base/pypy3-json-str-subclass-safety.patch :mkdirp yes
diff -r 05fbe3aa5b08 lib-python/3/json/encoder.py
--- a/lib-python/3/json/encoder.py	Tue Mar 29 08:15:20 2022 +0300
+++ b/lib-python/3/json/encoder.py	Fri Apr 29 15:19:41 2022 -0700
@@ -371,8 +371,10 @@
                 first = False
             else:
                 buf = separator
-            if isinstance(value, str):
+            if type(value) == str:
                 yield buf + '"' + self.__encoder(value) + '"'
+            elif isinstance(value, str):
+                yield buf + '"' + str(self.__encoder(value)) + '"'
             elif value is None:
                 yield buf + 'null'
             elif value is True:
@@ -448,8 +450,10 @@
                 yield item_separator
             yield '"' + self.__encoder(key) + '"'
             yield self.key_separator
-            if isinstance(value, str):
+            if type(value) == str:
                 yield '"' + self.__encoder(value) + '"'
+            elif isinstance(value, str):
+                yield '"' + str(self.__encoder(value)) + '"'
             elif value is None:
                 yield 'null'
             elif value is True:
#+end_src

**** patchelf musl patch
Temporary until main tree is updated. See https://bugs.gentoo.org/860888.
#+begin_src diff :tangle ./docker-profile/base/patchelf-musl-no-dt-mips-xhash.patch :mkdirp yes
diff --git a/src/patchelf.cc b/src/patchelf.cc
index 5dd320d..3a4fd50 100644
--- a/src/patchelf.cc
+++ b/src/patchelf.cc
@@ -1184,10 +1184,12 @@ void ElfFile<ElfFileParamNames>::rewriteHeaders(Elf_Addr phdrAddress)
                 // some binaries might this section stripped
                 // in which case we just ignore the value.
                 if (shdr) dyn->d_un.d_ptr = (*shdr).get().sh_addr;
+            #ifdef __GLIBC__
             } else if (d_tag == DT_MIPS_XHASH) {
                 // the .MIPS.xhash section was added to the glibc-ABI
                 // in commit 23c1c256ae7b0f010d0fcaff60682b620887b164
                 dyn->d_un.d_ptr = findSectionHeader(".MIPS.xhash").sh_addr;
+            #endif
             } else if (d_tag == DT_JMPREL) {
                 auto shdr = tryFindSectionHeader(".rel.plt");
                 if (!shdr) shdr = tryFindSectionHeader(".rela.plt");
#+end_src
** xorg
# FIXME why is this not being built from binpkg only? is it for layer
# efficiency?
*** run
#+name: &musl-run-xorg
#+begin_src screen
# -v ~/files/binpkgs/musl:/var/cache/binpkgs \
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
-it tgbugs/musl:xorg
#+end_src
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:xorg
#+end_src
*** build
#+name: &musl-build-xorg
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:xorg \
--file musl/xorg/Dockerfile musl/xorg
#+end_src

*** file
The really good news here is that portage ignores packages that were
built with mismatched use flags, so at the end of the day what we will
wind up with is a case where only packages with mismatched flags will
be built and deposited into musl-x. The less good news is that this is
not fully implemented yet as noted in <https://wiki.gentoo.org/wiki/
Binary_package_guide#Pulling_packages_from_a_binary_package_host>.

If you need to work around a broken ~USE="-harfbuzz -truetype"~ case
build them in a container rather than a builder and then quickpkg them
and then run the builder again.

#+name: &xorg-nox-common-1
#+begin_src dockerfile
# ARG PROFILE_IMAGE=tgbugs/musl:profile-x
# FIXME switch to use pypy3 profile instead probably ??? or do we do that in the pypy3 image probably?
ARG START_IMAGE=tgbugs/musl:pypy3

#FROM ${PROFILE_IMAGE} as profile_image

FROM ${START_IMAGE}

# XXX noweb COPY --from= AFTER this point!
#+end_src

#+name: &xorg-nox-common-2
#+begin_src dockerfile
# XXX noweb COPY --from= BEFORE this point!

ARG PROFILE=docker-profile:tgbugs/musl/x

RUN \
eselect profile set $PROFILE \
&& env-update

# cut here if you need to quickpkg to avoid some brokeness
#+end_src

#+name: &xorg-nox-common-3
#+begin_src dockerfile
# FIXME I think we have to update binhosts here

# FIXME this rebuild is bad because it results in duplication of
# rebuilt packages between layers, probably need updated-x
# XXX install freetype without harfbuzz first to avoid the circular dependency (sigh)
# also have to install harfbuzz -freetype as well https://bugs.gentoo.org/830966#c5
# XXX NOTE when harfbuzz and freetype are installed from binpkgs sometimes fontconfig
# will scream about missing libs, this is because the good harfbuzz is installed after
# fontconfig, confusing and scary, but apparently not fatal

# FIXME may need to break this out into a binpkg builder ala what we now do for openjdk
# that can be use by any profile that modifies useflags on these and thus needs a rebuild
# e.g. openjdk-nox pulls these all in, and only by sheer luck have they already been built
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -1q \
   --getbinpkgonly \
   media-libs/freetype \
   media-libs/harfbuzz \
# have to set -cairo here otherwise harfbuzz -truetype will fail to build
|| USE="-cairo -harfbuzz -truetype" emerge -j4 -1q \
   --getbinpkg \
   media-libs/freetype \
   media-libs/harfbuzz \
# remind me again why were we using -j1 here? old gcc issues?
&& emerge -j4 -q -uDN @world \
   --getbinpkg \
   --exclude sys-process/procps \
   --keep-going \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

RUN \
test ! -e /emerge-fail

RUN \
eselect fontconfig disable 10-hinting-slight.conf \
&& eselect fontconfig enable \
   10-no-sub-pixel.conf \
   57-dejavu-sans.conf \
   57-dejavu-sans-mono.conf
#+end_src

#+begin_src dockerfile :tangle ./musl/xorg/Dockerfile
<<&xorg-nox-common-1>>
<<&profile-x>>
<<&xorg-nox-common-2>>
<<&xorg-nox-common-3>>
#+end_src

# FIXME 10-hinting-slight.conf no longer exists now ???

The issues with freetype hinting are partially dealt with in the
profile because so many packages pull in freetype, we have to deal
with the issue globally. We deal with some lingering issues here.

Only enabling dejavu sans and disabling any and all hinting matters.
There isn't a way to disable antialiasing using the gentoo fontconfig
and even if you do the disabled hinting engine has different and ugly
behavior compared to =-cleartype-hinting= so not sure what is going on
for even further insanity if you enable =10-hinting-none.conf= OR
=10-unhinted.conf= *YOU WILL GET HINTING !?!?!??! WAT!?* or at least
maybe AA is enabled which does not maybe ANY sense. Probably there is
some logic which is that in order to disable some feature there is
some default that is enabled so there winds up being a difference
between there being no reference to a feature and a reference to it to
explicitly disable it. Sigh.
** nox
*** run
#+name: &musl-run-nox
#+begin_src screen
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-it tgbugs/musl:nox
#+end_src
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
--rm \
-it \
tgbugs/musl:nox
#+end_src
*** build
TODO we start from updated here not from pypy3, there is a pypy3/nox profile, but this image is not the pypy3/nox image
#+name: &musl-build-nox
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:nox \
--build-arg PROFILE='docker-profile:tgbugs/musl/nox' \
--build-arg START_IMAGE='tgbugs/musl:updated' \
--file musl/nox/Dockerfile musl/nox
#+end_src
# --build-arg PROFILE_IMAGE='tgbugs/musl:profile-nox' \
*** file
#+begin_src dockerfile :tangle ./musl/nox/Dockerfile
<<&xorg-nox-common-1>>
<<&profile-nox>>
<<&xorg-nox-common-2>>
<<&xorg-nox-common-3>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN @world \
   --getbinpkg \
   --exclude sys-process/procps \
   --keep-going \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

RUN \
test ! -e /emerge-fail
#+end_src
** openjdk
*** run
debug
#+begin_src screen
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-it tgbugs/musl:openjdk-nox
#+end_src
*** build
#+name: &musl-build-openjdk
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:openjdk \
--file musl/openjdk/Dockerfile musl/openjdk
#+end_src

#+name: &musl-build-openjdk-nox
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:openjdk-nox \
--build-arg START_IMAGE='tgbugs/musl:nox' \
--file musl/openjdk/Dockerfile musl/openjdk
#+end_src

*** file
inherits from tgbugs/musl:xorg
TODO handle the nox case
#+begin_src dockerfile :tangle ./musl/openjdk/Dockerfile
ARG START_IMAGE=tgbugs/musl:xorg

FROM ${START_IMAGE}

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -1q \
   --getbinpkgonly \
   dev-java/openjdk \
# remove openjdk-bin mask for just this bootstrap if openjdk is not present
|| { sed -i "/openjdk-bin/d" /etc/portage/package.mask/profile \
;  emerge -j4 -q -uDN dev-java/openjdk-bin \
   --getbinpkg \
   --keep-going;} \
&& emerge -j4 -q -uDN openjdk \
   --getbinpkg \
   --keep-going \
|| echo $? > /emerge-fail \
<<&archive-or-rm>>

RUN \
test ! -e /emerge-fail
#+end_src
** package-builder
*** populate 0
Yes it is kind of annoying to fully split the packages here when many of them don't actually
change, but I don't have an easy way to detect when it is safe to symlink a nox build into
the X build, though I think we can create a processes that would check the packages and to
see whether they have identical metadata and then remove one and symlink the other ....


A brief note on various =bindist= warnings that may appear during this step.

For =openssh= and =openssl=, the issue is related to various patents on ECC and RC5.
As far as I can tell from https://en.wikipedia.org/wiki/ECC_patents and the reference
in https://en.wikipedia.org/wiki/RC5, these patents have all expired, so redistribution
of packages compiled with =-bindist= is not an issue.

For =freetype= it seems that most of the patents https://freetype.org/patents.html
have expired as well. The latest ebuild in the tree has removed bindist entirely.

# these two are technically x/nox agnostic
#+name: &musl-run-updated-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:updated
#+end_src

#+name: &musl-run-pypy3-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:pypy3
#+end_src


# it is safe to use --include-config here becauseit is done before any modifications are made
# FIXME TODO need a way to ignore existing exact matches unless we override
#+name: &musl-run-xorg-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:xorg
#+end_src

#+name: &musl-run-openjdk-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:openjdk
#+end_src

**** quickpkg dedupe
This more or less works to avoid duplicate packages in a binhost multi
instance setup.
#+header: :shebang "#!/usr/bin/env python" :tangle-mode (or #o0755)
#+begin_src jupyter-python :session pys :tangle ./bin/quickpkg-new :mkdirp yes
import portage
from portage.versions import _pkg_str
from portage.gpkg import gpkg

def contents_csums(contents):
    return sorted([l.split()[2] for l in contents.split('\n') if l.startswith('obj')])

def pkg_csums(bintree, atom):
    # XXX can use from portage.binpkg import get_binpkg_format
    # to displatch on package tyupe if we really need it
    pkg = gpkg(settings=bintree.settings, gpkg_file=bintree.pkgdir + '/' + atom._metadata['PATH'])
    _contents = pkg.get_metadata('CONTENTS')
    if _contents:
        contents = _contents.decode()
        return contents_csums(contents)
    else:
        object()  # don't match anything

def atoms_to_package():
    eroot = portage.settings['EROOT']
    trees = portage.db[eroot]
    bintree = trees['bintree']
    vartree = trees['vartree']
    vardb = vartree.dbapi

    installed = vartree.dbapi.cpv_all()
    packaged, not_packaged, misses = [], [], {}
    for i in installed:
        bt, bi, use, contents = vardb.aux_get(i, ['BUILD_TIME', 'BUILD_ID', 'USE', 'CONTENTS'])
        bt = int(bt) if bt else -1
        bi = int(bi) if bi else -1
        csums = contents_csums(contents)
        # yes build id has issues for some reason that I don't entirely understand
        matches = [a for a in bintree.dbapi.match(i) if
                   (a._metadata['USE'] == use and
                    (a.build_time == bt or
                     #a.build_id == bi and
                     csums == pkg_csums(bintree, a)))]
        if matches:
            packaged.append(i)
        else:
            misses[i] = [a for a in bintree.dbapi.match(i) if not
                         (a._metadata['USE'] == use and
                          (a.build_time == bt or
                           #a.build_id == bi and
                           csums == pkg_csums(bintree, a)))]
            not_packaged.append(i)
            #[[l.build_id for l in [k] + v] for k, v in misses.items()]
            #[[l.build_time for l in [k] + v] for k, v in misses.items()]
            #[[l._metadata['USE'] if hasattr(l, '_metadata') else None
              #for l in [k] + v] for k, v in misses.items()]

    return sorted([f'={a}' for a in not_packaged])

if __name__ == '__main__':
    atp = atoms_to_package()
    if atp:
        print(*atoms_to_package())
    else:
        print('-h')  # keep quickpkg happy since it doesn't like no args
#+end_src

*** run
#+begin_src bash
function build_package () {
echo docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
--rm \
tgbugs/musl:package-builder \
$@
}
#+end_src


#+begin_src bash
build_package sh -c "USE=-harfbuzz emerge -1q freetype"
# and here we see why I keep harfbuzz out of the nox profile
build_package sh -c "emerge -1q freetype"
#+end_src

# TODO it is almost certainly worth keeping these containers around
# and stashing them because they can be used to build more packages
# without having to do a full reinstall, which still takes awhile

# TODO figure out how to properly archive distfiles and binpkgs

# FIXME there is a nasty issue here with composability for use flag
# changes in the profile, in all likelihood we would be better off
# maintaining a stack layers on the builder to update the use flags
# independent of the profile until we we know that we have to do a
# full rebuild, simply because rebuilding build images from scratch
# every time is still slow and adding new packages will almost
# inevitably reveal issues that require such use changes many should
# go in the profile because we know that we are always going to need
# those in the future, it should be fairly straight forward to create
# a /var/db/docker-profile -> /etc/portage translator for the builder

I suggest adding all the =_path_= variables below (and the repo name)
to your shell rc file if you use any of the docker run commands during
development so that you can do so in a new shell. These values are
usually stable per system.
# FIXME watch out with the use of a=${a:-b} the value of a will persist
# in the environment when you change the default value
#+name: &builder-vars
#+begin_src bash :noweb yes
_path_binpkgs_root=${_path_root_binpkgs:-<<&host-binpkgs-root-path()>>}
_binpkgs_repo_name=${_binpkgs_repo_name:-<<&host-binpkgs-repo-name()>>}
_path_binpkgs=${_path_binpkgs:-${_path_binpkgs_root}/${_binpkgs_repo_name}}
_path_distfiles=${_path_distfiles:-<<&host-distfiles-path()>>}
_path_distcc_hosts=${_path_distcc_hosts:-<<&host-distcc-hosts-path()>>}
_path_ssh=${_path_ssh:-<<&host-ssh-path()>>}

_tm_pb=${_tm_pb:-tgbugs/musl:package-builder}
_tm_s_pb=${_tm_s_pb:-tgbugs/musl:static-package-builder}
_tm_n_pb=${_tm_n_pb:-tgbugs/musl:package-builder-nox}

_tm_pbs=${_tm_pbs:-${_tm_pb}-snap}
_tm_s_pbs=${_tm_s_pbs:-${_tm_s_pb}-snap}
_tm_n_pbs=${_tm_n_pbs:-${_tm_n_pb}-snap}

_tg_pb=${_tg_pb:-tgbugs/gnu:package-builder}

_tg_pbs=${_tg_pbs:-${_tg_pb}-snap}

#+end_src

#+name: &builder-resnap
#+begin_src bash
function builder-resnap () {
docker run ${_tm_pb}
docker commit $(docker ps -lqf ancestor=${_tm_pb}) ${_tm_pbs}
}
# FIXME SIGH SIGH SIGH why is this easier than doing the right thing
function static-builder-resnap () {
docker run ${_tm_s_pb}
docker commit $(docker ps -lqf ancestor=${_tm_s_pb}) ${_tm_s_pbs}
}
function nox-builder-resnap () {
docker run ${_tm_n_pb}
docker commit $(docker ps -lqf ancestor=${_tm_n_pb}) ${_tm_n_pbs}
}
function gnu-builder-resnap () {
docker run ${_tg_pb}
docker commit $(docker ps -lqf ancestor=${_tg_pb}) ${_tg_pbs}
}
#+end_src

#+name: &container-check
#+begin_src bash
function gnu-container-check () {
docker container inspect local-repos-snap > /dev/null || \
docker create -v /var/db/repos --name local-repos-snap tgbugs/repos:latest /bin/true
}

function container-check () {
gnu-container-check

# FIXME need to check that the cross image exists sigh make
#docker container inspect cross-sbcl > /dev/null || \
#docker create -v /sbcl --name cross-sbcl tgbugs/musl:cross-sbcl /bin/true
}
#+end_src

# FIXME currently the host sets /etc/distcc/hosts and mounts it
# host discovery for distcc will take more work ... in particular
# port mapping via ssh, the other possibility is that we just
# add a utility that can configure a container image to update
# itself with current settings or something
# FIXME FEATURES and MAKEOPTS are also set assuming the host is gentoo

# FIXME need to mount /var/tmp/portage as a ramdisk most times
# FIXME need a pre-test to ensure that the distcc config points to hosts that
# are actually accessible and/or that we are running with network host
# the issue was actually that the ssh connections timed out and reset
# so there were no hosts and distcc was segfaulting as a result, fun bug
# --volumes-from cross-sbcl \
#+name: &builder-args
#+begin_src bash :noweb yes
<<&builder-args-gnu>>
#+end_src

# FIXME cross build repos missing proper configuration for compression and archive type (even though there aren't very many packages)
#+name: &builder-args-gnu
#+begin_src bash
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v ${_path_ssh}:/var/lib/portage/home/.ssh \
-v ${_path_distcc_hosts}:/etc/distcc/hosts \
-v ${_path_binpkgs_root}/cross/gnu/x86_64-pc-linux-musl:/usr/x86_64-pc-linux-musl/var/cache/binpkgs \
-v ${_path_binpkgs_root}/cross/gnu/x86_64-gentoo-linux-musl:/usr/x86_64-gentoo-linux-musl/var/cache/binpkgs \
-v ${PWD}/bin:/usr/local/bin \
--env FEATURES="$(portageq envvar FEATURES | grep -o distcc)" \
--env MAKEOPTS="$(portageq envvar MAKEOPTS)" \
#+end_src
# --network host \
# network host is required to get distcc working on here due to the port forwarding
# hilariously or depressingly network host is still the only sane solution
# https://stackoverflow.com/q/17770902

#+name: &builder-bootstrap
#+begin_src bash :noweb yes
function builder-bootstrap () {
container-check

docker run \
<<&builder-args>>
${_tm_pbs} \
emerge  --color=y --with-bdeps=y -j4 -q --keep-going --getbinpkg \
sys-devel/distcc \
sys-devel/crossdev

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}

for target in {x86_64-pc-linux-gnu,x86_64-pc-linux-musl,x86_64-gentoo-linux-musl}; do
docker run \
<<&builder-args>>
${_tm_pbs} \
crossdev --stage4 --stable --portage --getbinpkg --target ${target}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
done

}

# FIXME SIGH copy paste
function gnu-builder-bootstrap () {
gnu-container-check

docker run \
<<&builder-args-gnu>>
${_tg_pbs} \
emerge  --color=y --with-bdeps=y -j4 -q --keep-going --getbinpkg \
sys-devel/distcc \
sys-devel/crossdev

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tg_pbs}) ${_tg_pbs}

for target in {x86_64-pc-linux-gnu,x86_64-pc-linux-musl,x86_64-gentoo-linux-musl}; do
docker run \
<<&builder-args-gnu>>
${_tg_pbs} \
crossdev --stage4 --stable --portage --getbinpkg --target ${target}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tg_pbs}) ${_tg_pbs}
done

}
#+end_src

# TODO distcc test
#+begin_src bash
function test_distcc () {
local test_host
for test_host in $(distcc --show-hosts); do
echo ${test_host}
DISTCC_HOSTS=${test_host} distcc x86_64-gentoo-linux-musl-gcc -c test.c -o test.o -v
echo
done
}
#+end_src

#+name: distcc-test-file
#+begin_src c
#include <stdio.h>
int main(void)
{
	printf("Hello world\n");
	return 0;
}
#+end_src

# TODO crossdev aarch64-unknown-linux-gnu-emerge
#+name: &builder-world
#+begin_src bash :noweb yes
function builder-world () {
local OUT _builder _axis

_axis=${1}

if [ "${_axis}" = "static" ]; then
_builder=${_tm_s_pbs}
elif [ "${_axis}" = "nox" ]; then
_builder=${_tm_n_pbs}
elif [ "${_axis}" = "gnu" ]; then
_builder=${_tg_pbs}
else
_builder=${_tm_pbs}
fi

echo builder ${_builder}

echo get targets
# get targets
container-check
targets=$(\
docker run \
--rm \
<<&builder-args>>
${_builder} \
sh -c 'set -o pipefail; emerge --color=n --with-bdeps=y -q -uDN -p @docker | { grep "\(^\[ebuild\|acct-\)" || true; } | cut -b17- | awk '"'"'{ print "="$1 }'"'")
# XXX acct- is a workaround for https://bugs.gentoo.org/890777

OUT=$?
[ ${OUT} -eq 0 ] || return ${OUT}

[ "${targets}" ] || return 0  # we're done here

targets_group=$(echo ${targets} | awk -v RS='\\s' '/^=acct-group/')
targets_nogroup=$(echo ${targets} | awk -v RS='\\s' '!/^=acct-group/')

echo only target bdeps
# emerge only build dependencies of targets
# FIXME for some reason there are sporadic package rebuilds that are being missed here
# e.g. due to slot depends changes
container-check
docker run \
<<&builder-args>>
${_builder} \
emerge --color=y --with-bdeps=y --onlydeps --onlydeps-with-rdeps=n -j4 -q --keep-going -uDN ${targets}

OUT=$?
docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_builder}) ${_builder}
[ ${OUT} -eq 0 ] || return ${OUT}

[ "${targets_group}" ] && {
echo only acct-group targets  # XXX avoid --nodeps order issues
container-check
docker run \
<<&builder-args>>
${_builder} \
emerge --color=y --with-bdeps=y --nodeps -j4 -q --keep-going -u ${targets_group}

OUT=$?
docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_builder}) ${_builder}
[ ${OUT} -eq 0 ] || return ${OUT}
}

[ "${targets_nogroup}" ] && {
echo only targets not acct-group
container-check
docker run \
<<&builder-args>>
${_builder} \
emerge --color=y --with-bdeps=y --nodeps -j4 -q --keep-going -u ${targets_nogroup}

OUT=$?
docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_builder}) ${_builder}
return $OUT
}
}

# FIXME SIGH code dupe
function static-builder-world () {
   builder-world static
}

function nox-builder-world () {
   builder-world nox
}

function gnu-builder-world () {
   # FIXME incorrectly pulls in the cross-sbcl volume
   builder-world gnu
}
#+end_src

#+name: &builder-arb
#+begin_src bash :noweb yes
function builder-run () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_pbs} \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}

function gnu-builder-run () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args-gnu>>
${_tg_pbs} \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tg_pbs}) ${_tg_pbs}
}

function static-builder-run () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_s_pbs} \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}

function nox-builder-run () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_n_pbs} \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_n_pbs}) ${_tm_n_pbs}
}

function builder-smart-live-rebuild () {
container-check
docker run \
<<&builder-args>>
${_tm_pbs} \
smart-live-rebuild -- --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}

function static-builder-smart-live-rebuild () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_s_pbs} \
smart-live-rebuild -- --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}

function builder-arb () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
# XXX FIXME code dupe
function static-builder-arb () {
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
container-check
docker run \
<<&builder-args>>
${_tm_s_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
"${@}"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src

# XXX seems like cross emerge really does not work at all as desired ???
# well this is somewhat annoying https://wiki.gentoo.org/wiki/Cross_build_environment
# grrr the system should be able to use the host packages, yes I know that there are
# surely many build tools that have bad assumptions baked in about the host environment
# matching the target environment ... but sigh
# XXX LOL the answer was simple, --nodeps DUH!
# the other part of the solution is to add ** to ACCEPT_KEYWORDS
# but it may need to be se in the cross env make.conf
# yeah ... unfortunately for things like sbcl ... there is no way
# because the ebuild authors would have had to anticipate this
# and it is insanely hard to test stuff like this, I make the modification
# in sbcl.env that is needed to get it to work, but still ...
# just symlink it to the cross env portage/env, and then we are to our
# usual determine-endianness issues with host vs target
#+name: &cross-builder-arb
#+begin_src bash :noweb yes
function cross-aarch64-gnu-builder-arb () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
<<&builder-args>>
--env USE='-*' \
--env ACCEPT_KEYWORDS='**' \
${_tm_pbs} \
aarch64-unknown-linux-gnu-emerge --color=y --with-bdeps=y -j4 -q --keep-going \
--usepkg=n --nodeps --buildpkgonly \
${@}

}
#+end_src

There are some packages such as =dev-lang/go= and some cross compiles
that require elevated privs in order to build otherwise they try to
call =process_vm_readv= then die.

See https://github.com/gentoo/gentoo-docker-images/issues/98 and
https://github.com/moby/moby/issues/1916.

#+name: &builder-arb-priv
#+begin_src bash :noweb yes
function builder-arb-priv () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
--security-opt seccomp=unconfined \
<<&builder-args>>
${_tm_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
# FIXME code dupe
function static-builder-arb-priv () {
container-check
# rebuild packages modified without revbump e.g. due to changing /etc/portage/patches
docker run \
--security-opt seccomp=unconfined \
<<&builder-args>>
${_tm_s_pbs} \
emerge --color=y --with-bdeps=y -j4 -q --keep-going --usepkg=n \
${@}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
#+end_src
# dev-lisp/sbcl cross compile

# ah the irony of docker dependencies needing ISE:do_peekstr:process_vm_readv
# due to using go-md2man and thus being unsafe to build in a sandboxed docker container
#+name: &musl-run-build-need-priv
#+begin_src bash
builder-arb-priv -1 -uN --getbinpkg \
dev-lang/go \
dev-go/go-md2man \
app-containers/runc \
app-containers/containerd \
app-containers/docker-cli
#+end_src

# --network host \
#+name: &builder-debug
#+begin_src bash :noweb yes
function builder-debug () {
container-check
docker run \
--privileged \
<<&builder-args>>
"${@}" \
-it ${_tm_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_pbs}) ${_tm_pbs}
}
function builder-debug-nowrite () {
container-check
docker run \
--privileged \
<<&builder-args>>
"${@}" \
-it ${_tm_pbs}
}
# XXX FIXME code dupe
function static-builder-debug () {
container-check
docker run \
--privileged \
<<&builder-args>>
"${@}" \
-it ${_tm_s_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_s_pbs}) ${_tm_s_pbs}
}
function nox-builder-debug () {
container-check
docker run \
--privileged \
<<&builder-args>>
"${@}" \
-it ${_tm_n_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tm_n_pbs}) ${_tm_n_pbs}
}
# SIGH
function gnu-builder-debug () {
gnu-container-check
docker run \
--privileged \
<<&builder-args-gnu>>
"${@}" \
-it ${_tg_pbs}

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tg_pbs}) ${_tg_pbs}
}
#+end_src

#+begin_src bash
# --nodeps # potentially useful

@live-rebuild

app-misc/screen
dev-lisp/sbcl


# to debug issues
docker run \
--volumes-from local-repos-snap \
--rm \
-it \
tgbugs/musl:package-builder-snap

# too many issues, just merge and get on with it
# the lack of separation between build time dependencies and runtime is quite annoying
# that or the dependency trees are even worse than I thought
# emerge --color=y -j4 -q --keep-going --onlydeps
# emerge --color=y -j4 -q --keep-going --buildpkgonly
#+end_src

TODO gnu builder cross

*** build
# FIXME cp -r is a hack for the time being, patches should be source more sanely
# cp -r patches/ musl/package-builder/
#+name: &musl-build-package-builder
#+begin_src screen
docker build \
--tag tgbugs/musl:package-builder \
--file musl/package-builder/Dockerfile musl/package-builder
#+end_src

*** file
# TODO distcc
# COPY patches /etc/portage/patches
#+name: &musl-package-builder-common
#+begin_src dockerfile
COPY --from=tgbugs/common:portage-maven / /

ADD repo_name /var/db/crossdev/profiles/repo_name
ADD layout.conf /var/db/crossdev/metadata/layout.conf
ADD crossdev.conf /etc/portage/repos.conf/crossdev.conf
# ADD sbcl.env /etc/portage/env/dev-lisp/sbcl
# FIXME need a better way to update the world file/docker set i.e. mount at runtime
ADD world /etc/portage/sets/docker

RUN \
echo 'FEATURES="${FEATURES} buildpkg"' >> /etc/portage/make.conf \
&& echo 'EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --binpkg-changed-deps=n --usepkg"' >> /etc/portage/make.conf
#+end_src

We don't add distcc until we get to the builder here to avoid issues
during bootstrap. Usually we don't have too many packages to rebuild
to get to a sane world state.

#+begin_src dockerfile :tangle ./musl/package-builder/Dockerfile
FROM tgbugs/musl:xorg

<<&musl-package-builder-common>>
#+end_src

*** ghc bootstrap
FIXME issue with needing to install the prior version to bootstrap the next
ideally we would be able to test for that
FIXME when ghc gets updated we have to reinstall all haskell packages and rebuild them
what a nightmare, fortunately just pandoc and dot2graphml for now, but that is 163 packages
that we have to rebuild, sometimes haskell-updater will miss some packages and you will
have to rebuild them manually
#+begin_src bash
emerge -q -j12 app-text/pandoc dev-haskell/dot2graphml
emerge -q --usepkg=n haskell-updater
haskell-updater --all --no-deep -- --usepkg=n
#+end_src
# must emerge -1q =dev-lang/ghc-{previous-revision} prior to bootstrap
# emerge ghc --onlydeps into builder, and then use the builder image as a starting point
# start from the builder snapshot but do not overwrite the snapshot when we're done i.e. use builder-debug-nowrite
# check here for latest version: https://pkgs.alpinelinux.org/package/edge/community/x86_64/ghc
# FIXME except ... that 9.4.4 seeminly can't bootstrap 9.0.2 ... what utter nonsense
#+begin_src bash
# curl -L -o ghc-9.0.2-r1.tar.bz http://dl-cdn.alpinelinux.org/alpine/edge/community/x86_64/ghc-9.0.2-r1.apk
# tar xvzf ghc-9.0.2-r1.tar.bz  # yes this is crazy, throw the container away when when are done
curl -L -o ghc-9.4.4-r1.tar.bz http://dl-cdn.alpinelinux.org/alpine/edge/community/x86_64/ghc-9.4.4-r1.apk
tar xvzf ghc-9.4.4-r1.tar.bz  # yes this is crazy, throw the container away when when are done
FEATURES=-distcc emerge -1q dev-lang/ghc
#+end_src
since we are lucky enough to have an existing ghc xpak file from another system we can use that sigh
technically can skip the emerge dev-lang/ghc bit if the versions match ...
#+begin_src screen
docker run \
-v ~/files/binpkgs/ghc-9.0.2-r4-1.xpak:/tmp/multi/dev-lang/ghc/ghc-9.0.2-r4-1.xpak \
-e PKGDIR=/tmp/multi \
--privileged \
<<&builder-args>>
"${@}" \
-it ${_tm_pbs} \
sh -c "emerge -K =dev-lang/ghc-9.0.2-r4; unset PKGDIR; emerge dev-lang/ghc; quickpkg dev-lang/ghc"
#+end_src

+and then we have to modify all the top level entry point scripts to adjust their install location+
give up and for the bootstrap just extract the alpine build straight into the existing file system
because we can't set the prefix

but even here the Winline errors are showing up during the build maybe
they aren't fatal in non-crossbuild settings?

haha! this works! we are good to go, lots of file collisions of
course, but at least we have the binpkg now this means we aren't going
to try to get ghc-cross working for the time being because kicking off
from alpline seems to be working well enough for one auxillary package
**** old
https://github.com/redneb/ghc-alt-libc/releases/download/ghc-9.0.2-musl/ghc-9.0.2-x86_64-unknown-linux-musl.tar.xz
Have to roll with =USE=ghcbootstrap= but mercifully this makes it extremely easy to just plob the binaries on
the system and get to work.
also no distcc
TODO follow sbcl pattern here and stick the stuff we need in =/ghc= probably and provide as a separate image?
#+begin_src bash
pushd /tmp/
PV=9.0.2
curl -OL https://github.com/redneb/ghc-alt-libc/releases/download/ghc-${PV}-musl/ghc-${PV}-x86_64-unknown-linux-musl.tar.xz
tar xvJf ghc-${PV}-x86_64-unknown-linux-musl.tar.xz
pushd ghc-${PV}
./configure --prefix=/ghc
make install
popd
popd
#+end_src

#+begin_src ebuild :tangle ./musl/package-builder/ghc.env
pre_pkg_setup() { export PATH="${PATH}:/ghc/bin"; }
#+end_src

using this on musl fails because ghc-cabal is segfaulting for some reason
https://github.com/NixOS/nixpkgs/issues/118731, the solution is to use a
version of ghc that can target musl 1.2.3, i.e. the one from alpine

*** sbcl bootstrap :old:
Since the addition of the =system-bootstrap= use flag we cross compile
from gnu to musl and emerge the cross compiled binpkg once and then we
are good to go, though may need to emerge the old version of sbcl when
we have to update to a new version.

The gentoo ebuilds for sbcl retrieve an existing binary for bootstrapping.
Due to the fact that the current EAPI (?) is not libc aware for precompiled
binaries we would have to create and maintain a binary for the musl overlay.
Modifying =src_unpack= is a more expedient solution.
#+name: &sbcl-env
#+begin_src ebuild :tangle ./musl/package-builder/sbcl.env
src_unpack() {
	unpack ${A}
	[ -d /sbcl ] && {
		einfo "Using /sbcl for bootstrap"
		cp -r /sbcl sbcl-binary || die;
		cp -a ${S}/run-sbcl.sh sbcl-binary/ || die;
	} || {
	command -v sbcl && {
		einfo "Using local sbcl found at $(command -v sbcl) for bootstrap"
		local bin_core_home;
		IFS=',' read -r -a bin_core_home <<< $(sbcl --noinform --no-sysinit --no-userinit --eval \
		'(progn (format t "~a,~a,~a" sb-ext:*runtime-pathname* sb-ext:*core-pathname* (sb-int:sbcl-homedir-pathname)))' --quit) || die;
		mkdir -p sbcl-binary/src/runtime || die;
		mkdir -p sbcl-binary/output || die;
		mkdir -p sbcl-binary/obj/sbcl-home || die;
		cp -a ${bin_core_home[0]} sbcl-binary/src/runtime/ || die;
		cp -a ${bin_core_home[1]} sbcl-binary/output/ || die;
		cp -a ${bin_core_home[2]}/contrib sbcl-binary/obj/sbcl-home/contrib || die;
		cp -a ${S}/run-sbcl.sh sbcl-binary/ || die;
	} } ||
	mv sbcl-*-* sbcl-binary || die
	cd "${S}"
}
#+end_src
*** crossdev
In order to fix
#+begin_example
 * Missing digest for '/var/db/docker-profile/cross-x86_64-pc-linux-gnu/binutils/binutils-2.34-r2.ebuild'
 * Missing digest for '/var/db/docker-profile/cross-x86_64-pc-linux-gnu/binutils/binutils-2.33.1-r1.ebuild'
#+end_example

This works around the fact that musl uses thin manifests.  See
https://wiki.gentoo.org/wiki/Custom_ebuild_repository#Crossdev.
#+name: &crossdev-repo_name
#+begin_src conf :tangle ./musl/package-builder/repo_name
crossdev
#+end_src

#+name: &crossdev-layout
#+begin_src conf :tangle ./musl/package-builder/layout.conf
masters = gentoo
thin-manifests = true
#+end_src

#+name: &crossdev-conf
#+begin_src conf :tangle ./musl/package-builder/crossdev.conf
[crossdev]
location = /var/db/crossdev
priority = 10
masters = gentoo
auto-sync = no
#+end_src

But even with that fix there is an issue with linking the core runtime libs.
#+begin_example
/usr/libexec/gcc/x86_64-pc-linux-gnu/ld: cannot find crti.o: No such file or directory
#+end_example

For reasons I do not fully understand we have to use the gentoo repo
as the source for the gcc ebuild, the two are virtually identical, so
maybe the toolchain eclass is silently different? Unknown.
#+begin_src bash
crossdev --stage4 --stable --target x86_64-pc-linux-gnu --ov-gcc /var/db/repos/gentoo
#+end_src

At this point we can attempt to emerge sbcl, but =src_config= will fail.
#+begin_src bash
x86_64-pc-linux-gnu-emerge -q -j4 sbcl
#+end_src

As a result, I reworked the profile so that it can support whatever
libc we want and do the cross build from gnu to musl since there are
distributed sbcl-binaries for gnu but not for musl. The way that
multiple libcs are implemented in gentoo right now seems to add
significant maintenance overhead due to ebuild duplication.

*** world
#+name: world-package-builder
#+begin_src conf :tangle ./musl/package-builder/world
<<ident((dedupe-lines "world-package-builder-dupes"))>>
#+end_src

#+name: world-package-builder-dupes
#+begin_src conf
<<world-package-builder-nox>>
<<world-kg-release>>
<<world-kg-dev>>
<<world-docker>>
<<world-interlex>>
<<world-sparcron>>
<<world-package-builder-common>>
x11-base/xorg-server
x11-libs/gtk+
#+end_src

#+name: world-package-builder-common
#+begin_src conf
app-portage/smart-live-rebuild
app-editors/gvim
#+end_src

#+begin_src conf
media-libs/freetype
media-libs/fontconfig
media-fonts/dejavu
#+end_src

** package-builder-nox
*** populate 0
#+name: &quickpkg-image
#+begin_src bash
function quickpkg-image () {
container-check  # FIXME what if we want to snap when we only have local-portage-snap?
docker run \
--volumes-from local-repos-snap \
-v "${_path_binpkgs}":/var/cache/binpkgs \
-v "${PWD}"/bin/quickpkg-new:/tmp/quickpkg-new \
--rm \
${1} \
/bin/sh -c 'quickpkg $(/tmp/quickpkg-new)'
}
#+end_src

#+name: &musl-run-nox-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:nox
#+end_src

#+name: &musl-run-openjdk-nox-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:openjdk-nox
#+end_src

*** run
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
--rm \
tgbugs/musl:package-builder-nox \
emerge --color=y -j4 -q --keep-going @docker
#+end_src
*** world
If there is a new package that one of your images needs add it here.
Yes, there are going to be issues with keywording that are likely going
to require updates to the profile followed by a rebuild here. I can't quite
remember whether binpkgs check use flags.
#+name: world-package-builder-nox
#+begin_src conf :tangle ./musl/package-builder/nox.world
<<world-debug>>
<<world-dynapad-base>>
<<world-python>>
<<world-schemes>>
<<world-blazegraph>>
<<world-package-builder-common>>
dev-lisp/sbcl
#+end_src

# requires a crossdev environment for this to work
#+name: world-lisp
#+begin_src conf
dev-lisp/sbcl
dev-lisp/clozurecl
dev-lisp/clisp
#+end_src

#+name: world-schemes
#+begin_src conf
dev-scheme/chicken
dev-scheme/guile
dev-scheme/gambit
#+end_src
# TODO build Chez from the Racket repo for unencumbered boot files
#+name: world-xemacs
#+begin_src conf
app-editors/xemacs
app-xemacs/xemacs-packages-all
#+end_src

*** build
#+name: &musl-build-package-builder-nox
#+begin_src screen
docker build \
--tag tgbugs/musl:package-builder-nox \
--file musl/package-builder/nox.Dockerfile musl/package-builder
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/package-builder/nox.Dockerfile
FROM tgbugs/musl:nox

<<&musl-package-builder-common>>

# overwrite the regular world file
ADD nox.world /etc/portage/sets/docker
#+end_src

** package-binhost
** binpkg-only
*** run
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
--rm \
-it tgbugs/musl:binpkg-only
#+end_src

*** build
#+name: &musl-build-binpkg-only
#+begin_src bash
docker build \
--tag tgbugs/musl:binpkg-only \
--file musl/binpkg-only/Dockerfile musl/binpkg-only
#+end_src

*** file
# wow parallel-install -ebuild-locks speeds things up quite a bit
# unfortunately they break acct-group and acct-user packages
# due to /etc/gshadow.lock contention which I think happends due
# to the -ebuild-locks feature because setting that allows
# unsandboxed steps to install concurrently
#+name: &musl-binpkg-only-common
#+begin_src dockerfile

RUN \
echo 'EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --usepkgonly --getbinpkgonly"' >> /etc/portage/make.conf \
&& echo 'FEATURES="${FEATURES} parallel-install -ebuild-locks"' >> /etc/portage/make.conf
#+end_src

#+begin_src dockerfile :tangle ./musl/binpkg-only/Dockerfile
FROM tgbugs/musl:xorg
<<&musl-binpkg-only-common>>
#+end_src

** binpkg-only-nox
*** run
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
--rm \
-it tgbugs/musl:binpkg-only-nox
#+end_src

*** build
#+name: &musl-build-binpkg-only-nox
#+begin_src screen
docker build \
--tag tgbugs/musl:binpkg-only-nox \
--file musl/binpkg-only/nox.Dockerfile musl/binpkg-only
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/binpkg-only/nox.Dockerfile
FROM tgbugs/musl:nox
<<&musl-binpkg-only-common>>
#+end_src

** debug
*** world
#+name: world-debug
#+begin_src conf
app-editors/vim
app-portage/eix
sys-devel/gdb::musl
#+end_src

** docker :bootstrap:
This image provides one route to bootstrap an environment that can
execute this file. Other routes also exist.

This route requires the following dependencies.
1. This =source.org= file.
2. Emacs 27 or later (earlier might work but not tested)
3. A posix shell
4. docker version 20 or later
5. Access to a gentoo stage 3 musl image.

It does not require git to be installed on the host so =source.org=
could be retrieved via curl or from a backup or similar.

With a bit of wrangling the bootstrap might also be able to drop the
Emacs dependency.

A second phase bootstrap is used to provide a stable starting point
for the rest of the process. This second phase does use git.

*** run
Reminder that this gives access to the host docker system.
#+begin_src bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-it tgbugs/musl:docker
#+end_src

Version that works with existing package host folders.

#+begin_src bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-v ~/files/binpkgs:/binpkgs \
-it tgbugs/musl:docker
#+end_src

After quite a bit of exploration it seems that passing =docker.sock=
is the sanest way to achieve what we want, though it does create a
strange warping of perspective because all containers run on the host
docker server. This is unfortunate because it causes the semantics to
differ between running the bootstrap outside of docker or trying to
run it "inside" of docker. See the dind heading above for more.
*** build
#+name: &musl-build-docker
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:docker \
--file musl/docker/Dockerfile musl/docker
#+end_src

*** entrypoints
0th
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/docker/entrypoint-0.sh :mkdirp yes
pushd dockerfiles
./source.org ${@}
#+end_src

1st
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/docker/entrypoint-1.sh :mkdirp yes
git clone https://github.com/tgbugs/dockerfiles.git
pushd dockerfiles
./source.org ${@}
#+end_src

*** file
# TODO daemon.json
#+begin_src dockerfile :tangle ./musl/docker/Dockerfile
<<&build-world>>
ADD source.org /dockerfiles/source.org
ADD entrypoint-0.sh /etc/entrypoint-0.sh
ENTRYPOINT /etc/entrypoint-0.sh
#+end_src

#+begin_src dockerfile :tangle ./musl/docker/nox.Dockerfile
<<&build-world-nox>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
NOTE =dev-lang/go= is pulled in by =app-emulation/docker= and must be
built using ref:&builder-arb-priv to avoid =process_vm_readv= being
blocked by the container.

#+name: world-docker
#+begin_src conf :tangle ./musl/docker/world
app-editors/emacs
app-containers/docker
app-containers/docker-cli
app-containers/docker-buildx
#+end_src

** testing-python
Python testing.
*** world
# gentoo no longer has 3.{6,7} in the main tree, going to be a pain test back there
# dev-lang/python:3.6
# dev-lang/python:3.7
# dev-lang/python:3.8
#+name: world-python
#+begin_src conf :tangle ./musl/testing-python/world
dev-lang/python:3.9
dev-lang/python:3.10
dev-lang/python:3.11
dev-python/pypy3
dev-python/pip
dev-python/pipenv
#+end_src
# XXX pipenv continues to be a toxic waste dump of insanity and brokeness
# https://bugs.gentoo.org/717666 really really bad call on my part for
# picking it back in 2018 because Pipfile seemed useful
** testing-emacs
Emacs testing.
*** world
# app-editors/emacs:23
# app-editors/emacs:24
#+begin_src conf :tangle ./musl/testing-emacs/world
app-editors/emacs:18
app-editors/emacs:25
app-editors/emacs:26
app-editors/emacs:27
app-editors/emacs:28
app-editors/emacs:29-vcs
#+end_src
** emacs
Emacs using the athena 3d toolkit to avoid pulling in gtk.
*** bugs
If you quickpkg emacs and then try to install it you can encounter
#+begin_example
mv: cannot stat '/var/tmp/portage/app-editors/emacs-27.2-r5/image/usr/share/info/emacs-27/dir.orig': No such file or directory
#+end_example
This is somewhat concerning since the failure is during preinst and it
definitely should not be looking in /var/tmp/portage for that orig
file. It seems that forcing a rebuild with builder-arb fixes the issue.
*** run
#+begin_src screen
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:emacs
#+end_src

debug run
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:emacs
#+end_src

If you see the following error you somehow forgot/are missing the musl overlay.
#+begin_example
Error loading shared library libbsd.so.0: No such file or directory (needed by /usr/lib/libICE.so.6)
Error loading shared library libbsd.so.0: No such file or directory (needed by /usr/lib/libXdmcp.so.6)
Error relocating /usr/lib/libICE.so.6: arc4random_buf: symbol not found
Error relocating /usr/lib/libXdmcp.so.6: arc4random_buf: symbol not found
#+end_example

*** build
#+name: &musl-build-emacs
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:emacs \
--file musl/emacs/Dockerfile musl/emacs
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/emacs/Dockerfile
<<&build-world>>
#+end_src

#+begin_src dockerfile :tangle ./musl/emacs/nox.Dockerfile
<<&build-world-nox>>
#+end_src

*** world
# FIXME I think something in the emacs ebuild is broken because sometimes it fails to pull in libbsd???
#+name: world-emacs
#+begin_src conf :tangle ./musl/emacs/world
app-emacs/vterm
app-emacs/zmq
app-editors/emacs
#+end_src

** icedtea
*** build
#+name: &musl-build-icedtea
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:icedtea \
--file musl/icedtea/Dockerfile musl/icedtea
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/icedtea/Dockerfile
<<&build-world>>
#+end_src
*** world
# FIXME BROKEN
#+name: world-icedtea-broken
#+begin_src conf :tangle ./musl/icedtea/world :tangle no
dev-java/icedtea-bin::musl
#+end_src

Backup.
#+name: world-icedtea
#+begin_src conf :tangle ./musl/icedtea/world
dev-libs/nss
x11-libs/libXcomposite
x11-libs/libXtst
dev-java/icedtea-bin::tgbugs-overlay
#+end_src
# back to musl since somehow my local setup is broken for the package builder
# and the musl repo is fixed again and I managed to pull everything down this time
# dev-java/icedtea-bin::local

# note the lack of tangle
#+name: world-icedtea-nox
#+begin_src conf
dev-libs/nss
dev-java/icedtea-bin::local
#+end_src

*** legacy
The musl overlay installs icedtea-bin correctly now so this is
+thankfully no longer needed+ only needed periodically.
#+name: &musl/icedtea/legacy
#+begin_src dockerfile :tangle ./musl/icedtea/legacy.Dockerfile
FROM tgbugs/musl:xorg

ARG ARCHIVE

ARG BASE="https://github.com/tgbugs/musl/releases/download/icedtea-bin-3.18.0-alpine-helper-0/"

ARG TMCH=34581ad0f14b5898abfb8d0a7ad89d560270a2e5

RUN \
eselect repository create local /usr/local/portage

# FIXME this is an evil hack that WILL expire
RUN \
mkdir -p /usr/local/portage/dev-java/icedtea-bin \
&& pushd /usr/local/portage/dev-java/icedtea-bin \
&& ln -s /var/db/repos/musl/dev-java/icedtea-bin/files \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/icedtea-bin-3.18.0.ebuild" \
&& curl -L -O "https://raw.githubusercontent.com/tgbugs/musl/${TMCH}/dev-java/icedtea-bin/Manifest"

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q nss \
<<&archive-or-rm>>

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
emerge -j4 -q dev-java/icedtea-bin::local --onlydeps \
<<&archive-or-rm>>

ARG SIGH="icedtea-bin-3.18.0-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-dbg-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-doc-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-base-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-lib-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-jre-x86_64-musl.tar.gz \
icedtea-bin-3.18.0-libjpeg-x86_64-musl.tar.gz"

RUN --mount=from=gentoo/portage:latest,source=/var/db/repos/gentoo,target=/var/db/repos/gentoo,rw \
pushd /var/cache/distfiles \
&& for SI in ${SIGH}; do curl -L -o "${SI}" "${BASE}${SI/-musl/}"; done \
&& popd \
&& emerge -j4 -q dev-java/icedtea-bin::local \
<<&archive-or-rm>>
#+end_src

# export failure=$(docker ps -lq)
# docker start $failure
# docker attach $failure

** protege
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:protege
#+end_src

*** build
#+name: &musl-build-protege
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:protege \
--build-arg UID=${UID} \
--file musl/protege/Dockerfile musl/protege
#+end_src

Due to the fact that protege needs X11 running in order to create
config files.  Run the following command, change the default reasoner
to ELK, make any other changes that are needed, and then quit protege.
The second command will run automatically and commit the changes.

NOTE you must run the =protege= command manually to prevent the commit
from changing the default behavior of the container from changing its
entry point to run =protege=.

#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:protege && \
docker commit $(docker ps -lq) tgbugs/musl:protege
#+end_src

*** world
#+name: world-protege
#+begin_src conf :tangle ./musl/protege/world
virtual/jre:17
dev-python/pip
x11-misc/xdg-user-dirs
#+end_src
*** file
We install pip during this step because any builds that =FROM
tgbugs/musl:protege= default to =protegeuser=.
# TODO FIXME we should be able to install protege as root
#+name: &musl/protege
#+begin_src dockerfile :tangle ./musl/protege/Dockerfile
FROM tgbugs/musl:xorg as builder

ARG ARCHIVE
ARG PROTEGE_VERSION="5.6.1"

WORKDIR /build

<<&user-skel-common>>

USER ${USER_NAME}

ARG HOME=/build/home/${USER_NAME}

WORKDIR $HOME

# phase two protege and reasoners
ARG URL_PROTEGE="https://github.com/protegeproject/protege-distribution/releases/download/protege-5.6.1/Protege-5.6.1-linux.tar.gz"
ARG URL_FACT="https://bitbucket.org/dtsarkov/factplusplus/downloads/uk.ac.manchester.cs.owl.factplusplus-P5.x-v1.6.5.jar"

RUN \
cd ~/ \
&& curl -L -O ${URL_PROTEGE} \
&& tar xvzf Protege-${PROTEGE_VERSION}-linux.tar.gz \
&& pushd Protege-${PROTEGE_VERSION} \
# remove the glibc linked jre
&& rm jre/ -r \
&& sed -i 's/^\$EFFECTIVE_JAVA_HOME\/bin\/java/\/usr\/bin\/java\ --add-opens java.xml\/com.sun.org.apache.xml.internal.serialize=ALL-UNNAMED/' run.sh \
#&& sed -i 's/500M/12G/' run.sh \
#&& sed -i 's/200M/5G/' run.sh \
#&& sed -i 's/16M/160M/' run.sh \
&& pushd plugins \
&& curl -L -O ${URL_FACT} \
&& popd; popd \
&& mkdir -p ~/.local/share ~/.local/bin \
&& mv Protege-${PROTEGE_VERSION} ~/.local/share/ \
&& pushd ~/.local/bin \
&& ln -s ../share/Protege-${PROTEGE_VERSION}/run.sh protege \
&& popd \
&& rm Protege-${PROTEGE_VERSION}-linux.tar.gz

# paths to preferences files
ARG PATH_CFU_1=_\!\&\!\!\`g\"\>\!\&@\!\[@\"\(\!%\`\!\|w\"@\!\&\)\!\[@\"\'\!%\`\!\`g\"\&\!%4\!@w\"\&\!\&:=
ARG PATH_CFU_2=_\!\'%\!c\!\"w\!\'w\!a@\"j\!\'%\!d\!\"p\!\'8\!bg\"f\!\(\!\!cg\"l\!\'\}\!~@\"y\!\'\`\!bg\"j\!\'\`\!cw==
ARG PATH_CFU_3=_\!\'8\!cg\"n\!#4\!c\!\"y\!\'8\!d\!\"l\!\'c\!~@\!u\!\'\`\!~\!\"p\!\(@\!bw\"y\!#4\!\}w\"v\!\(\)\!~@\!u\!\(\`\!c\!\"k\!\'%\!d\!\"l\!#4\!\`\!\"s\!\(\`\!~w\"p\!\'4\!\^@\"h\!\'4\!\}@\"n\!\'\`\!cg==
ARG PATH_CFU="${PATH_CFU_1}/${PATH_CFU_2}/${PATH_CFU_3}"

# set preferences so that protege starts in the right state the first time
# protege doesn't create this prefs file by default so we would have to do this regardless
# this helps because it prevents the search for plugins on first run so that goes faster
RUN \
pushd ~/ \
&& mkdir -p ".java/.userPrefs/${PATH_DRI_1}" \
&& chmod 0700 ".java/.userPrefs" \
&& mkdir -p ".java/.userPrefs/${PATH_CFU}" \
&& echo '<?xml version="1.0" encoding="UTF-8" standalone="no"?>' > ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '<!DOCTYPE map SYSTEM "http://java.sun.com/dtd/preferences.dtd">' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '<map MAP_XML_VERSION="1.0">' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '  <entry key="CheckForUpdates" value="false"/>' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& echo '</map>' >> ".java/.userPrefs/${PATH_CFU}/prefs.xml" \
&& popd

FROM tgbugs/musl:binpkg-only

<<&build-world-common>>

COPY --from=builder /build /

<<&musl-file-user-base>>
#+end_src

Sadly this approach does not work because protege dies before the
reasoner prefs file is written.  Therefore we have to run the image
manually and commit before release. Sigh.
#+begin_src dockerfile
# start protege to generate settings files, have to sleep becuase the
# protege sh wrapper breaks $!
RUN \
protege \
& sleep 6 \
&& kill $(ps | grep java | awk '{ printf $1 }')

# on first run protege doesn't check to see if there is already
# something in this prefs.xml file and appends to it automatically
RUN \
find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q DEFAULT_REASONER_ID {} \; \
-exec sed -i 's/org.protege.editor.owl.NoOpReasoner/org.semanticweb.elk.elk.reasoner.factory/' {} \;

# must use absolute path otherwise command form won't work
WORKDIR /home/${USER_NAME}
#+end_src

In order to get paths that point to the prefs.xml files that we can
embed in the docker file you need the following commands.
#+begin_src bash
printf '%q' $(find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q CheckForUpdates {} \; -print0)
#+end_src

A useful find command for debugging whether the correct reasoner has been set.
#+begin_src bash
find ~/.java/.userPrefs -name 'prefs.xml' -exec grep -q DEFAULT_REASONER_ID {} \; -exec cat {} \;
#+end_src

** NIF-Ontology
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:NIF-Ontology
#+end_src

*** build
# TODO progress prints to stderr
#+name: &musl-build-NIF-ontology
#+begin_src bash
docker build \
--tag tgbugs/musl:NIF-Ontology \
--file musl/NIF-Ontology/Dockerfile musl/NIF-Ontology
#+end_src

*** file
# FIXME composition with protege user issues I think the right way to
# do this is to move to having a single container user image that we
# build and then use COPY --from on that?
#+name: &musl/NIF-Ontology
#+begin_src dockerfile :tangle ./musl/NIF-Ontology/Dockerfile
FROM tgbugs/musl:protege

# phase three ontology
RUN \
pushd ~/ \
;   mkdir git \
;   pushd git \
;       git clone https://github.com/SciCrunch/NIF-Ontology.git \
;       pushd NIF-Ontology \
;           pushd ttl \
;           cp catalog-v001.xml.example catalog-v001.xml \
;       popd \
;   popd
#+end_src

** neurondm
*** run
#+begin_src bash
# to allow the container access to the local x session you have to run the following
xhost local:docker
# use xhost -local:docker to remove

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:neurondm

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:neurondm \
protege
#+end_src

*** build
#+begin_src bash
docker build \
--tag tgbugs/musl:neurondm \
--build-arg ONTOLOGY_GITREF=neurons \
--file musl/neurondm/Dockerfile musl/neurondm
#+end_src

*** file
#+name: &musl/neurondm
#+begin_src dockerfile :tangle ./musl/neurondm/Dockerfile
FROM tgbugs/musl:NIF-Ontology

ARG ONTOLOGY_GITREF=neurons

# phase three ontology
RUN \
pushd ~/git/NIF-Ontology \
;   git checkout ${ONTOLOGY_GITREF} \
;   popd

# phase four python tools
RUN \
pushd ~/ \
;   pushd git \
;       git clone https://github.com/tgbugs/pyontutils.git \
;       pushd pyontutils \
;           pip install --user --break-system-packages -e . \
;           pushd neurondm \
;               pip install --user --break-system-packages -e . \
;           popd \
;       popd \
;   popd
#+end_src

** npo-1.0
*** run
#+begin_src bash
xhost local:docker

docker pull tgbugs/musl:npo-1.0

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0 \
sh -c 'protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src
**** macos notes
#+begin_src bash
brew install virtualbox  # there are some system level persmissions that you will need to set
brew install --cask docker
open -a Docker\ Desktop
# You will need to go to Docker Desktop > Preferences > Resources
# and increase the memory limit to 8 gigs
# otherwise oom killer will end Protege while trying to load npo.ttl

brew install xquartz
open -a XQuartz
# You will need to go to XQuartz > Preferences > Security
# and enable Allow connections from network clients
xhost +localhost
export DISPLAY=:0
# test to make sure everything still works e.g. by running xeyes

docker pull tgbugs/musl:npo-1.0
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=host.docker.internal$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0 \
sh -c 'protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src

Run the block above and once protege starts type =Control R= to run
the reasoner. The docker image is running the Linux version of Protege
so the key bindings use Control instead of Command. You can then run
OWL DL queries in the tab. Note that if you are using the ELK reasoner
(enabled by default in the image) then you will have to click through
a number of warning dialogues, this is normal.

*** build
#+begin_src bash
docker build \
--tag tgbugs/musl:npo-1.0 \
--build-arg ONTOLOGY_GITREF=npo-1.0 \
--file musl/neurondm/Dockerfile musl/neurondm
#+end_src

** npo-1.0-neurondm-build
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--workdir /home/protegeuser/git/NIF-Ontology/ttl \
tgbugs/musl:npo-1.0-neurondm-build \
sh -c 'git stash && protege ~/git/NIF-Ontology/ttl/npo.ttl'
#+end_src
*** build
Build using the SciCrunch SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:npo-1.0-neurondm-build \
--build-arg NEURONS_BRANCH=npo-1.0 \
--build-arg NUID=${UID} \
--secret id=scigraph-api-key,src=<(echo export SCIGRAPH_API_KEY=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api-key"))')) \
--file musl/npo-1.0-neurondm-build/Dockerfile musl/npo-1.0-neurondm-build
#+end_src

Build using an alternate SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:npo-1.0-neurondm-build \
--build-arg NEURONS_BRANCH=npo-1.0 \
--build-arg NUID=${UID} \
--build-arg SCIGRAPH_API=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api"))') \
--secret id=scigraph-api-key,src=<(echo) \
--file musl/npo-1.0-neurondm-build/Dockerfile musl/npo-1.0-neurondm-build
#+end_src
# --build-arg SCIGRAPH_API=http://192.168.1.207:9000/scigraph \

*** file
# FIXME should probably be using a multi source file here instead of
# noweb but I'm not sure we can really do that because the output
# depends on the state of the ontology repo
#+name: &musl/neurondm-build
#+begin_src dockerfile :tangle ./musl/npo-1.0-neurondm-build/Dockerfile
FROM tgbugs/musl:npo-1.0
<<&-base-musl/neurondm-build>>
#+end_src

*** save
This is the image that will be archived to Zenodo for the paper. Note
that the dl queries will not run as expected on this unless you first
stash the changes in =~/git/NIF-Ontology=.

#+begin_src bash
docker save tgbugs/musl:npo-1.0-neurondm-build | gzip > /tmp/npo-1.0-neurondm-build.tar.gz
#+end_src

To restore from the archive run
#+begin_src bash
docker load --input npo-1.0-neurondm-build.tar.gz
#+end_src

The sha256 checksum for npo-1.0-neurondm-build.tar.gz on Zenodo at
doi:10.5281/zenodo.5033493 is
=8e0bb1c684ca8a28f1abeb01ef7aa2597388b8011244f097a92bdd2a523db102=.

** neurondm-build
This image runs the neurondm build process.
*** run
*** build
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:neurondm-build \
--build-arg NUID=${UID} \
--secret id=scigraph-api-key,src=<(echo export SCIGRAPH_API_KEY=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api-key"))')) \
--file musl/neurondm-build/Dockerfile musl/neurondm-build
#+end_src

Build using an alternate SciGraph API endpoint.
#+begin_src bash
# XXX note that NUID does nothing right now
docker build \
--tag tgbugs/musl:neurondm-build \
--build-arg NUID=${UID} \
--build-arg SCIGRAPH_API=$(python -c 'from pyontutils.config import auth; print(auth.get("scigraph-api"))') \
--secret id=scigraph-api-key,src=<(echo) \
--file musl/neurondm-build/Dockerfile musl/neurondm-build
#+end_src

*** file
#+name: &musl/neurondm-build
#+begin_src dockerfile :tangle ./musl/neurondm-build/Dockerfile
FROM tgbugs/musl:neurondm
<<&-base-musl/neurondm-build>>
#+end_src

#+name: &-base-musl/neurondm-build
#+begin_src dockerfile
# phase five build
# XXX FIXME we can't run this for the demonstrator because the lack of
# npokb identifiers causes the queries to fail we probably want two
# separate images for this
ARG SCIGRAPH_API
ARG NEURONS_BRANCH
ARG NUID=11741
# FIXME waiting on https://github.com/moby/buildkit/issues/815
#RUN --mount=type=secret,id=scigraph-api-key,uid=${NUID} \
RUN --mount=type=secret,id=scigraph-api-key,uid=1000 source /run/secrets/scigraph-api-key \
; python -m neurondm.models.allen_cell_types \
; python -m neurondm.models.huang2017 \
; python -m neurondm.models.ma2015 \
; git -C ~/git/NIF-Ontology status
#+end_src

** interlex
*** run
WARNING! If you mount your postgres data directory like this make sure
the host system is NOT also running postgres on top of that directory
otherwise you will have a BAD TIME.
#+begin_src screen
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/files/docker-postgres/interlex-dev:/var/lib/postgresql \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:interlex
#+end_src

*** build
#+name: &musl-build-interlex
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:interlex \
--file musl/interlex/Dockerfile musl/interlex
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/interlex/Dockerfile
FROM tgbugs/musl:binpkg-only

<<&build-world-common>>
#+end_src
*** world
# app-misc/elasticsearch  # XXX license issues, likely must handle separately
# so that we don't taint the profile, probably want a license builder image
# or something, this would allow us to build license tainted software and
# then individual images that want to use it could set the license before
# emerging the binpkg
#+name: world-interlex
#+begin_src conf :tangle ./musl/interlex/world
dev-python/interlex
dev-libs/redland
#+end_src

** blazegraph
*** run
#+begin_src bash
docker run \
-v /var/lib/blazegraph:/var/lib/blazegraph \
-p 9999:9999 \
-it tgbugs/musl:blazegraph
#+end_src
**** services
If you are running on some random system that doesn't already have the images, run the following.
#+begin_src bash :eval never
docker pull tgbugs/sckan:latest
docker pull tgbugs/musl:blazegraph
#+end_src

#+begin_src screen :noweb yes :tangle ./bin/run-sckan-blazegraph.sh
<<&create-sckan-data-if-not-exists>>
docker run \
--detach \
--volumes-from sckan-data \
-p 9999:9999 \
-it tgbugs/musl:blazegraph
#+end_src

#+begin_src bash
docker exec -it $(docker ps -lqf ancestor=tgbugs/musl:blazegraph) tail -f /var/log/blazegraph/sysout.log
#+end_src

*** build
#+name: &musl-build-blazegraph
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:blazegraph \
--file musl/blazegraph/Dockerfile musl/blazegraph
#+end_src

*** file
#+name: &musl/blazegraph
#+begin_src dockerfile :tangle ./musl/blazegraph/Dockerfile
<<&build-world-nox>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
#+name: world-blazegraph
#+begin_src conf :tangle ./musl/blazegraph/world
dev-db/blazegraph-bin
#+end_src

*** entrypoint
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/blazegraph/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/blazegraph start
tail -f /dev/null
#+end_src

** scigraph
*** run
#+begin_src bash
docker run \
-v /var/lib/scigraph:/var/lib/scigraph \
-p 9000:9000 \
tgbugs/musl:scigraph
#+end_src

*** build
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:scigraph \
--file musl/scigraph/Dockerfile musl/scigraph
#+end_src

*** file
#+name: &musl/scigraph
#+begin_src dockerfile :tangle ./musl/scigraph/Dockerfile
<<&build-world>>
ADD entrypoint.sh /etc/entrypoint.sh
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** world
#+name: world-scigraph
#+begin_src conf :tangle ./musl/scigraph/world
dev-java/scigraph-bin
#+end_src

*** entrypoint
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/scigraph/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
rc-service scigraph start
#+end_src

** kg-release
Base environment for knowledge graph distribution and interaction.
Combines both server and client functionalities into a single image.
In principle this could be split into multiple images, but for the
sake of simplicity and reproducibility it is a single image.

*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-release
#+end_src

*** build
#+name: &musl-build-kg-release
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:kg-release \
--file musl/kg-release/Dockerfile musl/kg-release
#+end_src

*** file
# when deriving from multiple parent worlds docker does not compose
# well at all, so we have to pick a primary world line so to speak
#+name: &musl/kg-release
#+begin_src dockerfile :tangle ./musl/kg-release/Dockerfile
FROM tgbugs/musl:emacs

<<&build-world-common>>
#+end_src

*** world
#+name: world-kg-release
#+begin_src conf :tangle ./musl/kg-release/world
<<world-emacs>>
dev-db/blazegraph-bin
dev-java/scigraph-bin
media-gfx/feh
media-gfx/graphviz
dev-python/ipykernel
dev-python/pip
dev-haskell/dot2graphml
x11-misc/xdg-user-dirs
#+end_src
# dev-python/jupyter_server is not needed, dev-python/ipykernel is sufficient for our limited emacs-jupyter use case

# TODO consider including for the python bits in queries
# dev-python/pyontutils-9999
# dev-python/nifstd-tools-9999

** kg-release-user
*** run
**** default
Quick link to [[&create-sckan-data]] useful if =sckan-data= has not
been created or was wiped in a purge.

#+begin_src screen
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-release-user
#+end_src

with configuration for xdg-open forwarding
#+begin_src screen
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src

debug with network in bridge mode
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--add-host local.binhost:127.0.0.1 \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src

debug with host network
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--add-host local.binhost:127.0.0.1 \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--add-host=host.docker.internal:host-gateway \
--network=host \
-e FORWARD_URL_HOST=host.docker.internal \
-e FORWARD_URL_PORT=59213 \
-it tgbugs/musl:kg-release-user
#+end_src
**** services
***** blazegraph
#+begin_src screen :noweb yes
<<&create-sckan-data-if-not-exists>>
docker run \
--detach \
--volumes-from sckan-data \
-v ${PWD}/musl/kg-release-user/entrypoints/blazegraph.sh:/etc/entrypoints/blazegraph.sh \
--entrypoint /etc/entrypoints/blazegraph.sh \
-p 9999:9999 \
-it tgbugs/musl:kg-release-user
#+end_src

To follow the logs you can run the following.
#+begin_src bash
docker exec -it $(docker ps -lqf ancestor=tgbugs/musl:kg-release-user) tail -f /var/log/blazegraph/sysout.log
#+end_src

***** both
#+begin_src screen :noweb yes :tangle ./bin/run-sckan-services.sh
<<&create-sckan-data-if-not-exists>>
docker run \
--volumes-from sckan-data \
-v ${PWD}/musl/kg-release-user/entrypoints/services.sh:/etc/entrypoints/services.sh \
--entrypoint /etc/entrypoints/services.sh \
-p 9999:9999 \
-p 9000:9000 \
-it tgbugs/musl:kg-release-user
#+end_src
*** test
#+name: &test-kg-release-user
#+begin_src screen
<<&create-sckan-data-if-not-exists>>
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-v ${PWD}/musl/kg-release-user/entrypoints/test.sh:/etc/entrypoints/test.sh \
--entrypoint /etc/entrypoints/test.sh \
--rm \
-it tgbugs/musl:kg-release-user
#+end_src
*** build
# FIXME move this into a container
#+name: &musl-build-kg-release-user
#+begin_src screen
unset _devel _docd _sckand _docsfsc
_devel=
_docd=(queries.org)
_docsf="https://raw.githubusercontent.com/SciCrunch/sparc-curation/master/docs/"
_sckand=(welcome.org tutorial.org overview.org examples.org scratch.org README.org)
_docsfsc="${_docsf}sckan/"
pushd ./musl/kg-release-user
  [ -d sckan ] && rm -r sckan
  mkdir sckan
  pushd sckan
    mkdir images
    mkdir reports
    if [ -n "${_devel}" ]; then
      cp -aL ~/git/sparc-curation/docs/sckan/*.org . ;
    else
      for fn in ${_docd[@]};   do curl -O ${_docsf}${fn}  ; done
      for fn in ${_sckand[@]}; do curl -O ${_docsfsc}${fn}; done
    fi
    chmod +x ./queries.org
  popd
popd

<<&musl-build-kg-release-user-min>>
#+end_src

#+name: &musl-build-kg-release-user-min
#+begin_src screen
docker build \
--tag tgbugs/musl:kg-release-user \
--build-arg UID=${UID} \
--file musl/kg-release-user/Dockerfile musl/kg-release-user
#+end_src

*** entrypoints
Default interactive entrypoint.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
su user -c 'emacs -geometry 120x40 -eval "(find-file-noselect (pop argv))" ~/sckan/welcome.org'
/etc/init.d/scigraph stop
/etc/init.d/blazegraph stop
#+end_src

Entrypoint to start blazegraph and run in the background.
# FIXME BUILDKIT_PROGRESS='plain' leaking through here somehow but now on orpheus when it tangles?
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/entrypoints/blazegraph.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/blazegraph start
tail -f /dev/null
#+end_src

Entrypoint to start services and run in the background.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/entrypoints/services.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
tail -f /dev/null
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-release-user/entrypoints/test.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel

# check that services are working as expected
/etc/init.d/scigraph start
SCIG_OOPS=$?
/etc/init.d/blazegraph start
BLAZ_OOPS=$?
[ ${SCIG_OOPS} -eq 0 ] && [ ${BLAZ_OOPS} -eq 0 ] || { echo scigraph ${SCIG_OOPS} and blazegraph ${BLAZ_OOPS} failed to start; exit 1;}
[ ${SCIG_OOPS} -eq 0 ] || { echo scigraph failed to start; exit 2;}
[ ${BLAZ_OOPS} -eq 0 ] || { echo blazegraph failed to start; exit 3;}

# check elisp config
su user -c 'sckan/queries.org test config' || { echo basic config test failed cannot continue; exit 4;}
# run data sanity check queries
su user -c 'sckan/queries.org test query neurons datasets protocols' || { echo at least one query test failed; exit 5;}
#+end_src

*** file
# FIXME we should be able to stash the builder in this image
# and reuse it without having to rerun over and over ...
#+name: kg-root-password
: sparcSCKAN-2021

#+name: &musl/kg-release-user
#+begin_src dockerfile :tangle ./musl/kg-release-user/Dockerfile
FROM tgbugs/musl:kg-release as builder

WORKDIR /build

<<&user-skel-common>>

ARG HOME=/build/home/${USER_NAME}

WORKDIR $HOME

COPY --chown=${UID}:${UID} sckan sckan

USER ${USER_NAME}

RUN \
xdg-user-dirs-update

RUN \
sed -i 's/-no-site-file//' ./sckan/queries.org \
&& ./sckan/queries.org

RUN \
pushd ./.emacs.d/ \
&& ln -s reval/cache/*/*-ow.el ow.el

ADD --chown=1000:1000 early-init.el ./.emacs.d/early-init.el
ADD --chown=1000:1000 init.el ./.emacs.d/init.el

RUN \
emacs -batch -eval \
"(let ((user-init-file (pop argv))) (load (pop argv)) (load user-init-file) (while argv (let ((f (pop argv))) (orgstrap-whitelist-file f) (kill-buffer (find-file-noselect f)))) (ow-use-packages evil undo-tree))" \
$HOME/.emacs.d/init.el $HOME/.emacs.d/early-init.el sckan/{queries,welcome,examples,scratch,tutorial}.org

FROM tgbugs/musl:kg-release

COPY --from=builder /build /

ADD entrypoints /etc/entrypoints
ADD entrypoint.sh /etc/entrypoint.sh

<<&musl-file-user-base>>

USER 0

RUN \
usermod -a -G blazegraph user \
;  usermod -a -G scigraph user \
;  usermod -a -G wheel user

RUN \
echo 'root:<<kg-root-password()>>' | chpasswd

# make it easier to use portage inside a container
RUN \
echo 'EMERGE_DEFAULT_OPTS=""' >> /etc/portage/make.conf \
&& echo 'FEATURES=""' >> /etc/portage/make.conf

# TODO when running this you will have to set the right mounts
# unless you bake a new kg-dev-with-data release
ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** emacs init
Must disable early loading of =package.el= because it makes it
impossible for site-lisp to add packages which breaks the activation
of any dependent packages.
#+begin_src elisp :tangle ./musl/kg-release-user/early-init.el
(setq package-enable-at-startup nil)
#+end_src
Calling =ow-enable-use-package= makes it possible to load site-lisp
and call =package-initialize= with =no-activate= set so that site
dependencies can be loaded correctly. This is all a dance to work
around the fundamentally broken design of =normal-top-level= and
=early-init= with regard to site-lisp.
#+begin_src elisp :tangle ./musl/kg-release-user/init.el
(load (expand-file-name "ow.el" user-emacs-directory))
(ow-enable-use-package nil '(vterm zmq))
#+end_src
** kg-dev
:PROPERTIES:
:CUSTOM_ID: kg-dev
:END:
*** run
# scigraph-build-local
# scigraph-deploy-local
# TODO package ontree server so that the updated local scigraph can be seen
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev
#+end_src

#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v /tmp/scigraph-build:/tmp/scigraph-build \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev \
echo TODO secrets, apinat build and more!
#+end_src

debug
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
--network host \
--add-host local.binhost:127.0.0.1 \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev
#+end_src

*** build
#+name: &musl-build-kg-dev
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:kg-dev \
--build-arg UID=${UID} \
--file musl/kg-dev/Dockerfile musl/kg-dev
#+end_src

*** world
#+name: world-kg-dev
#+begin_src conf :tangle ./musl/kg-dev/world
<<world-kg-release>>
<<world-sbcl-base>>
<<world-tex>>
app-arch/zip
app-misc/screen
app-misc/yq
app-text/pandoc
dev-java/robot-bin
dev-node/apinat-converter
dev-python/nifstd-tools
dev-python/sparcur
dev-db/redis
net-misc/rabbitmq-server
dev-scheme/racket
dev-util/shellcheck
net-libs/nodejs
dev-python/seaborn
#+end_src
# FIXME pandoc is a dev-python/nifstd-tools doc dep :/
# FIXME seaborn for generating figures, not clear whether this is the right place, but here for now

# FIXME and here we are having an annoying time
# with nifstd-tools and variant use flags sigh
# maybe build both versions of the package somehow
# without creating yet another profile variant

# FIXME issue with robot-bin building against openjdk-bin-17
# and then running against openjdk-17, that shouldn't matter
# but it seems that something got baked in by accident

# we include pennsieve in world here because
# it cannot be installed via pip due to a completely
# braindead handling of 2.7 vs 3.0 issues

#+name: world-tex
#+begin_src conf
app-text/texlive
dev-tex/biblatex
dev-tex/latexmk
dev-texlive/texlive-latexextra
dev-texlive/texlive-luatex
dev-texlive/texlive-music
#+end_src
We specify =texlive-latexextra= and =texlive-music= explicitly instead
of as use flags on texlive to avoid pulling in xetex as a dependency.

*** file
#+name: &musl/kg-dev
#+begin_src dockerfile :tangle ./musl/kg-dev/Dockerfile
FROM tgbugs/musl:kg-release
<<&build-world-common>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
eselect racket set cs
#+end_src

** kg-dev-user
:PROPERTIES:
:CUSTOM_ID: kg-dev-user
:END:
# FIXME somehow missing blazegraph user?
*** run
# TODO -v /var/lib/scigraph:/var/lib/scigraph \
reminder: localhost:9000 tells the image to use its own internal
scigraph not the host scigraph specifically it prevents it from using
the scicrunch production api endpoint
#+begin_src screen
# docker create -v /var/lib/blazegraph -v /var/lib/scigraph --name sckan-data tgbugs/sckan:latest /bin/true
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-e SCIGRAPH_API=http://localhost:9000/scigraph \
-it tgbugs/musl:kg-dev-user

#+end_src

Example of how to use the image for the SCKAN release workflow.
#+begin_src bash
docker run \
--volumes-from sckan-data \
-v /tmp/build:/tmp/build \
-v /tmp/scigraph-build:/tmp/scigraph-build \
-v /home/tom/.ssh:/home/user/.ssh \
-v /home/tom/.ssh_tmp:/home/user/.ssh_tmp \
-v /home/tom/git/misc:/home/user/git/misc \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v $(dirname ${SSH_AUTH_SOCK}):$(dirname ${SSH_AUTH_SOCK}) \
-e SSH_AUTH_SOCK=${SSH_AUTH_SOCK} \
-e SSH_AGENT_PID=${SSH_AGENT_PID} \
-e DISPLAY=$DISPLAY \
-e SCIGRAPH_API=http://localhost:9000/scigraph \
-it tgbugs/musl:kg-dev-user
#+end_src

#+begin_src screen
docker run \
-v /var/lib/blazegraph:/var/lib/blazegraph \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:kg-dev-user
#+end_src

*** test
#+name: &test-kg-dev-user
#+begin_src screen
<<&create-sckan-data-if-not-exists>>
docker run \
--volumes-from sckan-data \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-e SCIGRAPH_API=http://localhost:9000/scigraph \
-v ${PWD}/musl/kg-dev-user/entrypoints/test.sh:/etc/entrypoints/test.sh \
--entrypoint /etc/entrypoints/test.sh \
--rm \
-it tgbugs/musl:kg-dev-user
#+end_src
*** build
#+name: &musl-build-kg-dev-user
#+begin_src screen
docker build \
--tag tgbugs/musl:kg-dev-user \
--build-arg UID=${UID} \
--file musl/kg-dev-user/Dockerfile musl/kg-dev-user
#+end_src

*** entrypoint
#+begin_src bash
if [ -d /tmp/blazegraph ]; then
    cp /tmp/blazegraph/blazegraph.jnl /var/lib/blazegraph/
    cp /tmp/blazegraph/prefixes.conf /var/lib/blazegraph/
    chown -R blazegraph:blazegraph /var/lib/blazegraph
fi
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-dev-user/entrypoint.sh :mkdirp yes
rc-status
touch /run/openrc/softlevel
/etc/init.d/scigraph start
/etc/init.d/blazegraph start
#su user -c 'emacs -visit ~/git/sparc-curation/docs/queries.org'
su user -
/etc/init.d/scigraph stop
/etc/init.d/blazegraph stop
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-dev-user/entrypoints/sync.sh :mkdirp yes
/etc/init.d/scigraph start
# do prrequaestor things
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-dev-user/entrypoints/test.sh :mkdirp yes
echo TODO testing ...
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/kg-dev-user/entrypoints/sckan-release.sh :mkdirp yes
su user -c 'sh ~/git/sparc-curation/docs/developer-guide.org sckan-release'
#+end_src

*** file
# XXX note that using builder means that the command history
# that is used to create the /build/ directory are lost
# sigh bad trade offs for multi stage builds
# HOORAY pip install --user -e and /build/ are incompatable! >_<
#+name: &emacs-sanity
#+begin_src dockerfile
ARG INIT_URL=https://raw.githubusercontent.com/tgbugs/orgstrap/master/init-simple.el

RUN \
emacs --batch --quick --eval \
"(progn (setq ow-site-packages '(vterm zmq)) (url-handler-mode 1) (find-file (pop argv)) (eval-buffer))" \
"${INIT_URL}"

RUN \
pushd ~/.emacs.d \
&& ln -s reval/cache/*/*-ow.el ow.el \
&& ln -s reval/cache/*/*-reval.el reval.el \
&& ln -s reval/cache/*/*-init-content.el init-content.el \
&& echo "(setq package-enable-at-startup nil)" >> early-init.el \
&& echo "(defvar ow-site-packages '(vterm zmq))" >> init.el \
&& echo "(load (expand-file-name \"ow.el\" user-emacs-directory))" >> init.el \
&& echo "(load (expand-file-name \"reval.el\" user-emacs-directory))" >> init.el \
&& echo "(load (expand-file-name \"init-content.el\" user-emacs-directory))" >> init.el \
&& popd
#+end_src

#+begin_src dockerfile :tangle ./musl/kg-dev-user/Dockerfile
FROM tgbugs/musl:kg-dev as builder

WORKDIR /build

<<&user-skel-common>>

RUN \
usermod --move-home --home /home/user ${USER_NAME}
#mv /build/home/user /home/ \
#&& usermod -d /home/user -m

USER ${USER_NAME}

#ARG HOME=/build/home/${USER_NAME}  # FIXME somehow /build/ lingers ??? do I have a stale file !?? !
# XXX the issue is &user-skel-common uses /build/home/user in useradd with the expectation that
# it will not affect the actual image only the builder image
# FIXME XXXXXXXXXXXXXXXXXXXXXX SO SO SO SO BROKEN ARGH this breaks emacs and everything else
# it looks like /etc/passwd still has /build/home/user as HOME so setting $HOME doesn't save us?
# at least during debug that is what it looks like
ARG HOME=/home/${USER_NAME}

WORKDIR $HOME

RUN \
xdg-user-dirs-update

<<&emacs-sanity>>

RUN \
mkdir ~/git \
&& mkdir ~/.ssh_tmp \
&& chmod 0700 ~/.ssh_tmp

# FIXME that is going to need to go in .bashrc or something
ENV PYTHONPYCACHEPREFIX=${HOME}/.cache/pycache/

# FIXME break these into their own images to avoid serial dependencies

# FIXME pip install --user -e . fails when run in /build/ due to change in $HOME
# because it uses an expanded directory of course pip doesn't have any only-deps
# option

RUN \
pushd git \
&&     git clone https://github.com/tgbugs/pyontutils.git \
&&     git clone https://github.com/SciCrunch/sparc-curation.git \
&& popd

RUN \
pushd git \
&&     pushd pyontutils \
&&         python -m pip install --user --break-system-packages -e . \
&&         pypy3 -m pip install --user --break-system-packages -e . \
&&         pushd nifstd \
&&             python setup.py --release || true \
&&             python -m pip install --user --break-system-packages -e . \
&&             pypy3 -m pip install --user --break-system-packages -e . \
&&         popd \
&&     popd \
&&     pushd sparc-curation \
&&         python setup.py --release || true \
&&         python -m pip install --user --break-system-packages -e . \
&&         pypy3 -m pip install --user --break-system-packages -e . \
&&     popd \
&& popd \
&& ln -s ../../git/sparc-curation/docs/apinatomy.org ~/.local/bin/apinat-build \
&& rm -r ~/.cache/pip

RUN \
sh ./git/pyontutils/nifstd/scigraph/README.org --tangle

RUN \
./git/sparc-curation/docs/queries.org

RUN \
./git/sparc-curation/docs/apinatomy.org

RUN \
emacs -batch -eval \
"(let ((user-init-file (pop argv))) (package-initialize) (while argv (orgstrap-whitelist-file (pop argv))))" \
$HOME/.emacs.d/init.el \
./git/sparc-curation/docs/queries.org \
./git/sparc-curation/docs/apinatomy.org

FROM tgbugs/musl:kg-dev

COPY --from=builder /home/${USER_NAME} /home/${USER_NAME}

ADD entrypoints /etc/entrypoints
ADD entrypoint.sh /etc/entrypoint.sh

<<&musl-file-user-base>>

ENV PATH="/home/${USER_NAME}/.local/bin:${PATH}"

# XXX somehow this induces ~10MB of new content !??!
#RUN \
#pip install --user --no-deps -e \
#git/pyontutils/nifstd \
#git/sparc-curation \
#&& rm -r ~/.cache/pip

USER 0

RUN \
usermod -a -G blazegraph user \
;  usermod -a -G scigraph user \
;  usermod -a -G wheel user

RUN \
echo 'root:<<kg-root-password()>>' | chpasswd

# make it easier to use portage inside a container
RUN \
echo 'EMERGE_DEFAULT_OPTS=""' >> /etc/portage/make.conf \
&& echo 'FEATURES=""' >> /etc/portage/make.conf

# TODO when running this you will have to set the right mounts
# unless you bake a new kg-dev-with-data release
ENTRYPOINT /etc/entrypoint.sh
#+end_src
** racket
*** build
#+name: &musl-build-racket
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:racket \
--file musl/racket/Dockerfile musl/racket
#+end_src

Build debug workflow.
#+begin_src bash
# if you have not done so already
docker create \
-v /var/db/repos/gentoo \
--name local-portage-snap \
gentoo/portage:latest \
/bin/true

# if you have you have to clear the container with
# docker rm local-portage-snap

# then
docker run \
--volumes-from local-portage-snap \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:racket
#+end_src

*** file
#+name: &musl/racket
#+begin_src dockerfile :tangle ./musl/racket/Dockerfile
FROM tgbugs/musl:emacs
<<&build-world-common>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
eselect racket set cs
#+end_src

*** world
#+name: world-racket
#+begin_src conf :tangle ./musl/racket/world
<<world-emacs>>
dev-scheme/racket
#+end_src
** racket-user
*** run
#+begin_src bash
# to allow the container access to the local x session you have to run the following
xhost local:docker
# use xhost -local:docker to remove

docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:racket-user
#+end_src

*** build
#+name: &musl-build-racket-user
#+begin_src bash
docker build \
--tag tgbugs/musl:racket-user \
--build-arg UID=${UID} \
--file musl/racket-user/Dockerfile musl/racket-user
#+end_src

*** file
#+name: &musl/racket-user
#+begin_src dockerfile :tangle ./musl/racket-user/Dockerfile
FROM tgbugs/musl:racket

COPY --from=tgbugs/common:user / /

<<&musl-file-user-base>>
#+end_src

** dynapad-base
*** build
#+name: &musl-build-dynapad-base
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:dynapad-base \
--file musl/dynapad-base/Dockerfile musl/dynapad-base
#+end_src
*** file
#+name: &musl/dynapad-base
#+begin_src dockerfile :tangle ./musl/dynapad-base/Dockerfile
FROM tgbugs/musl:racket
<<&build-world-common>>
#+end_src

*** world
#+name: world-dynapad-base
#+begin_src conf :tangle ./musl/dynapad-base/world
<<world-racket>>
dev-libs/libconfig
sys-libs/db
dev-lang/tk
media-gfx/imagemagick
app-text/poppler
#+end_src
** dynapad-user
*** build
#+name: &musl-build-dynapad-user
#+begin_src bash
docker build \
--tag tgbugs/musl:dynapad-user \
--build-arg UID=${UID} \
--file musl/dynapad-user/Dockerfile musl/dynapad-user
#+end_src

*** file
#+name: &musl/dynapad-user
#+begin_src dockerfile :tangle ./musl/dynapad-user/Dockerfile
FROM tgbugs/musl:dynapad-base

COPY --from=tgbugs/common:user / /

<<&musl-file-user-base>>
#+end_src

** dynapad
*** run
Once you have created the =tgbugs/musl:dynapad= image (see the build
section below) you can use this command to run it and commit on close
each time so as not to lose any work. You will probably want to mount
any additional directories you will need .e.g for images using =-v=.

**** linux
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:dynapad \
sh -c 'pushd ~/git/dynapad && racketcgc -it apps/paddraw/paddraw.rkt'

# docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src
**** macos
See [[#macos-notes][macos notes]] for notes on getting docker working
with XQuartz.  Assuming everything is set up correctly you can the run
the following.
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-e DISPLAY=host.docker.internal:0 \
-it tgbugs/musl:dynapad \
sh -c 'pushd ~/git/dynapad && racketcgc -it apps/paddraw/paddraw.rkt'

# docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src

#+begin_src bash
xattr -d -r -s com.apple.quarantine /Applications/Docker.app
#+end_src

*** build
Since we need to mount the git directory from outside the image we
can't use a docker file. Commit the image after these steps are
finished (the commands above do that automatically).

If your UID is something other than 1000 you will probably want to
rebuild =tgbugs/musl:dynapad-user= so that your UID matches.

#+begin_src bash
docker pull tgbugs/musl:dynapad-user

docker run \
-v ~/git/dynapad:/home/dynapad/git/dynapad \
-it tgbugs/musl:dynapad-user
docker commit $(docker ps -lq) tgbugs/musl:dynapad
#+end_src

In the image run the following and then exit, the commit will be made
automatically. *NOTE* You may need to remove =build_musl= if it
already exists.

#+begin_src bash
function dynapad-build-all () {
local build_dir SUBPATH SO_SUFFIX
#local PATH
#PATH=~/git/NOFORK/racket/racket/bin/:/usr/bin:/bin
# command -v racketcgc
# command -v racocgc
build_dir=${1:-build}
    mkdir ${build_dir}
    pushd ${build_dir}
        cmake .. -G Ninja -DCMAKE_BUILD_TYPE=Debug || return $?
        ninja || return $?
    popd
    SUBPATH=$(racketcgc -e "(display (path->string (system-library-subpath)))")
    SO_SUFFIX=$(racketcgc -e "(display (bytes->string/utf-8 (system-type 'so-suffix)))")
    mkdir -p dynapad/compiled/bc/native/${SUBPATH}
    racocgc ctool --cgc \
            ++ldf -Wl,-rpath,"${PWD}/${build_dir}/" \
            --ld dynapad/compiled/bc/native/${SUBPATH}/libdynapad_rkt${SO_SUFFIX} \
            "${PWD}/${build_dir}/libdynapad${SO_SUFFIX}"
    racocgc pkg install dynapad-collects/ dynapad/
    racocgc make apps/paddraw/paddraw.rkt
    racocgc make apps/uberapp/uberapp.rkt
}
#+end_src

#+begin_src bash
dynapad-build-all build_musl
#+end_src

** sparcron
:PROPERTIES:
:CUSTOM_ID: sparcron
:END:
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:sparcron
#+end_src

*** build
#+name: &musl-build-sparcron
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:sparcron \
--file musl/sparcron/Dockerfile musl/sparcron
#+end_src

*** file
# when deriving from multiple parent worlds docker does not compose
# well at all, so we have to pick a primary world line so to speak
#+name: &musl/sparcron
#+begin_src dockerfile :tangle ./musl/sparcron/Dockerfile
FROM tgbugs/musl:binpkg-only

<<&build-world-common>>

RUN echo 1  # if you need to remerge without the world bump the number (ref:sparcron-echo)

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN dev-python/sparcur \
<<&archive-or-rm>>
#+end_src

*** world
# FIXME sparcur ebuild could pull this all in under test + cron or
# something like that , but the variant use flags issue rears its head,
# and more to the point, redis and rabbitmq-server could be running
# elsewhere and are requirements for this image, or meta ebuild but not
# actually for sparcur. In principle We could move to managing some of
# these world files as meta ebuilds in some cases.
# TODO probably don't need pip anymore except for debug?
# FIXME ideally we wouldn't need xdg-user-dirs at runtime, only during build
# but that would likely require the use of a generic builder instead of
# reuse of the base image for the -user variant as the builder
#+name: world-sparcron
#+begin_src conf :tangle ./musl/sparcron/world
dev-db/redis
dev-python/pip
dev-python/sparcur
net-misc/rabbitmq-server
www-servers/uwsgi
x11-misc/xdg-user-dirs
#+end_src

** sparcron-user
:PROPERTIES:
:CUSTOM_ID: sparcron-user
:END:
*** run
# FIXME SIGH yes indeed chown modifies the parent system permissions
# somehow this doesn't surprise me given how janky docker is in here
To run as a daemon use =-d= option in then =docker ps= to get the
container id, and then =docker logs -f= the container.

Development =docker run= example.
#+begin_src screen
_f=$(basename ~/ni/dev/sparc-curation-*.json)
_h=protocols-io-api-token-rw.pickle
docker run \
-v /var/lib/sparc/files:/var/lib/sparc/files \
-v /var/lib/sparc/.local/share/sparcur:/var/lib/sparc/.local/share/sparcur \
-v /var/lib/sparc/.cache:/var/lib/sparc/.cache \
-v /var/lib/sparc/.config/sparcur/docker-config.yaml:/var/lib/sparc/.config/sparcur/config.yaml \
-v ~/ni/dev/secrets-sparcron.yaml:/var/lib/sparc/.config/orthauth/secrets.yaml \
-v ~/ni/dev/${_f}:/var/lib/sparc/.config/orthauth/${_f} \
-v ~/ni/dev/${_h}:/var/lib/sparc/.config/orthauth/${_h} \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-e SCIGRAPH_API=http://192.168.1.207:9000/scigraph \
-it tgbugs/musl:sparcron-user
#+end_src

Production =docker run= example. Must be run as root.
#+name: &run-sparcron
#+begin_src screen
function docker-run-sparcron () {
_f=$(su sparc -c 'basename /var/lib/sparc/.config/pyontutils/sparc-curation-*.json')
_h=protocols-io-api-token-rw.pickle
docker run \
-d \
-v /var/lib/sparc/files:/var/lib/sparc/files \
-v /var/lib/sparc/.local/share/sparcur:/var/lib/sparc/.local/share/sparcur \
-v /var/lib/sparc/.cache:/var/lib/sparc/.cache \
-v /var/lib/sparc/.config/sparcur/docker-config.yaml:/var/lib/sparc/.config/sparcur/config.yaml \
-v /var/lib/sparc/.config/pyontutils/secrets.yaml:/var/lib/sparc/.config/orthauth/secrets.yaml \
-v /var/lib/sparc/.config/pyontutils/${_f}:/var/lib/sparc/.config/orthauth/${_f} \
-v /var/lib/sparc/.config/pyontutils/${_h}:/var/lib/sparc/.config/orthauth/${_h} \
-e SCIGRAPH_API=https://scigraph.olympiangods.org/scigraph \
-e UWSGI_SOCKET_SPARCRON=0.0.0.0:7260 \
-p 7260:7260 \
-it tgbugs/musl:sparcron-user
}
#+end_src

Production image restart.
#+name: &restart-sparcron
#+begin_src bash
function docker-restart-sparcron () {
_image=tgbugs/musl:sparcron-user
_cid_old=$(docker ps -lqf ancestor=${_image} -f status=running)
docker stop ${_cid_old} || return $?
docker-run-sparcron
_cid_new=$(docker ps -lqf ancestor=${_image_new})
docker logs -f ${_cid_new}
}
#+end_src

Production image upgrade.
#+name: &upgrade-sparcron
#+begin_src bash
function upgrade-sparcron () {
_image=tgbugs/musl:sparcron-user
_image_new=${_image}
_image_date=$(date -I --date $(docker inspect ${_image} --format '{{.Created}}'))
_cid_old=$(docker ps -lqf ancestor=${_image} -f status=running)
docker tag ${_image} ${_image}-${_image_date}
docker pull ${_image_new} || return $?
docker stop ${_cid_old} || return $?
docker-run-sparcron
_cid_new=$(docker ps -lqf ancestor=${_image_new})
docker logs -f ${_cid_new}
}
#+end_src

Production image archive.
#+begin_src bash :eval never :dir /su::
for img in $(docker image ls tgbugs/musl:sparcron-user-* --format '{{.Repository}}:{{.Tag}}'); do
docker save "${img}" | gzip > /mnt/str/sparc/docker-images/"${img//\//-}".tar.gz
done

for img in $(docker image ls tgbugs/musl:sparcron-user-* --format '{{.Repository}}:{{.Tag}}' | sort | head -n -1); do
docker image rm "${img}" || break
done
#+end_src
**** An example of how to rapidly redeploy changes using the tools here.
1. There is a bug. Oh no! e.g. you forgot to bump __internal_version__ so nothing reruns.
2. Chance sparcur code, commit, push.
3. bump ~echo~ in [[(sparcron-echo)]]
4. ~C-ucvt~ aka src_elisp[:eval never]{(org-babel-tangle '(4))} or ~./source.org tangle~

On the build machine.
#+begin_src bash :noweb yes
builder-arb --getbinpkg=y --onlydeps --onlydeps-with-rdeps=n sparcur
builder-arb --nodeps sparcur

<<&musl-build-sparcron>> &&

<<&musl-build-sparcron-user>> &&
docker push tgbugs/musl:sparcron; docker push tgbugs/musl:sparcron-user
#+end_src

On prod as root.
#+begin_src bash :noweb yes :eval never
<<&run-sparcron>>
<<&upgrade-sparcron>>
upgrade-sparcron
#+end_src

*** test
Since tests currently use screen, the suggestion mentioned in
=*musl**package-builder***run= to add the =_path_= vars to your shell
rc file (e.g. [[~/.bashrc]]) applies here as well. In the future if we
move away from using =ob-screen= then passing via =--user-init-file=
on the command line is also and option.
#+name: &test-sparcron-user
#+begin_src screen
<<&screen-set-vars>>
docker run \
\
-v ${_path_sparcron_sparcur_config}:/var/lib/sparc/.config/sparcur/config.yaml \
-v ${_path_sparcron_secrets}:/var/lib/sparc/.config/orthauth/secrets.yaml \
-v ${_path_sparcron_gsaro}:/var/lib/sparc/.config/orthauth/$(basename ${_path_sparcron_gsaro}) \
\
-v ${PWD}/musl/sparcron-user/entrypoints/test.sh:/etc/entrypoints/test.sh \
--entrypoint /etc/entrypoints/test.sh \
--rm \
-it tgbugs/musl:sparcron-user
#+end_src
**** unused :noexport:
Since we are passing these via ref:&screen-set-vars at the moment we
do not need these, and if we switch to running via bash or something
then we can use =:var _path_sparcron_sparcur_config=asdf= directly.
#+name: &var-sparcron-sparcur-config
#+begin_src elisp
path-sparcron-sparcur-config
#+end_src

#+name: &var-sparcron-secrets
#+begin_src elisp
path-sparcron-secrets
#+end_src

#+name: &var-sparcron-gsaro
#+begin_src elisp
path-sparcron-gsaro
#+end_src
*** build
#+name: &musl-build-sparcron-user
#+begin_src screen
docker build \
--tag tgbugs/musl:sparcron-user \
--file musl/sparcron-user/Dockerfile musl/sparcron-user
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/sparcron-user/Dockerfile
FROM tgbugs/musl:sparcron

ADD --chown=836:836 idlib-config.yaml /var/lib/sparc/.config/idlib/config.yaml
ADD --chown=836:836 sparcur-config.yaml /var/lib/sparc/.config/sparcur/config.yaml

ARG HOME=/var/lib/sparc

WORKDIR $HOME

RUN \
su "$(id -nu 836)" -c "xdg-user-dirs-update"

ADD entrypoints /etc/entrypoints
ADD entrypoint.sh /etc/entrypoint.sh

ENTRYPOINT /etc/entrypoint.sh
#+end_src

*** configs
This config provides sane defaults, if you need to add a section (such
as a =datasets-no:=) then use =-v= in docker run to mount over the
location of this file.
#+begin_src yaml :tangle ./musl/sparcron-user/sparcur-config.yaml
auth-stores:
  secrets:
    path: '{:user-config-path}/orthauth/secrets.yaml'
auth-variables:
  google-api-service-account-file-readonly:
    path: google api saro
  hypothesis-api-key: hypothesis api default-user
  hypothesis-group: hypothesis group sparc-curation
  remote-organization: N:organization:618e8dd9-f8d2-4dc4-9abb-c6aaab2e78a0
#+end_src

# TODO
#+begin_src yaml :tangle ./musl/sparcron-user/idlib-config.yaml
auth-stores:
  secrets:
    path: '{:user-config-path}/orthauth/secrets.yaml'
auth-variables:
  protocols-io-api-creds-file:
    path: protocols-io api creds-file
  protocols-io-api-store-file:
    path: protocols-io api store-file
#+end_src

*** entrypoints
# https://forums.gentoo.org/viewtopic-t-1014086-start-0.html
# sigh this really doesn't need the net admin cap just to start rabbit
Slowly inching toward being able to run this via a service manager.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/sparcron-user/entrypoint.sh :mkdirp yes
if [ -n "${UWSGI_SOCKET_SPARCRON}" ]; then
    echo "UWSGI_SOCKET_SPARCRON=${UWSGI_SOCKET_SPARCRON}" >> /etc/conf.d/sparcron-server
fi

rc-status
touch /run/openrc/softlevel
/etc/init.d/redis start
/etc/init.d/rabbitmq start
/etc/init.d/sparcron-server start

# testing and ensure that there is an existing cache on first run
su sparc -c 'pypy3 -m sparcur.sparcron'

su sparc -c 'EPYTHON=pypy3 PYTHONBREAKPOINT=0 celery --app sparcur.sparcron worker -n wcron -Q cron,default --concurrency=1 --beat --schedule-filename ./sparcur-cron-schedule --loglevel=INFO' &

su sparc -c 'EPYTHON=pypy3 PYTHONBREAKPOINT=0 celery --app sparcur.sparcron worker -n wexport -Q export --loglevel=INFO'
# FIXME missing rmeta stuff ?

#/etc/init.d/redis stop
#/etc/init.d/rabbitmq stop
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./musl/sparcron-user/entrypoints/test.sh :mkdirp yes
if [ -n "${UWSGI_SOCKET_SPARCRON}" ]; then
    echo "UWSGI_SOCKET_SPARCRON=${UWSGI_SOCKET_SPARCRON}" >> /etc/conf.d/sparcron-server
fi

rc-status
touch /run/openrc/softlevel

# check that services are working as expected
/etc/init.d/redis start
RED_OOPS=$?
/etc/init.d/rabbitmq start
RAB_OOPS=$?
/etc/init.d/sparcron-server start
SVR_OOPS=$?

[ ${RED_OOPS} -eq 0 ] || { echo redis failed to start;}
[ ${RAB_OOPS} -eq 0 ] || { echo rabbitmq failed to start;}
[ ${SVR_OOPS} -eq 0 ] || { echo sparcron-server failed to start;}
[ ${RED_OOPS} -ne 0 ] || [ ${RAB_OOPS} -ne 0 ] || [ ${SVR_OOPS} -ne 0 ] && { echo at least on service failed; exit 1;}

su sparc -c 'pypy3 -m sparcur.sparcron' || { echo startup check failed; exit 2;}
#+end_src

** protc
*** world
#+name: world-protc
#+begin_src conf
dev-libs/redland
#+end_src
* musl static
Same metadata as musl except with =static-libs= in order to produce
statically linked binaries.
** static-xorg
*** run
debug
#+begin_src screen
docker run \
--net host \
--add-host local.binhost:127.0.0.1 \
--volumes-from local-repos-snap \
-v ~/files/binpkgs/multi:/var/cache/binpkgs \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=${DISPLAY} \
--rm \
-it \
tgbugs/musl:static-xorg
#+end_src
*** build
# XXX warning, the harfbuzz/freetype issue can probably be avoided here
# because only freetype has the static-libs use flag
#+name: &musl-build-static-xorg
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:static-xorg \
--build-arg PROFILE='docker-profile:tgbugs/musl/static/x' \
--build-arg START_IMAGE='tgbugs/musl:updated' \
--file musl/xorg/static.Dockerfile musl/xorg
#+end_src
# --build-arg START_IMAGE='tgbugs/musl:xorg' \
*** file
#+begin_src dockerfile :tangle ./musl/xorg/static.Dockerfile
<<&xorg-nox-common-1>>
<<&profile-static-x>>
<<&xorg-nox-common-2>>
<<&xorg-nox-common-3>>
#+end_src
** static-package-builder
*** populate 0
#+name: &musl-run-static-xorg-quickpkg
#+begin_src bash
quickpkg-image tgbugs/musl:static-xorg
#+end_src
*** run
#+begin_src bash
docker run tgbugs/musl:static-package-builder
docker commit $(docker ps -lq) tgbugs/musl:static-package-builder-snap

docker run \
--volumes-from local-repos-snap \
-v ${_path_binpkgs}:/var/cache/binpkgs \
-v ${_path_distfiles}:/var/cache/distfiles \
tgbugs/musl:static-package-builder-snap \
emerge --color=y -j4 -q --keep-going -uDN @docker

docker commit $(docker ps -lq) tgbugs/musl:static-package-builder-snap
#+end_src
# --volumes-from cross-sbcl \
# FIXME racket failing with mkostemp failures during raco make or
# something !? what the fuck?  how was this not caught before ?!
*** build
#+name: &musl-build-static-package-builder
#+begin_src screen
docker build \
--tag tgbugs/musl:static-package-builder \
--file musl/package-builder/static.Dockerfile musl/package-builder
#+end_src
*** file
#+begin_src dockerfile :tangle ./musl/package-builder/static.Dockerfile
FROM tgbugs/musl:static-xorg

<<&musl-package-builder-common>>

# overwrite the regular world file
ADD static.world /etc/portage/sets/docker

ADD static-sbcl.env /etc/portage/env/dev-lisp/sbcl
#+end_src
*** world
#+name: world-static-package-builder
#+begin_src conf :tangle ./musl/package-builder/static.world
<<world-package-builder-common>>
<<world-sbcl>>
<<world-static-sbcl-c-libs>>
#+end_src

#+name: world-static-sbcl-c-libs
#+begin_src conf
dev-libs/openssl
dev-libs/libgit2
dev-libs/gmp
dev-libs/capstone
dev-libs/mpfr
dev-libs/redland
#+end_src
** static-binpkg-only
*** build
#+name: &musl-build-static-binpkg-only
#+begin_src bash
docker build \
--tag tgbugs/musl:static-binpkg-only \
--file musl/binpkg-only/static.Dockerfile musl/binpkg-only
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/binpkg-only/static.Dockerfile
FROM tgbugs/musl:static-xorg
<<&musl-binpkg-only-common>>
#+end_src

** sbcl
*** build
#+name: &musl-build-sbcl
#+begin_src screen
<<&docker-build>>
--tag tgbugs/musl:sbcl \
--file musl/sbcl/Dockerfile musl/sbcl
#+end_src
*** file
#+begin_src dockerfile :tangle ./musl/sbcl/Dockerfile
FROM tgbugs/musl:static-binpkg-only
<<&build-world-common>>
#+end_src
*** world
#+name: world-sbcl
#+begin_src conf :tangle ./musl/sbcl/world
<<world-emacs>>
<<world-sbcl-base>>
#+end_src
# FIXME why did we have these on the list before? some build order issue or something? weird ... maybe it has been fixed now?
# dev-lisp/uiop
# dev-lisp/asdf
#+name: world-sbcl-base
#+begin_src conf
dev-lisp/sbcl
#+end_src
*** patches
make the patches since they are too much to tangle
FIXME this is currently an entirely manual step
FIXME this needs to be moved to run inside a builder phase
#+name: &fn-sbcl-static-patch
#+begin_src bash :noweb yes
function sbcl-static-patch () {
local version tag spath tpath patch
version=${1}
tag=sbcl-${version}
patch=static-${version}.patch
spath=./<<&helper-repos()>>/sbcl/patches
tpath=./docker-profile/static/
ipath=patches/dev-lisp/sbcl-${version}/
sighpath=./<<&helper-repos()>>/sbcl/patches/dev-lisp/sbcl-${version}/${patch}
if [[ ! -f "${sighpath}" ]]; then
  mkdir <<&helper-repos()>>
  pushd <<&helper-repos()>>
    git clone https://github.com/sbcl/sbcl.git
    pushd sbcl
      git fetch
      git remote add tgbugs https://github.com/tgbugs/sbcl.git
      git fetch tgbugs
      mkdir -p ${ipath}
      # gentoo eapply_user happens after gentoo patches are applied so we have to compensate here :/
      git diff ${tag}..remotes/tgbugs/static-executable-v2-${version} ':(exclude)README*' | \
        sed 's,maybetime sh,maybetime sh -x,' > \
        ${ipath}/${patch}
    popd
  popd
fi
# XXX old, we renamed this so that they will work
# this portion has to be repeatable because we zap docker-profile on every tangle
# mkdir -p ${tpath}
# cp -a ${spath} ${tpath}
}
#+end_src

#+begin_src bash :noweb no-export
<<&fn-sbcl-static-patch>>
sbcl-static-patch 2.2.6
sbcl-static-patch 2.2.7
#+end_src

#+name: &sbcl-env-static
#+begin_src ebuild :tangle ./docker-profile/static/sbcl.env :tangle no
post_src_configure() {
truncate -s $(head -n -2 "${CONFIG}" | wc -c) "${CONFIG}"
sbcl_feature "true" ":sb-linkable-runtime"
sbcl_feature "true" ":sb-prelink-linkage-table"
echo ') list)' >> "${CONFIG}"
}
#+end_src

# <<&sbcl-env>>
#+begin_src ebuild :noweb yes :tangle ./musl/package-builder/static-sbcl.env
<<&sbcl-env-static>>
#+end_src

** sbcl-user
*** run
#+begin_src bash
docker run \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/musl:sbcl-user
#+end_src

*** build
#+name: &musl-build-sbcl-user
#+begin_src screen
docker build \
--tag tgbugs/musl:sbcl-user \
--build-arg UID=${UID} \
--file musl/sbcl-user/Dockerfile musl/sbcl-user
#+end_src

*** file
# TODO emacs setup etc.
#+begin_src dockerfile :tangle ./musl/sbcl-user/Dockerfile
FROM tgbugs/musl:sbcl

COPY --from=tgbugs/common:user / /

<<&musl-file-user-base>>

# FIXME builder to factor common here
<<&emacs-sanity>>
#+end_src

** sbcl-stripped
*** run
#+begin_src bash
docker run \
--network host \
--rm \
-it tgbugs/musl:sbcl-stripped \
--load /quicklisp/setup.lisp \
--eval '(asdf:load-system :dexador)' \
--eval '(push :dexador *features*)'
--eval '(asdf:load-system :quicklisp-https)'
#+end_src

It is BEYOND stupid how difficult it is to configure iptables to be
able to connect to 4009 when =--network host= produces the desired
result immediately. No quick solution so moving on as usual. Sigh.

old
#+begin_src bash
docker run \
--network host \
--rm \
-it tgbugs/musl:sbcl-stripped \
--eval '(asdf:initialize-source-registry (list :source-registry (list :tree #p"/dexador") (list :tree #p"/quicklisp-https") :inherit-configuration))' \
--eval '(asdf:load-system :dexador)' \
--load /quicklisp.lisp \
--eval "(quicklisp-quickstart:install)" \
--eval '(asdf:load-system :quicklisp-https)' \
--eval "(ql:quickload :swank)" \
--eval '(defvar *swank-server* (swank:create-server :port 4009))' \
--eval '(sb-posix:readlink "/proc/1/exe")'

#+end_src

TODO figure out minimal requirements to safely bootstrap to dexador
so we can use ssl from within common lisp ... the most obvious answer
is to use curl which is tiny by comparison, or embed a known hash for
a specific dexador version? ... or make that a prerequisite? urg
more likely the correct thing to do is to grab dex, use it to grab
quicklisp-https, except that given how we are generating these images
there is zero reason not to just use git to securely retrieve the code
we need for bootstrap and leave it as an exercise for the reader if they
want to ... alternately libgit2 and cl-git are another way I think, but
still need to be side loaded if we don't have curl, so we use an existing

XXX dex has a bunch of deps ...

# --eval "(ql:quickload (:swank :dexador))" \

#+begin_src lisp
swank-api:*emacs-connection*
#+end_src

*** build
#+name: &musl-build-sbcl
#+begin_src screen
docker build \
--tag tgbugs/musl:sbcl-stripped \
--file musl/sbcl-stripped/Dockerfile musl/sbcl-stripped
#+end_src
*** file
# TODO add libgit2 so we can use cl-git
#+begin_src dockerfile :tangle ./musl/sbcl-stripped/Dockerfile :comments no
# syntax=docker/dockerfile:experimental
FROM tgbugs/musl:sbcl as builder

WORKDIR /build

RUN \
lddtree -l /usr/bin/sbcl /usr/bin/openssl       | \
xargs -n 1 qfile -q                             | \
xargs      qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq -F '%{CATEGORY}/%{PN}' | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
cut -d':' -f1                                   | \
xargs qlist | xargs -P8 -I{} -n 1 rsync -aR {} /build

#RUN \
#curl -O https://beta.quicklisp.org/quicklisp.lisp

#RUN \
#curl -O https://beta.quicklisp.org/quicklisp.lisp.asc

# amazing how utterly bad the ux is for gpg that it actively makes things less secure
#RUN \
#gpg --verify quicklisp.lisp.asc quicklisp.lisp

RUN \
git clone --branch version-2021-02-13 --depth=1 https://github.com/quicklisp/quicklisp-client.git quicklisp

RUN \
git clone --depth=1 https://github.com/rudolfochrist/ql-https.git /ql-https

RUN \
git clone --depth=1 https://github.com/snmsts/quicklisp-https.git quicklisp/local-projects/quicklisp-https

RUN --network=none \
sbcl --no-userinit --disable-debugger \
--eval '(asdf:initialize-source-registry (list :source-registry (list :tree #p"/ql-https") (list :tree #p"/build/quicklisp") :inherit-configuration))' \
--eval '(defpackage #:ql-setup)' \
# don't forget the trailing slash for files >_<
--eval '(defvar ql-setup::*quicklisp-home* (probe-file "/build/quicklisp/"))' \
--eval '(load "/ql-https/ql-setup.lisp")' \
--eval '(asdf:load-system :ql-https)' \
--eval '(save-lisp-and-die "/continue.core" :purify nil)'

RUN \
sbcl --core /continue.core --no-userinit --disable-debugger \
--eval '(setf ql-https::*quietly-use-https* t)' \
--eval '(quicklisp:setup)' \
--eval '(ql:quickload :dexador)' \
--eval '(format t "YOU WHAT NOW??")' \
--quit

FROM scratch

WORKDIR /

COPY --from=builder /build /

RUN --network=none \
["/usr/bin/sbcl", \
"--non-interactive", \
"--no-userinit", "--disable-debugger", \
#"--eval", "(asdf:initialize-source-registry (list :source-registry (list :tree #p\"/quicklisp-https\") :inherit-configuration))", \
"--load", "/quicklisp/setup.lisp", \
"--eval", "(asdf:load-system :dexador :verbose nil)", \
"--eval", "(asdf:load-system :quicklisp-https :verbose nil)", \
"--quit"]

ENTRYPOINT ["/usr/bin/sbcl"]
#+end_src
*** extra :noexport:
extras
#+begin_src bash
lddtree -l /usr/bin/sbcl | xargs -n 1 qfile -q | xargs qlist
qdepends -rp -q sbcl | xargs -n 1 qdepends -rp | xargs -n 1 qdepends -rp

qdepends -rp -q sbcl | xargs -n 1 qdepends -rp | xargs -n 1 qdepends -rpq | xargs -n 1 qdepends -rp -q -F '%{CATEGORY}/%{PN}' | sort -u | cut -d':' -f1 | qlist

qlist /usr/bin/sbcl
qlist openssl
lddtree -l /usr/bin/sbcl
#+end_src

some insights into relative runtime sizes the results for these are
compressed and I have made zero effort to strip these builds for light
weight images because the point of is to be fully functional with the
source code and whatever documentation comes along in most cases, more
to the point what this means is that baring some serious work to slim
down these things, a full polyglot runtime is annoyingly large

the above written before I check haskell ... LOL HASKELL
racket has 3 full implementations in my distribution, but still, very, very large
for comparison the other schemes are all tiny under 10M
gcc and llvm both pushing 70M, rust 91M ... anyway ... no way are we going to be
able to optimize the size of these things, so the minimal sbcl image is for other
projects, not for prrequaestor which depends on far too many other runtimes

#+begin_src bash
pushd ~/files/binpkgs/multi
ls -alh \
dev-lisp/sbcl \
net-libs/nodejs \
dev-lang/python \
dev-python/pypy3 \
app-editors/emacs \
dev-lang/ghc \
dev-scheme/racket \
sys-devel/gcc \
sys-devel/llvm \
dev-lang/rust \
dev-lang/erlang \
dev-lang/perl \
dev-vcs/git \
dev-libs/openssl

#+end_src

#+begin_src dockerfile
# ugh python is huge ... so is emacs
RUN \
   mkdir /cpython \
&& qlist python-3.10 | xargs -P8 -I{} -n 1 rsync -aR {} /cpython \
&& du -hxd1 /cpython \
&& mkdir /pypy3
&& qlist pypy3       | xargs -P8 -I{} -n 1 rsync -aR {} /pypy3 \
&& du -hxd1 /pypy3 \
&& mkdir /emacs \
&& qlist emacs       | xargs -P8 -I{} -n 1 rsync -aR {} /emacs \
&& du -hxd1 /emacs
&& mkdir /nodejs \
&& qlist nodejs       | xargs -P8 -I{} -n 1 rsync -aR {} /nodejs \
&& du -hxd1 /nodejs
# 123M /cpython
# 194M /pypy3
# 162M /emacs
# 49M  /nodejs
# 4.0M /curl

# TODO keep other things needed for e.g. prrequaestor
RUN \
echo git nifstd-tools neurondm |
xargs      qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq                        | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
xargs -n 1 qdepends -rpq -F '%{CATEGORY}/%{PN}' | sort -u | tr ' ' '\n' | grep -v '^!<net-misc/openssh' | \
cut -d':' -f1

#+end_src

#+begin_src lisp
sb-sys:*linkage-info*
(defun linfo (&key (make-undefined nil))
  (let ((ht (car sb-sys:*linkage-info*))
        (undefined-entries (cdr sb-sys:*linkage-info*))
        out)
    (loop
      :for key :being :the :hash-keys :in ht :using (hash-value idx)
      :for datap := (listp key)
      :for name := (if datap (first key) key)
      :for undefinedp := (not (null (or (member key undefined-entries :test #'equal)
                                        (member name make-undefined :test #'equal))))
      :do (push (cons idx (list name datap undefinedp)) out))
    (let ((*print-pretty* nil))
      (prin1 (mapcar #'cdr (sort out #'< :key #'car))))))
#+end_src
* gnu
may not need this if we can use crossdev to build glibc sbcl on musl that that seems a stretch
** eselect-repo
*** build
# TODO see if we can get the prologue running everywhere not sure if ti will tangle though
#+name: &gnu-build-eselect-repo
#+begin_src screen :prologue (format "echo running block %S" (plist-get (nth 1 (org-element-at-point)) :name))
docker build \
--tag tgbugs/gnu:eselect-repo \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/eselect-repo/Dockerfile gnu/eselect-repo
#+end_src

*** file
#+begin_src dockerfile :tangle ./gnu/eselect-repo/Dockerfile
FROM gentoo/stage3:amd64-hardened-openrc

<<&gentoo-file-eselect-repo-common-1>>

<<&profile-gnu>>

<<&gentoo-file-eselect-repo-common-2>>

RUN \
eselect profile set docker-profile:tgbugs/gnu \
&& env-update

<<&gentoo-file-eselect-repo-common-3>>
#+end_src

** updated
Unfortunately running =-uDN= pulls in all sorts of stuff when we least want it, so just roll with updated here too.
FIXME actually ... updated is ... bad? ideally we just go to package-builder directly so ... wait no we do still need quickpkg grr.
Maybe quickpkg-new from the package builder or something?
Well for now we keep them in parallel until we can switch to the raw package builder.
*** build
#+name: &musl-build-updated
#+begin_src screen
docker build \
--tag tgbugs/gnu:updated \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/updated/Dockerfile gnu/updated
#+end_src

*** file
#+name: &gnu/updated
#+begin_src dockerfile :tangle ./gnu/updated/Dockerfile
FROM tgbugs/gnu:eselect-repo
<<&updated-common>>
#+end_src

** package-builder
*** populate 0
#+name: &gnu-run-package-builder-quickpkg
#+begin_src bash
quickpkg-image tgbugs/gnu:package-builder
#+end_src

*** build
#+name: &gnu-build-package-builder
#+begin_src screen
docker build \
--tag tgbugs/gnu:package-builder \
--file gnu/package-builder/Dockerfile gnu/package-builder
#+end_src

*** file
#+begin_src dockerfile :tangle ./gnu/package-builder/Dockerfile
FROM tgbugs/gnu:eselect-repo

<<&musl-package-builder-common>>

# XXX FIXME running this causes portage invalid location for some reason???
# maybe because the folder existing prevents the tmp/ folder from being created ???
# ADD 99-sbcl /usr/x86_64-pc-linux-musl/etc/portage/package.use/99-sbcl
#+end_src
*** crossdev
# hack to reuse musl common for file
#+begin_src conf :tangle ./gnu/package-builder/repo_name
<<&crossdev-repo_name>>
#+end_src

#+begin_src conf :tangle ./gnu/package-builder/layout.conf
<<&crossdev-layout>>
#+end_src

#+begin_src conf :tangle ./gnu/package-builder/crossdev.conf
<<&crossdev-conf>>
#+end_src

#+begin_src conf :tangle ./gnu/package-builder/sbcl.env
#+end_src
*** world
#+begin_src conf :tangle ./gnu/package-builder/world
<<world-sbcl-base>>
#+end_src
*** cross
**** issues
Building cross packages from the builder isn't the most straightforward process.
#+name: gnu-cross-musl-emerge-info
#+begin_src bash :noweb yes :results code :wrap example
<<&builder-vars>>
docker run \
<<&builder-args-gnu>>
--rm \
${_tg_pbs} \
x86_64-pc-linux-musl-emerge --info
#+end_src

# FIXME cross build repos missing proper configuration for compression and archive type (even though there aren't very many packages)

Examples of the issue.
#+begin_example
PKGDIR="/usr/x86_64-pc-linux-musl/var/cache/binpkgs/"
PORTAGE_CONFIGROOT="/usr/x86_64-pc-linux-musl/"
#+end_example

However, =FEATURES=buildpkg= is set it seems. So this might just be an
issue of setting mounts for source/target pkgdirs, e.g.
#+begin_example
-v ~/files/binpkgs/cross/gnu/x86_64-pc-linux-musl:/usr/x86_64-pc-linux-musl/var/cache/binpkgs/
#+end_example
or more sanely =${CBUILD}/${CHOST}= ?
#+begin_example
-v ~/files/binpkgs/cross/x86_64-pc-linux-gnu/x86_64-pc-linux-musl:/usr/x86_64-pc-linux-musl/var/cache/binpkgs/
#+end_example
except that we then have to maintain a mapping from our shorthand to =CBUILD=.

FIXME currently broken ?!??
#+begin_example
!!! Invalid binary package: '/var/cache/binpkgs/dev-util/strace/strace-6.1-3.gpkg.tar', Unsupported binary package format from '/var/cache/binpkgs/dev-util/strace/strace-6.1-3.gpkg.tar'
>>> Installing (1 of 5) dev-util/strace-6.1::gentoo
>>> Emerging (2 of 5) dev-lisp/asdf-3.3.5::gentoo for /usr/x86_64-pc-linux-musl/

!!! Invalid binary package: '/usr/x86_64-pc-linux-musl/var/cache/binpkgs/app-arch/xz-utils/xz-utils-5.4.2-2.xpak'
!!! Missing metadata key(s): CATEGORY, PF, SLOT. This binary package is not
!!! recoverable and should be deleted.
#+end_example

#+RESULTS: gnu-cross-musl-emerge-info
#+begin_example
#+end_example
**** sbcl
Yeah ... the usual issue with cross compiling zlib/zstd support.
# TODO may need/want to tangle to gnu/package-builder/cross/x86_64-pc-linux-musl or something?
#+begin_src conf :tangle ./gnu/package-builder/99-sbcl
<<&config-cross-sbcl-package.use>>
#+end_src

#+begin_src conf :tangle ./gnu/package-builder/cross-make.defaults
BINPKG_FORMAT="gpkg"
BINPKG_COMPRESS="zstd"
BINPKG_COMPRESS_FLAGS_ZSTD="--ultra -22"
FEATURES="${FEATURES} binpkg-multi-instance"
EMERGE_DEFAULT_OPTS="${EMERGE_DEFAULT_OPTS} --binpkg-respect-use=y"  # FIXME portageq shows bru opt twice ??
#+end_src

work around lack of cross compile support in =src_compile= during system-bootstrap
and also do not reset because we have to use the
get the core location for host sbcl for bootstrap_lisp since =SBCL_HOME= is reset to point to CHOST aka target location
a general solution for the ebuild would be to detect when ~CBUILD != CHOST~ and find the cbuild sbcl
and fail over to clisp if sbcl is not present, not quite system bootstrap in that case because you could
somehow provide an alternate sbcl, but that should still be ok, the use of =has_version= is fundamentally
broken for cross compile in this context (see e.g. [[/usr/lib/portage/pypy3/phase-helpers.sh]])

#+begin_src bash :tangle ./gnu/package-builder/sbcl-cross.env
src_compile() {
	local bindir="${WORKDIR}"/sbcl-binary
	local bootstrap_lisp="sh ${bindir}/run-sbcl.sh --no-sysinit --no-userinit --disable-debugger"
	local core

	if use system-bootstrap ; then
		# must set core location since SBCL_HOME is changed below
		core=$(sbcl --noinform --noprint --quit --eval '(format t "~a~%" sb-ext:*core-pathname*)')
		bootstrap_lisp="sbcl --core ${core} --no-sysinit --no-userinit --disable-debugger"
	fi

	# Bug #869434
	append-cppflags -D_GNU_SOURCE

	# clear the environment to get rid of non-ASCII strings, see bug #174702
	# set HOME for paludis
	env - HOME="${T}" PATH="${PATH}" \
		CC="$(tc-getCC)" AS="$(tc-getAS)" LD="$(tc-getLD)" \
		CPPFLAGS="${CPPFLAGS}" CFLAGS="${CFLAGS}" ASFLAGS="${ASFLAGS}" LDFLAGS="${LDFLAGS}" \
		SBCL_HOME="/usr/$(get_libdir)/sbcl" SBCL_SOURCE_ROOT="/usr/$(get_libdir)/sbcl/src" \
		GNUMAKE=make ./make.sh \
		"${bootstrap_lisp}" \
		|| die "make failed"

	# need to set HOME because libpango(used by graphviz) complains about it
	if use doc; then
		env - HOME="${T}" PATH="${PATH}" \
			CL_SOURCE_REGISTRY="(:source-registry :ignore-inherited-configuration)" \
			ASDF_OUTPUT_TRANSLATIONS="(:output-translations :ignore-inherited-configuration)" \
			make -C doc/manual info html || die "Cannot build manual"
		env - HOME="${T}" PATH="${PATH}" \
			CL_SOURCE_REGISTRY="(:source-registry :ignore-inherited-configuration)" \
			ASDF_OUTPUT_TRANSLATIONS="(:output-translations :ignore-inherited-configuration)" \
			make -C doc/internals info html || die "Cannot build internal docs"
	fi
}
#+end_src

Script to use to cross-built sbcl to build a native built musl sbcl.
#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle ./bin/musl-bootstrap-from-cross-sbcl.sh :mkdirp yes
emerge --usepkg --nodeps -1q -j4 dev-lisp/asdf dev-lisp/uiop
emerge --usepkgonly dev-lisp/sbcl || {
# we don't need to be able to merge old versions that are not in tree
# because once we cross bootstrap our pure musl process with system-bootstrap
# will keep everything up to date, yes a new system will have to bootstrap from
# a new version, but that is a given, XXX watch out for missing ebuild after long period of not updating though?
PKGDIR=/usr/x86_64-gentoo-linux-musl/var/cache/binpkgs/ USE='-zstd -system-bootstrap' emerge -K dev-lisp/sbcl
env-update
source /etc/profile
emerge -q --buildpkg=n dev-lisp/sbcl
# double rebuild for completeness, not strictly required, but keeps the provenance simpler
emerge -q dev-lisp/sbcl
}
#+end_src

#+name: &cross-bootstrap-sbcl
#+begin_src screen
function gnu-cross-musl-sbcl () {
# FIXME super hacked way to determine whether we already bootstrapped
{ [ -z "$(ls -A ${_path_binpkgs_root}/cross/gnu/x86_64-gentoo-linux-musl/dev-lisp/sbcl)" ] && gnu-cross-musl-sbcl-build; } || return 0
}

function gnu-cross-musl-sbcl-build () {
# build the starting glibc linked sbcl
gnu-builder-run emerge -q -j4 dev-lisp/sbcl
# FIXME env-update and source /etc/profile are needed to ensure that SBCL_HOME is set correctly in the environment after install
# otherwise sbcl will look for sbcl.core in the current directory (making it look like the package is broken)
gnu-builder-run env-update
# gnu-builder-run source /etc/profile

gnu-builder-run x86_64-gentoo-linux-musl-emerge -q -j4 --keep-going sys-libs/musl  # FIXME not sure if needed

# configure the gnu cross to musl environment
# must use x86_64-gentoo-linux-musl NOT x86_64-pc-linux-musl because the gentoo musl images are x86_64-gentoo-linux-musl
docker run \
-v ${PWD}/gnu/package-builder/sbcl-cross.env:/tmp/sbcl-cross.env \
-v ${PWD}/gnu/package-builder/99-sbcl:/tmp/99-sbcl \
-v ${PWD}/gnu/package-builder/cross-make.defaults:/tmp/cross-make.defaults \
${_tg_pbs} \
sh -c \
"
mkdir -p               /usr/x86_64-gentoo-linux-musl/etc/portage/env/dev-lisp
cp /tmp/sbcl-cross.env /usr/x86_64-gentoo-linux-musl/etc/portage/env/dev-lisp/sbcl
mkdir -p        /usr/x86_64-gentoo-linux-musl/etc/portage/package.use/;\
cp /tmp/99-sbcl /usr/x86_64-gentoo-linux-musl/etc/portage/package.use/99-sbcl;\
cat /tmp/cross-make.defaults >> /usr/x86_64-gentoo-linux-musl/etc/portage/make.conf\
"

docker commit --change='CMD ["/bin/bash"]' $(docker ps -lqf ancestor=${_tg_pbs}) ${_tg_pbs}  # TODO possibly write to own lineage or make own script and --rm

# this symlink is critical to get the whole thing to work otherwise the tools-for-build/determine-endianness error will show up
# FIXME the string is getting split when passing through the function
gnu-builder-run sh -c '[ -f /lib/ld-musl-x86_64.so.1 ] || ln -s /usr/x86_64-gentoo-linux-musl/usr/lib/libc.so /lib/ld-musl-x86_64.so.1'
# the symlink trick we do for ld doesn't work for libzstd so have to
# USE='-zlib -zstd' must be set here (or rather in the crossdev package.use) to avoid tools-for-build/grovel-headers issues with missing libs
#gnu-builder-run sh -c "USE='-zlib -zstd' x86_64-pc-linux-musl-emerge -q -j4 --keep-going dev-lisp/sbcl"
#gnu-builder-run x86_64-pc-linux-musl-emerge -q -j4 --keep-going --usepkg dev-lisp/sbcl

# FIXME somehow only x86_64-pc-linux-musl-emerge is installed? did we miss a cross build?
# since we have sbcl installed on the builder we can use system-bootstrap to reduce useflag noise
gnu-builder-run sh -c 'USE=system-bootstrap x86_64-gentoo-linux-musl-emerge -q -j4 --keep-going dev-lisp/sbcl'
# reminder can't use LD_LIBRARY_PATH=/usr/x86_64-gentoo-linux-musl/usr/lib because it breaks the builder (gnu) binaries
}

function musl-bootstrap-sbcl () {
# finish the bootstrap to produce the musl sbcl binpkg by building in the musl builder itself
builder-run musl-bootstrap-from-cross-sbcl.sh
# this has the nice side effect that we ensure that the native sbcl is always present in the builder
# so that any updates to sbcl will be able to use system-bootstrap without issue
# FIXME we do need to watch out for cases where we lose and ebuild for an older version
# but I think portage may handle that automatically for us? not quite sure
}

function cross-bootstrap-sbcl () {
# all together now
gnu-cross-musl-sbcl
musl-bootstrap-sbcl
}
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :noweb yes :tangle ./bin/gnu-cross-musl-sbcl.sh
<<&cross-bootstrap-sbcl>>
cross-bootstrap-sbcl
#+end_src

**** ghc
XXX this is still broken

1. have to have ghc installed in the build environment
2. configure for some stage wants ncurses to be present otherwise it will fail

The =/lib/ld-musl-x86_64.so.1= symlink is also necessary for this to
work as it was in the case of sbcl. This must be a in oversight/bug in
the cross compilation environment. This hack might allow things that
link musl directly to work, but I think it also may be deferring the
issue since the underlying problem without the symlink is that the
compilers don't work because something is getting crossed up and the
build process is trying to run musl binaries on a gnu system instead
of running the gnu equivalents to build the musl bits. This works for
sbcl because we can disable all linking via use flags, but we can't do
that with haskell, and as a result the build process tries to run a
program that it built for another arch in a later step ... which is
sad and unfortunate. =-gmp= makes no difference because ld is called
to link different bits of ghc together.

Setting =ROOT=/usr/x86_64-gentoo-linux-musl= also doesn't fix the issue.

#+begin_src bash :tangle ./bin/gnu-cross-musl-ghc.sh
USE=-doc emerge --usepkg -q -j4 dev-lang/ghc
x86_64-gentoo-linux-musl-emerge --usepkg --nodeps -q1 sys-libs/ncurses
USE='ghcbootstrap -doc -gmp' x86_64-gentoo-linux-musl-emerge --usepkg --nodeps -q dev-lang/ghc
#+end_src

if you can somehow get the cross compile to work then you could run the following
#+begin_src bash :tangle ./bin/musl-bootstrap-from-cross-ghc.sh
emerge --onlydeps -1q -j4 --usepkg dev-lang/ghc
emerge --usepkgonly dev-lang/ghc || {
PKGDIR=/usr/x86_64-gentoo-linux-musl/var/cache/binpkgs/ USE='ghcbootstrap -doc -gmp' emerge -K dev-lang/ghc
emerge dev-lang/ghc
}
#+end_src

***** issues
looks like relative paths are not being calculated correctly but are coming from fs root? instead of ROOT ???
#+begin_example
x86_64-gentoo-linux-musl-ld: cannot find /usr/x86_64-gentoo-linux-musl/tmp/portage/dev-lang/ghc-9.0.2-r4/temp/ghc2151_0/ghc_8.o inside /usr/x86_64-pc-linux-gnu/x86_64-gentoo-linux-musl/binutils-bin/2.39/../../../../x86_64-gentoo-linux-musl
x86_64-gentoo-linux-musl-ld: cannot find /usr/x86_64-gentoo-linux-musl/tmp/portage/dev-lang/ghc-9.0.2-r4/temp/ghc2151_0/ghc_7.o inside /usr/x86_64-pc-linux-gnu/x86_64-gentoo-linux-musl/binutils-bin/2.39/../../../../x86_64-gentoo-linux-musl
`x86_64-gentoo-linux-musl-ld' failed in phase `Merge objects'. (Exit code: 1)
make[1]: *** [libraries/ghc-prim/ghc.mk:4: libraries/ghc-prim/dist-install/build/GHC/Prim/Ext.o] Error 1
make[1]: *** Waiting for unfinished jobs....
x86_64-gentoo-linux-musl-ld: cannot find /usr/x86_64-gentoo-linux-musl/tmp/portage/dev-lang/ghc-9.0.2-r4/temp/ghc2142_0/ghc_6.o inside /usr/x86_64-pc-linux-gnu/x86_64-gentoo-linux-musl/binutils-bin/2.39/../../../../x86_64-gentoo-linux-musl
x86_64-gentoo-linux-musl-ld: cannot find /usr/x86_64-gentoo-linux-musl/tmp/portage/dev-lang/ghc-9.0.2-r4/temp/ghc2142_0/ghc_5.o inside /usr/x86_64-pc-linux-gnu/x86_64-gentoo-linux-musl/binutils-bin/2.39/../../../../x86_64-gentoo-linux-musl
`x86_64-gentoo-linux-musl-ld' failed in phase `Merge objects'. (Exit code: 1)
make[1]: *** [libraries/ghc-prim/ghc.mk:4: libraries/ghc-prim/dist-install/build/GHC/CString.o] Error 1
make: *** [Makefile:128: ghc/stage2/build/tmp/ghc-stage2] Error 2
#+end_example

I'm trying to cross compile ghc from gnu -> musl, and the linker is struggling to find the correct path.
build.log http://sprunge.us/R4Sl23
It seems that there are two absolute paths being combined, but ld expects the 2nd path to be relative.

possibly due to ROOT issues, or maybe because the makefile has a bug?

***** bug
#+begin_question :id 1 :type irc :server irc.libera.chat :channel #gentoo
crossdev question: there are a number of packages e.g. sbcl, ghc where certain paths fail to account for e.g. the /usr/x86_64-gentoo-linux-musl prefix
the end result is that we wind up with paths like:
/usr/x86_64-gentoo-linux-musl/usr/x86_64-gentoo-linux-musl/usr/share/common-lisp/source/asdf/version.lisp-expr
instead of:
/usr/x86_64-gentoo-linux-musl/usr/share/common-lisp/source/asdf/version.lisp-expr
in some cases this also breaks the linker
is there an know way to fix things like this?
#+end_question

#+begin_answer :id 1
sam says submit a bug because it seems uncommon
#+end_answer

#+begin_src bash
emerge sys-devel/crossdev
crossdev --stage4 --stable --portage --getbinpkg --target x86_64-gentoo-linux-musl
x86_64-gentoo-linux-musl-emerge -q -j4 --keep-going sys-libs/musl
# at this point you can try to build sbcl
x86_64-gentoo-linux-musl-emerge -q -j4 --keep-going dev-lisp/sbcl

# this hack allows the sbcl build to succeed, without it the build fails much earlier
[ -f /lib/ld-musl-x86_64.so.1 ] || ln -s /usr/x86_64-gentoo-linux-musl/usr/lib/libc.so /lib/ld-musl-x86_64.so.1

#+end_src

** crossdev
*** build
#+name: &gnu-build-crossdev
#+begin_src screen
docker build \
--tag tgbugs/gnu:crossdev \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/crossdev/Dockerfile gnu/crossdev
#+end_src
*** file
# FIXME masking issues somehow blocking musl ... seems like the issue may be that we haven't dumped stuff, also masked by CHOST? wat?
#+begin_src dockerfile :tangle ./gnu/crossdev/Dockerfile
FROM tgbugs/gnu:eselect-repo

#emerge -j4 -q -uDN \  # yeahno
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   sys-devel/crossdev \
<<&archive-or-rm>>

# FIXME why isn't this finding the binpkgs ???
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge --usepkg --getbinpkgonly \
   cross-x86_64-pc-linux-musl/musl \
   cross-x86_64-pc-linux-musl/linux-headers \
   cross-x86_64-pc-linux-musl/gcc \
   cross-x86_64-pc-linux-musl/binutils \
;  crossdev --stable --target x86_64-pc-linux-musl --stage4 \
<<&archive-or-rm>>
#+end_src

** ghc-cross :do_not_use:
This is very much not working right now, our solution to use alpine to
get a ghc that works with musl 1.2.3 works. I suspect that the ghc
ebuilds are not set up to work with cross compiling for some reason.
*** run
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/gnu:ghc-cross
#+end_src

Test that the cross compiled version is working as expected.
#+begin_src bash
docker run \
-it tgbugs/gnu:ghc-cross \
/usr/x86_64-pc-linux-musl/usr/bin/ghci
#+end_src
*** build
#+begin_src screen
docker build \
--tag tgbugs/gnu:ghc-cross \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/ghc-cross/Dockerfile gnu/ghc-cross
#+end_src
*** file
#+begin_src dockerfile :tangle ./gnu/ghc-cross/Dockerfile
FROM tgbugs/gnu:crossdev

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   dev-lang/ghc \
<<&archive-or-rm>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
x86_64-pc-linux-musl-emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   sys-libs/musl \
   sys-libs/zlib \
<<&archive-or-rm>>

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
USE=ghcbootstrap x86_64-pc-linux-musl-emerge -j4 -q \
   dev-lang/ghc \
<<&archive-or-rm>>
#+end_src
*** patch
See https://gitlab.haskell.org/ghc/ghc/-/issues/17944
and https://gitlab.haskell.org/ghc/ghc/-/issues/12416
and https://gitlab.haskell.org/ghc/ghc/-/merge_requests/2943
and https://gitlab.haskell.org/ghc/ghc/-/merge_requests/4466
**** ignore Winline (fails)
evil but generalized solution to fatal inline warnings, this is a bootstrap build after all
#+begin_src diff
--- a/rts/ghc.mk
+++ b/rts/ghc.mk
@@ -355,7 +355,6 @@
 WARNING_OPTS += -Wstrict-prototypes
 WARNING_OPTS += -Wmissing-prototypes
 WARNING_OPTS += -Wmissing-declarations
-WARNING_OPTS += -Winline
 WARNING_OPTS += -Wpointer-arith
 WARNING_OPTS += -Wmissing-noreturn
 WARNING_OPTS += -Wnested-externs
#+end_src

but then linking fails

#+begin_example
`x86_64-pc-linux-musl-ld' failed in phase `Merge objects'. (Exit code: 1)
make[1]: *** [libraries/ghc-prim/ghc.mk:4: libraries/ghc-prim/dist-install/build/GHC/Prim/Ext.o] Error 1
#+end_example

not sure if related https://gitlab.haskell.org/ghc/ghc/-/issues/17962

also seems to fail at other steps, but the build processes more or less works
as expected if you go in an just call make as root ... very likely because the
environment is totally different

**** previous attempts (fails)
=mkdir -p /usr/x86_64-pc-linux-musl/etc/portage/patches/dev-lang/ghc-9.0.2=
#+begin_src diff :tangle ./docker-profile/base/ghc-inlining-old-do-not-use.patch
--- a/rts/sm/Evac.c       2021-09-15 15:27:32.000000000 -0000
+++ b/rts/sm/Evac.c       2022-12-01 19:52:51.123156616 -0000
@@ -58,7 +58,7 @@
 #define MAX_THUNK_SELECTOR_DEPTH 16
 
 static void eval_thunk_selector (StgClosure **q, StgSelector *p, bool);
-STATIC_INLINE void evacuate_large(StgPtr p);
+static void evacuate_large(StgPtr p);
 
 /* -----------------------------------------------------------------------------
    Allocate some space in which to copy an object.

#+end_src

from ghc fc8a7f8f2aed3420dcbe2c5c25a525634779166f
#+begin_src diff ./docker-profile/base/ghc-inlining.patch
diff --git a/includes/Rts.h b/includes/Rts.h
index 1e5a60262b..027d5173a1 100644
--- a/includes/Rts.h
+++ b/includes/Rts.h
@@ -37,12 +37,17 @@ extern "C" {
 #include "HsFFI.h"
 #include "RtsAPI.h"
 
-// Turn off inlining when debugging - it obfuscates things
+// Disencourage gcc from inlining when debugging - it obfuscates things
 #if defined(DEBUG)
 # undef  STATIC_INLINE
 # define STATIC_INLINE static
 #endif
 
+// Fine grained inlining control helpers.
+#define ATTR_ALWAYS_INLINE __attribute__((always_inline))
+#define ATTR_NOINLINE      __attribute__((noinline))
+
+
 #include "rts/Types.h"
 #include "rts/Time.h"
 
diff --git a/rts/sm/Evac.c b/rts/sm/Evac.c
index e660fad1d8..8595a80c38 100644
--- a/rts/sm/Evac.c
+++ b/rts/sm/Evac.c
@@ -58,7 +58,7 @@
 #define MAX_THUNK_SELECTOR_DEPTH 16
 
 static void eval_thunk_selector (StgClosure **q, StgSelector *p, bool);
-STATIC_INLINE void evacuate_large(StgPtr p);
+ATTR_NOINLINE static void evacuate_large(StgPtr p);
 
 /* -----------------------------------------------------------------------------
    Allocate some space in which to copy an object.
@@ -134,8 +134,13 @@ alloc_for_copy (uint32_t size, uint32_t gen_no)
    The evacuate() code
    -------------------------------------------------------------------------- */
 
-/* size is in words */
-STATIC_INLINE GNUC_ATTR_HOT void
+/* size is in words
+
+   We want to *always* inline this as often the size of the closure is static,
+   which allows unrolling of the copy loop.
+
+ */
+ATTR_ALWAYS_INLINE GNUC_ATTR_HOT static inline void
 copy_tag(StgClosure **p, const StgInfoTable *info,
          StgClosure *src, uint32_t size, uint32_t gen_no, StgWord tag)
 {
@@ -194,7 +199,7 @@ copy_tag(StgClosure **p, const StgInfoTable *info,
 }
 
 #if defined(PARALLEL_GC) && !defined(PROFILING)
-STATIC_INLINE void
+ATTR_ALWAYS_INLINE static inline void
 copy_tag_nolock(StgClosure **p, const StgInfoTable *info,
          StgClosure *src, uint32_t size, uint32_t gen_no, StgWord tag)
 {
@@ -231,7 +236,7 @@ copy_tag_nolock(StgClosure **p, const StgInfoTable *info,
  ,* pointer of an object, but reserve some padding after it.  This is
  ,* used to optimise evacuation of TSOs.
  ,*/
-static bool
+ATTR_ALWAYS_INLINE static inline bool
 copyPart(StgClosure **p, StgClosure *src, uint32_t size_to_reserve,
          uint32_t size_to_copy, uint32_t gen_no)
 {
@@ -283,7 +288,7 @@ spin:
 
 
 /* Copy wrappers that don't tag the closure after copying */
-STATIC_INLINE GNUC_ATTR_HOT void
+ATTR_ALWAYS_INLINE GNUC_ATTR_HOT static inline void
 copy(StgClosure **p, const StgInfoTable *info,
      StgClosure *src, uint32_t size, uint32_t gen_no)
 {
@@ -301,7 +306,7 @@ copy(StgClosure **p, const StgInfoTable *info,
    that has been evacuated, or unset otherwise.
    -------------------------------------------------------------------------- */
 
-static void
+ATTR_NOINLINE static void
 evacuate_large(StgPtr p)
 {
   bdescr *bd;
-- 
2.37.4
#+end_src

We haven't resolved all the issues yet ...
#+begin_example
In file included from includes/Rts.h:244,

                 from rts/Interpreter.c:8:0: error: 
rts/Interpreter.c: In function interpretBCO:

includes/rts/StablePtr.h:32:8: error:
     warning: inlining failed in call to deRefStablePtr: call is unlikely and code size would grow [-Winline]
       32 | StgPtr deRefStablePtr(StgStablePtr sp)
          |        ^~~~~~~~~~~~~~
   |
32 | StgPtr deRefStablePtr(StgStablePtr sp)
   |        ^

rts/Interpreter.c:1112:45: error:
     note: called from here
     1112 |                   ioAction = (StgClosure *) deRefStablePtr (
          |                                             ^~~~~~~~~~~~~~~~
     1113 |                       rts_breakpoint_io_action);
          |                       ~~~~~~~~~~~~~~~~~~~~~~~~~
     |
1112 |                   ioAction = (StgClosure *) deRefStablePtr (
     |                                             ^

#+end_example

let's see if 9.2.4 will compile any better
#+begin_src bash
mkdir -p /usr/x86_64-pc-linux-musl/etc/portage/repos.conf
cp /etc/portage/repos.conf/eselect-repo.conf /usr/x86_64-pc-linux-musl/etc/portage/repos.conf/
ACCEPT_KEYWORDS='**' FEATURES=-distcc USE=ghcbootstrap x86_64-pc-linux-musl-emerge =dev-lang/ghc-9.2.4::haskell   
#+end_src

... ugh nope, this one fails well before 9.0.2 does
#+begin_example
config.status: executing src commands
# wc on OS X has spaces in its output, which libffi's Makefile
# doesn't expect, so we tweak it to sed them out
mv libffi/build/Makefile libffi/build/Makefile.orig
sed "s#wc -w#wc -w | sed 's/ //g'#" < libffi/build/Makefile.orig > libffi/build/Makefile
"touch" libffi/stamp.ffi.static-shared.configure
make: *** [Makefile:128: ghc/stage2/build/tmp/ghc-stage2] Error 2
#+end_example

when running make in =libraries/ghc-prim= we find +some+ many additional issues
I have no idea why these are showing up in the musl cross builds when they are not in the native gnu case
a sampling of the kinds of issues
#+begin_example
In function 'updateRemembSetPushTSO':

rts/sm/NonMovingMark.c:693:20: error:
     warning: inlining failed in call to 'finish_upd_rem_set_mark': --param max-inline-insns-single limit reached [-Winline]
      693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
          |                    ^~~~~~~~~~~~~~~~~~~~~~~
    |
693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
    |                    ^

rts/sm/NonMovingMark.c:719:9: error:
     note: called from here
      719 |         finish_upd_rem_set_mark((StgClosure *) tso);
          |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    |
719 |         finish_upd_rem_set_mark((StgClosure *) tso);
    |         ^
rts/sm/NonMovingMark.c: In function 'updateRemembSetPushStack':

rts/sm/NonMovingMark.c:693:20: error:
     warning: inlining failed in call to 'finish_upd_rem_set_mark': --param max-inline-insns-single limit reached [-Winline]
      693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
          |                    ^~~~~~~~~~~~~~~~~~~~~~~
    |
693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
    |                    ^

rts/sm/NonMovingMark.c:734:13: error:
     note: called from here
      734 |             finish_upd_rem_set_mark((StgClosure *) stack);
          |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    |
734 |             finish_upd_rem_set_mark((StgClosure *) stack);
    |             ^

rts/sm/NonMovingMark.c:693:20: error:
     warning: inlining failed in call to 'finish_upd_rem_set_mark': --param max-inline-insns-single limit reached [-Winline]
      693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
          |                    ^~~~~~~~~~~~~~~~~~~~~~~
    |
693 | STATIC_INLINE void finish_upd_rem_set_mark(StgClosure *p)
    |                    ^

rts/sm/NonMovingMark.c:734:13: error:
     note: called from here
      734 |             finish_upd_rem_set_mark((StgClosure *) stack);
          |             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    |
734 |             finish_upd_rem_set_mark((StgClosure *) stack);
    |    
#+end_example

** sbcl-cross
*** run
#+begin_src bash
docker run \
--volumes-from local-repos-snap \
-v /mnt/str/portage/distfiles:/var/cache/distfiles \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
-it tgbugs/gnu:sbcl-cross
#+end_src

Test that the cross compiled version is working as expected.
#+begin_src bash
docker run \
-it tgbugs/gnu:sbcl-cross \
/usr/x86_64-pc-linux-musl/usr/bin/sbcl --core /usr/x86_64-pc-linux-musl/usr/lib/sbcl/sbcl.core
#+end_src
*** build
#+begin_src screen
docker build \
--tag tgbugs/gnu:sbcl-cross \
--network host \
--add-host local.binhost:127.0.0.1 \
--file gnu/sbcl-cross/Dockerfile gnu/sbcl-cross
#+end_src
*** file
#+begin_src dockerfile :tangle ./gnu/sbcl-cross/Dockerfile
FROM tgbugs/gnu:crossdev

# sbcl crossdev build looks in the wrong place for asdf and uiop
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   dev-lisp/asdf \
   dev-lisp/uiop \
   dev-lisp/sbcl \
<<&archive-or-rm>>

# TODO move these into the builder probably?
ADD alt-ld.patch /etc/portage/patches/dev-lisp/sbcl/alt-ld.patch
ADD alt-ld.patch /usr/x86_64-pc-linux-musl/etc/portage/patches/dev-lisp/sbcl/alt-ld.patch
ADD 99-sbcl /usr/x86_64-pc-linux-musl/etc/portage/package.use/99-sbcl

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
x86_64-pc-linux-musl-emerge -j4 -q \
   --getbinpkg \
   --keep-going \
   sys-libs/musl \
   app-arch/zstd \
   sys-libs/zlib \
<<&archive-or-rm>>

RUN \
ln -s /usr/x86_64-pc-linux-musl/usr/lib/libc.so /lib/ld-musl-x86_64.so.1

RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
x86_64-pc-linux-musl-emerge -j4 -q \
   dev-lisp/asdf \
   dev-lisp/uiop \
   dev-lisp/sbcl \
<<&archive-or-rm>>
#+end_src

Until we can figure out how to get the cross build to link this
correctly we leave it out.  We don't really need it since this build
is only for a bootstrapping sbcl on musl. There are native ways to do
this inside of the sbcl toolset itself, but for now this is easier.
# */* static-libs static
#+name: &config-cross-sbcl-package.use
#+begin_src conf :tangle ./gnu/sbcl-cross/99-sbcl
dev-lisp/sbcl -zlib -zstd  # crossdev compile reference errors
#+end_src

#+begin_src diff :tangle ./gnu/sbcl-cross/alt-ld.patch
diff --git a/make-target-contrib.sh b/make-target-contrib.sh
index 217b5b2e0..45406f506 100755
--- a/make-target-contrib.sh
+++ b/make-target-contrib.sh
@@ -29,8 +29,12 @@ if [ -z "$CC" ]; then
     fi
 fi
 
+if [ -z "${LD}" ]; then
+    LD=ld
+fi
+
 unset EXTRA_CFLAGS # avoid any potential interference 
-export CC LANG LC_ALL
+export CC LD LANG LC_ALL
 
 # Load our build configuration
 . output/build-config
diff --git a/src/runtime/GNUmakefile b/src/runtime/GNUmakefile
index 0543c1244..284755e5c 100644
--- a/src/runtime/GNUmakefile
+++ b/src/runtime/GNUmakefile
@@ -24,7 +24,6 @@ SBCL_PAXCTL ?= :
 LINKFLAGS += -g
 DEPEND_FLAGS = -MM
 GREP = grep
-LD = ld
 
 # By default, don't make and use a library, just use the object files.
 LIBSBCL = $(OBJS)
#+end_src

#+begin_src bash
git clone https://github.com/sbcl/sbcl.git
pushd sbcl
git remote add daewok https://github.com/daewok/sbcl.git
git fetch daewok
git checkout daewok/static-executable
#+end_src

** musl/cross/sbcl
TODO loop this in so that we can keep the cross build image up to date so that
we aren't bootstrapping cross builds with ancient versions of sbcl, not sure
the extent to which that matters, but at a certain point musl might update and
the we could be in trouble, also requires that we loop in gnu sbcl-cross and
have some logic for new sbcl releases

the general objective here is to avoid the situation where there is rot in the
bootstrapping process because we always use the docker image the same way there
has been rot with clojure pulling everything from maven, less of a risk in this
case but still something to keep an eye on

another way to do this would be to emerge the crossbuilt binpkg directly and then
go with system-bootstrap in that way instead the sideloading that we do here which
requires modification of the ebuild, yeah, this seems cleaner than cooking up this
image since it avoids the need for more docker build commands entirely

*** build
#+name: &gnu-build-musl-cross-sbcl
#+begin_src screen
docker build \
--tag tgbugs/musl:cross-sbcl \
--file musl/cross/sbcl/Dockerfile musl/cross/sbcl

docker rm cross-sbcl
docker create -v /sbcl --name cross-sbcl tgbugs/musl:cross-sbcl /bin/true
#+end_src

*** file
#+begin_src dockerfile :tangle ./musl/cross/sbcl/Dockerfile
FROM busybox:latest

WORKDIR /

COPY --from=tgbugs/gnu:package-builder-snap /usr/x86_64-pc-linux-musl/usr/lib/sbcl /sbcl
COPY --from=tgbugs/gnu:package-builder-snap /usr/x86_64-pc-linux-musl/usr/bin/sbcl /sbcl/src/runtime/sbcl

RUN \
mkdir -p /sbcl/obj/sbcl-home \
&& ln -s /sbcl/contrib /sbcl/obj/sbcl-home/contrib \
&& mkdir -p /sbcl/output \
&& ln -s /sbcl/sbcl.core /sbcl/output/sbcl.core

VOLUME /sbcl
#+end_src

* other
** bootstrap attempt 3
So, this nearly works, except for the fact that you can't actually
use bind mounts from inside a nested docker container because the
mount source location is always on the docker daemon file system
not on the client file system (sigh). You can't even find it in
the normal docker wsl container and it pollution remains forever.

In conclusion. If you need to do this on windows, just do it in wsl2
directly e.g. via an ubuntu vm and don't bother with trying to use
docker windows for the bootstrap/build process, you can push the
images somewhere and pull the back to windows if you need them much
more easily.

There is still the issue of the mismatch between the daemon file
system and the client file system with the docker socket approach, but
just think host thoughts and you can fly (sigh). Have to run the binpkgs
mkdir setup bit on the host/daemon file system.

in the host environment you must already have
1. docker
2. +git+ nope, you just need to be able to see this section of the file
3. +emacs+ nope, just copy and paste

debug build
#+begin_src sh
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-e _UID=${UID} \
--rm \
-it \
alpine:latest
#+end_src

On windows.
#+begin_src powershell
docker run -v //var/run/docker.sock:/var/run/docker.sock --rm -it alpine:latest
#+end_src

step 0 don't use =docker build= at this level (duh!?)
#+begin_src bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-u ${_UID} \
alpine:latest \
/dockerfiles/bin/alpine-bootstrap
#+end_src

#+header: :shebang "#!/usr/bin/env sh"
#+begin_src bash :tangle bin/alpine-bootstrap
DUID=48

addgroup -g ${DUID} docker

apk add bash emacs-nox git screen
apk add curl python3 # missed these one, needed to run the pkghost for the time being
apk add xdg-user-dirs
apk add docker
# hrm!? (no, doesn't work, because windows weirdness)
#apk add podman
#ln -s podman /usr/bin/docker

_UID=1000
USER_NAME=user

addgroup -g ${_UID} ${USER_NAME} \
&& adduser -HD -u ${_UID} -G ${USER_NAME} ${USER_NAME} \
&& adduser ${USER_NAME} docker

xdg-user-dirs-update

git clone https://github.com/tgbugs/dockerfiles.git

dockerfiles/source.org setup  # TODO

cd dockerfiles

# watch out sometimes this can fail on first run?
# or uh, er running ./source.org build in it kills it?
# do the screen thing below (still debugging)
screen -s /bin/bash -dmS org-session -t server
_screen_socket=$(screen -ls | grep org-session | awk '{ print $1 }')

# XXX if something is misconfigured this can cause screen to terminate ???
# possibly due to missing python and/or missing curl? or possibly due to having only a single screen open? not clear
# looks like it was due to missing curl or missing python, or missing them and running in busybox sh or something?
./source.org build  # to start the binpkg server

# the screen manual is useless the behavior is insane and inconsistent
# but apparently this invocation will create and switch to the new window
# I have no idea how to get the forsaken thing to switch from cli if you
# somehow create a screen without a title so here we are ...
screen -S ${_screen_socket} -X screen -t build

./source.org build --repos # to bootstrap the images we need on the real system, the bootstrap environment has e.g. the distfiles, but
#+end_src

** alpine bootstrap
Barely working and incomplete bootstrap in alpine.
Might be useful for CI depending on how well the
tgbugs/musl:docker work progresses.

# this is cute but just git clone because there are a couple of legacy
# cases where git is needed in the host environment (unfortunately)
#+name: &aboot
#+begin_src elisp
(let ((u (pop argv)) (p (pop argv)) (enable-local-eval t)) (mkdir (file-name-directory p) t) (org-babel-do-load-languages 'org-babel-load-languages '((screen . t))) (url-handler-mode 1) (find-file u) (write-file p) (chmod p #o755) (find-file p) (org-sbe workflow))
#+end_src

#+begin_src screen
SHELL=/bin/bash screen -dmS org-session
# emacs -batch -eval "<<&aboot>>" https://raw.githubusercontent.com/tgbugs/dockerfiles/master/source.org ~/git/dockerfiles/source.org
#+end_src

# unfortunate for the builder mount ...
#+begin_src bash
docker run -v /var/run/docker.sock:/var/run/docker.sock -u ${UID} -it tgbugs/other:alpine-bootstrap
#+end_src

#+begin_src screen
<<&docker-build>>
--build-arg DUID=$(getent group docker | cut -d: -f3) \
--tag tgbugs/other:alpine-bootstrap \
--file other/alpine-bootstrap/Dockerfile other/alpine-bootstrap
#+end_src

#+begin_src dockerfile :tangle ./other/alpine-bootstrap/Dockerfile
FROM alpine:latest

ARG DUID=48

RUN  \
addgroup -g ${DUID} docker

RUN \
apk add bash docker emacs-nox git screen

ARG UID=1000
ARG USER_NAME=user

RUN \
addgroup -g ${UID} ${USER_NAME} \
&& adduser -HD -u ${UID} -G ${USER_NAME} ${USER_NAME} \
&& adduser ${USER_NAME} docker

USER $USER_NAME

WORKDIR /home/${USER_NAME}

RUN \
xdg-user-dirs-update

RUN \
git clone https://github.com/tgbugs/dockerfiles.git

RUN \
dockerfiles/source.org setup

# RUN \
# mkdir -p ~/files/binpkgs/multi
#+end_src
** ubuntu-genera-base
*** file
#+begin_src dockerfile :tangle ./other/ubuntu-genera-base/Dockerfile
FROM ubuntu:18.04

RUN apt update

RUN apt install -y \
curl \
inetutils-inetd \
vim \
telnet \
nfs-common \
nfs-kernel-server \
iproute2 \
libx11-6 \
xserver-xephyr \
x11-xserver-utils \
iputils-ping
#+end_src

*** build
# docker pull ubuntu:18.04
# docker run -it ubuntu:18.04

#+begin_src bash
docker build \
--tag tgbugs/other:ubuntu-genera-base \
--file other/ubuntu-genera-base/Dockerfile other/ubuntu-genera-base
#+end_src

** genera
A docker file that specifies and image that can run Open Genera 2.0.

We can't distribute the final image for a variety of reasons, however
the configured base image can be distributed and is a valuable
resource as a result.

Useful as a starting point for debugging why it won't work on other systems.

Nearly everything is working except that docker and NFS exports seem
to be fighting with each other.  Old comments on the web mention
issues with exporting overlayfs mounts to NFS, but this commit from
2017 <https://patchwork.kernel.org/project/linux-fsdevel/patch/
1508258671-10800-15-git-send-email-amir73il@gmail.com/> seems to have
fixed that issue.

Three entry points.
https://www.reddit.com/r/lisp/comments/lhsltk/lisp_implementations_similiar_to_old_lisp_machines/
https://gist.github.com/oubiwann/1e7aadfc22e3ae908921aeaccf27e82d
https://archives.loomcom.com/genera/genera-install.html
*** exploration
This will eventually become a docker file, but right now it is still
too experimental so the workflow is run and commit rather than build.

#+begin_src bash
xhost local:docker

# NET_ADMIN apparently needed for tuntap creation (bsd jails and vnets looking really good right now)
# SYS_ADMIN apparently needed to get NFS exports to work (bsd jails looking even better!?)
# generally though this is ok because we are really only using this docker image as a way to get
# an environment where genera will run

docker run -it \
-v ~/files/tmp/genera:/files \
-v /tmp/.X11-unix:/tmp/.X11-unix \
-e DISPLAY=$DISPLAY \
--device /dev/net/tun \
--cap-add NET_ADMIN \
--cap-add SYS_ADMIN \
tgbugs/other:ubuntu-genera-base
#+end_src

In the docker shell (will become the docker file or a script run in the docker file)
#+begin_src bash
#mkdir -p /dev/net
#mknod /dev/net/tun c 10 200

# tunnel creation
# ip tuntap delete dev tap0 mode tap  # to remove since it fights with the host
ip tuntap add dev tap0 mode tap
ip addr add 192.168.2.1/24 dev tap0
ip link set dev tap0 up

# inetd

echo "time      stream  tcp  nowait root internal" >> /etc/inetd.conf
echo "time      dgram   udp  wait   root internal" >> /etc/inetd.conf
echo "daytime   stream  tcp  nowait root internal" >> /etc/inetd.conf
echo "daytime   dgram   udp  wait   root internal" >> /etc/inetd.conf

service inetutils-inetd restart

# retrieve genera files TODO snapshot these to reduce redownload

mkdir genera
pushd genera
curl -LO https://archives.loomcom.com/genera/genera
chmod a+x genera
curl -L -O https://archives.loomcom.com/genera/worlds/Genera-8-5-xlib-patched.vlod
curl -L -O https://archives.loomcom.com/genera/worlds/VLM_debugger
curl -L -O https://archives.loomcom.com/genera/worlds/dot.VLM
mv dot.VLM .VLM
mkdir lib
pushd lib
curl -L -O https://archives.loomcom.com/genera/var_lib_symbolics.tar.gz
tar xvf var_lib_symbolics.tar.gz
chown -R root:root symbolics
ln -s /genera/lib/symbolics /var/lib/symbolics  # may fail
popd

sed -i 's,/home/seth,,' .VLM
echo "192.168.2.1    genera-vlm" >> /etc/hosts
echo "192.168.2.2    genera" >> /etc/hosts

# nfs XXX TODO broken

echo 'RPCNFSDCOUNT="--nfs-version 2 8"' >> /etc/default/nfs-kernel-server
echo 'RPCMOUNTDOPTS="--nfs-version 2 --manage-gids"' >> /etc/default/nfs-kernel-server
echo "/files genera(rw,sync,no_subtree_check,all_squash,anonuid=1000,anongid=1000)" >> /etc/exports
# we really want to export / but I'm seeing the following error
# exportfs: / does not support NFS export
#echo "/ genera(rw,sync,no_subtree_check,all_squash,anonuid=1000,anongid=1000)" >> /etc/exports

# I think rpcbind needs be be started, otherwise nfs-kernel-server may fail to start
# and/or NFS will not work at all
service rpcbind start

service nfs-kernel-server restart

# start genera using host X server

DISPLAY=:0.0; ./genera -coldloadgeometry 640x480+0+0 -geometry 1280x1024+0+0 &

# start genera using Xephyr (a bit more stable/predictable)

DISPLAY=:0.0; Xephyr -br -reset -terminate -ac -noreset -screen 1280x1024 :3 &
DISPLAY=:3.0; ./genera -coldloadgeometry 640x480+0+0 -geometry 1280x1024+0+0 &

#+end_src
* sckan
=base= must be built before =services=, obvious from errors or from
reading the docker files but doesn't jump out and is the inverse of
the order of specification (because services is rebuilt more
frequently).
** build and save
This is the block that has better flow control and will block until finished.
However, setting the return value to be non-zero on failure is not done yet.
#+name: &sckan-build-save-image
#+begin_src bash :noweb yes
# --tag run:sckan-build-save-image # XXX hack to run non-image blocks
set -e
<<&musl-def-build-sckan-base>>

<<&musl-def-build-sckan-services>>

d-build-sckan-base
d-build-sckan-services

<<&sckan-save-image>>
#+end_src
** save
To save a gzipped archive run
#+name: &sckan-save-image
#+begin_src screen
# first run the following to find the latest build, then
docker image ls tgbugs/sckan:data-*
_datetime=$(docker image ls tgbugs/sckan:data-* | sort | tail -n 1 | awk '{ print $2 }')
echo writing docker image to /tmp/docker-sckan-${_datetime}.tar.gz
docker save tgbugs/sckan:${_datetime} | gzip > /tmp/docker-sckan-${_datetime}.tar.gz
#+end_src

To restore from the archive run
#+begin_src bash
docker load --input sckan-data-2021-09-30T232453Z.tar.gz
#+end_src
** services
This combines the raw (data) base image with prefixes.conf and services.yaml.
Note that the image names for these are shifted so that they don't confuse users.
The logic is that base + services = data, but users don't know anything about services.
*** container
Test this with tgbugs/musl:kg-release-user
#+name: &create-sckan-data
#+begin_src bash
docker container inspect sckan-data > /dev/null && \
docker rm sckan-data
docker create -v /var/lib/blazegraph -v /var/lib/scigraph --name sckan-data tgbugs/sckan:latest /bin/true
#+end_src

#+name: &create-sckan-data-if-not-exists
#+begin_src bash
docker container inspect sckan-data > /dev/null || \
{ echo creating sckan-data image 1>&2; docker create -v /var/lib/blazegraph -v /var/lib/scigraph --name sckan-data tgbugs/sckan:latest /bin/true;}
#+end_src

*** build
#+name: &musl-def-build-sckan-services
#+begin_src bash
function d-build-sckan-services () {
[ -f ./source.org ] || { echo not in dockerfiles; return 1;}

local _sckanl _image_date

mkdir -p ./sckan/services/blazegraph

[ -d ./sckan/services/scigraph ] && rm -r ./sckan/services/scigraph
mkdir -p ./sckan/services/scigraph

pushd ./sckan/services

# blazegraph
# TODO from zip
_sckanl="$(ls -d /tmp/build/release-*-sckan | sort -u | tail -n 1)"
rsync -a ${_sckanl}/data/prefixes.conf blazegraph/ || return $?

# scigraph
sh ~/git/pyontutils/nifstd/scigraph/README.org tangle  # FIXME bad, assumes ~/git/pyontutils present on the host :/
~/git/pyontutils/nifstd/scigraph/bin/run-build-services-sparc || return $?
rsync -a /tmp/scigraph-build/sparc/services.yaml scigraph/ || return $?
rsync -a /tmp/scigraph-build/sparc/$(head -n 1 scigraph/services.yaml | cut -b3-) scigraph/ || return $?

popd

_image_date=$(date --utc +%Y-%m-%dT%H%M%SZ)

docker build \
--tag tgbugs/sckan:data-${_image_date} \
--tag tgbugs/sckan:latest \
--file sckan/services/Dockerfile sckan/services
}
#+end_src

#+name: &musl-build-sckan-services
#+begin_src screen
<<&musl-def-build-sckan-services>>
d-build-sckan-services
#+end_src

*** file
#+begin_src dockerfile :tangle ./sckan/services/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD --chown=834:834 blazegraph/ /build/var/lib/blazegraph
ADD --chown=835:835 scigraph/ /build/var/lib/scigraph

FROM tgbugs/sckan:base-latest
COPY --from=builder /build /
#+end_src

** base
*** build
# TODO release snapshots for these images

# FIXME scigraph log folder ownership is still fucked after all these years ffs
#+name: &musl-def-build-sckan-base
#+begin_src screen
function d-build-sckan-base () {
[ -f ./source.org ] || { echo not in dockerfiles; return 1;}

local _sckanl _zip _path _scigr _image_date

mkdir -p ./sckan/base/blazegraph

[ -d ./sckan/base/scigraph ] && rm -r ./sckan/base/scigraph
mkdir -p ./sckan/base/scigraph

pushd ./sckan/base

# TODO from zip
_sckanl="$(ls -d /tmp/build/release-*-sckan | sort -u | tail -n 1)"
rsync -a ${_sckanl}/data/blazegraph.jnl blazegraph/ || return $?

# TODO from zip
_zip=$(realpath /tmp/scigraph-build/sparc-sckan/LATEST)
_path="${_zip%.*}"
_scigr="${_path##*/}"
rsync -a ${_path} scigraph/ || return $?
ln -s /var/lib/scigraph/${_scigr} scigraph/graph || return $?

popd

_image_date=$(date --utc +%Y-%m-%dT%H%M%SZ)

docker build \
--tag tgbugs/sckan:base-${_image_date} \
--tag tgbugs/sckan:base-latest \
--file sckan/base/Dockerfile sckan/base
}
#+end_src

#+name: &musl-build-sckan-base
#+begin_src screen
<<&musl-def-build-sckan-base>>
d-build-sckan-base
#+end_src

*** file
# /build/sckan/ this could include the provenance data, but I think we should probably leave it out?
# TODO also consider splitting blazegraph and scigraph volume images ?
# TODO have a version of this that does the builds itself instead of just copying everything in
#+begin_src dockerfile :tangle ./sckan/base/Dockerfile
FROM busybox:latest as builder

WORKDIR /build

ADD --chown=834:834 blazegraph/ /build/var/lib/blazegraph
ADD --chown=835:835 scigraph/ /build/var/lib/scigraph

FROM scratch
COPY --from=builder /build /
#+end_src

* utils :noexport:
# FIXME --network host is ok for now, but we should probably try to
# switch to using --ssh or something since it is needed for building
# all binpkg-only images
#+name: &docker-build
#+begin_src bash
docker build \
--network host \
--add-host local.binhost:127.0.0.1 \
#+end_src

#+name: &build-world
#+begin_src dockerfile
FROM tgbugs/musl:binpkg-only
<<&build-world-common>>
#+end_src

#+name: &build-world-nox
#+begin_src dockerfile
FROM tgbugs/musl:binpkg-only-nox
<<&build-world-common>>
#+end_src

#+name: &build-world-common
#+begin_src dockerfile

ARG ARCHIVE

ADD world /etc/portage/sets/docker

# -ebuild locks is so much faster building acct-* ebuilds first is MUCH faster
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
FEATURES=ebuild-locks emerge -1 -j4 -q -uDN $(emerge -p @docker | grep -o 'acct-.\+$' | sed 's/^/=/') \
;  emerge -j4 -q --backtrack=99 -uDN @docker \
<<&archive-or-rm>>
#+end_src

#+name: &archive-or-rm
#+begin_src dockerfile
;  export CODE=$? \
;  echo CODE $CODE \
;  [[ -n ${ARCHIVE} ]] \
|| { rm -r /var/cache/distfiles/* > /dev/null 2>&1 \
   ; rm -r /var/cache/binpkgs/* > /dev/null 2>&1 \
   ; rm -r /var/log/portage/elog/summary.log > /dev/null 2>&1 \
   ; rm -r /var/log/emerge-fetch.log > /dev/null 2>&1 \
   ; rm -r /var/log/emerge.log > /dev/null 2>&1;} \
;  exit $CODE
#+end_src

A build helper for use during development when you need to add
packages you forgot but don't want to rebuild the whole world.
#+name: &build-helper-temp
#+begin_src dockerfile
RUN --mount=from=tgbugs/repos:latest,source=/var/db/repos,target=/var/db/repos,rw \
emerge -j4 -q -uDN \
#+end_src

* automatic image dependency resolution
yeah we could do it with make or something
but technically all the contents are in this file
so we can use org to do it as well
#+begin_src bash
grep -r FROM --include='*Dockerfile'
#+end_src

TODO also need to track cases where artifacts have a cryptic dependencies
on other images e.g. openjdk, pypy3, sbcl-cross, etc. where we break strict
dependency tracking by e.g. building a package in a every so slightly tweaked
environment to avoid circular dependencies and then quickpkg to get the result

we're going to need context so we can find the build command
and then work backwards from the build commands to the Dockerfile
and then to the tangle target to the block contents
#+begin_src elisp :lexical yes :results none
(defun find-build-command (libc name)
  (let ((blockname (format "&%s-build-%s" libc name)))
    '()))

(setq
 docker-file-depends-on-tag
 (let (out)
   (save-excursion ; TODO also need to save fold state
     (org-babel-map-executables nil
       ;; (language body arguments switches name start coderef)
       (let* ((info (org-babel-get-src-block-info))
              (lang (nth 0 info))
              (body (orgstrap--expand-body info))
              (params (nth 2 info))
              (name (nth 4 info ))
              (tangle (cdr (assoc :tangle params))))
         (when (and (string= lang "dockerfile") tangle (not (string= tangle "no")))
           (setq out (cons
                      (cons
                       (substring tangle 2) ; drop ./ ; XXX FIXME error if doesnot start with ./
                       (with-temp-buffer
                         (insert body)
                         ;; TODO need to handle these kinds of cases
                         ;; ARG PROFILE_IMAGE=tgbugs/musl:profile-x
                         ;; ARG START_IMAGE=tgbugs/musl:pypy3
                         ;; don't bother trying to replicate this, it is
                         ;; vastly easier to just use evil-ex-global for now
                         (evil-ex-global (point-min) (point-max) "^\\(FROM\\|COPY --from=\\|RUN --mount=from=\\)" "d" t)
                         ;;(evil-ex-global (point-min) (point-max) "--from=builder" "d" nil) ; keep builder to make it easy to identify multi stage builds
                         (evil-ex-substitute (point-min) (point-max) '("^COPY --from=\\([^ ]+\\) .+$") "\\1")
                         (evil-ex-substitute (point-min) (point-max) '("^RUN --mount=from=\\([^ ,]+\\).+$") "\\1")
                         (split-string (replace-regexp-in-string "^FROM\\| as .+$" "" (buffer-string)) "\n" t " +"))) ; note, produces dupes
                      out))
           ))))
   out))

(setq
 tag-produced-by-docker-file
 (let (out)
   (save-excursion
     (org-babel-map-executables nil
       ;; (language body arguments switches name start coderef)
       (let* ((info (org-babel-get-src-block-info))
              (lang (nth 0 info))
              (body (orgstrap--expand-body info))
              (params (nth 2 info))
              (name (nth 4 info))
              (tangle (cdr (assoc :tangle params)))
              )
         (when (and name
                    (or (string= lang "screen")
                        (string= lang "bash"))
                    (string-match "&\\([^-]+\\)-build-\\(.+\\)" name))
           (setq out (cons
                      (cons
                       name
                       (with-temp-buffer
                         (insert (replace-regexp-in-string "\\\\\n" " " body))
                         (goto-char (point-min))
                         ;;(evil-ex-substitute (point-min) (point-max) '("\\\\n") " " "g") ; why doesn't this work ???
                         (evil-ex-global (point-min) (point-max) "^docker build" "d" t)
                         (goto-char (point-min))
                         ;;(re-search-forward "^--tag \\([^ ]+\\)[ \n]")
                         ;;(re-search-forward "^--file \\([^ ]+\\)[ \n]")

                         ;; TODO need to handle these kinds of cases
                         ;; --build-arg PROFILE_IMAGE='tgbugs/musl:profile-static-x' \
                         ;; --build-arg START_IMAGE='tgbugs/musl:updated' \
                         (cl-loop
                          for s in (split-string (replace-regexp-in-string " --" "\t" (buffer-string)) "\t" t " +")
                          when (string-match "^\\(tag\\|file\\) \\([^ ]+\\)" s)
                          collect (cons (match-string 1 s) (match-string 2 s)))))
                      out)))))
     (cl-loop
      for (name . alist) in out append
      (cl-loop
       with file = (cdr (assoc "file" alist)) ; there can be multiple tag
       for tag-pair in (cl-remove-if-not (lambda (p) (string= (car p) "tag")) alist)
       collect (cons
                (cdr tag-pair)
                file))))))

(setq
 tag-depends-on-tag
 (cl-loop
  for (tag . file) in tag-produced-by-docker-file
  collect
  (cons
   tag
   (cdr (assoc file docker-file-depends-on-tag)))))

(setq
 docker-file-depends-on-docker-file
 (cl-loop
  for (file . tags) in docker-file-depends-on-tag
  collect
  (cons
   file
   (cl-loop
    for tag in tags
    collect (or (cdr (assoc tag tag-produced-by-docker-file)) tag)))))

#+end_src

#+begin_src elisp :results none
(load "~/ni/dev/elisp/trees.el")
#+end_src

#+begin_src elisp
(let ((adj (multi-to-adj tag-depends-on-tag)))
  (string-join
   (cl-loop
    for r in '(nil t)
    collect
    (format-tree nil (adj->nested adj :reverse r) :layout :down :node-formatter (lambda (n) (format "%s" n))))))
#+end_src

* Bootstrap :noexport:

#+name: orgstrap
#+begin_src elisp :results none :lexical yes :noweb yes
(defvar-local refresh      nil)
(defvar-local repos        nil)
(defvar-local sync-gentoo  nil)
(defvar-local resnap       nil)
(defvar-local live-rebuild nil)
(defvar-local no-pkg-bldr  nil)
(defvar-local only-static  nil)

(defvar-local path-distfiles (expand-file-name "<<&host-distfiles-path()>>"))
(defvar-local path-binpkgs-root (expand-file-name "<<&host-binpkgs-root-path()>>")) ; FIXME multi
(defvar-local path-binpkgs (concat path-binpkgs-root "/" "<<&host-binpkgs-repo-name()>>"))
(defvar-local path-distcc-hosts (expand-file-name "<<&host-distcc-hosts-path()>>"))
(defvar-local path-ssh (expand-file-name "<<&host-ssh-path()>>"))

(defvar-local path-sparcron-sparcur-config nil)
(defvar-local path-sparcron-secrets nil)
(defvar-local path-sparcron-gsaro nil)
; FIXME should we only mount the key itself to avoid config issues internally ? probably yes ? also known_hosts issues, the docker build ssh-agent doesn't really help here

(defun make-screen-vars ()
  (apply #'format
         "export _refresh=%s _repos=%s _sync_gentoo=%s _resnap=%s _live_rebuild=%s _nopkgbldr=%s _only_static=%s \\
_path_distfiles=%S _path_binpkgs_root=%S _path_binpkgs=%S _path_distcc_hosts=%S _path_ssh=%S \\
%s %s %s;"
         (append
          (mapcar (lambda (b) (if b 1 ""))
                  (list refresh repos sync-gentoo resnap live-rebuild no-pkg-bldr only-static))
          (append
           (list path-distfiles path-binpkgs-root path-binpkgs path-distcc-hosts path-ssh)
           ;; FIXME TODO see whether whether we can use the path-sparcron approach for all paths?
           ;; the difference seems to be whether it makes sense to embed default paths in this file
           ;; because in some cases e.g. paths with identifiers in their name, defaults are not helpful
           (mapcar (lambda (s)
                     (if (symbol-value s)
                         (format "_%s=%S" (string-replace "-" "_" (symbol-name s)) (symbol-value s))
                       ""))
                   '(path-sparcron-sparcur-config path-sparcron-secrets path-sparcron-gsaro))))))

(defun run-setup ()
;; docker daemon config ; XXX this can't be done due to bad design of docker (investigate podman)
;; docker client config
;;  remote repo key
;; binpkgs path
;; portage ssh keys
;; distcc hosts file

  ;; in alpine:latest around 2023-07-11 it seems to be sufficient to just set the binpkgs paths
  ;; at least when running in windows for bootstrap we don't seem to need any further configuration
  (let ((bp "~/files/binpkgs"))
    (cl-loop
     for sp in '("multi" "cross/gnu/x86_64-pc-linux-musl" "cross/gnu/x86_64-gentoo-linux-musl" )
     do (make-directory (expand-file-name sp bp) 'parents))))

(defun fix-ocbe-source ()
  "it would seem that blanking `enable-local-eval' resets this"
  (setq-local
   org-confirm-babel-evaluate
   (lambda (lang body)
     (not (or (and (member lang '("elisp" "emacs-lisp"))
                   (or (string= body "value")
                       (string= body "(make-screen-vars)")))
              (and (member lang '("screen"))
                   (string= (cl-subseq body 0 15) "HISTFILE=~/.org")))))))

(defun dedupe-lines (blockname)
  (let* ((info (save-excursion
                 (org-save-outline-visibility 'use-markers
                   (let ((obs (org-babel-find-named-block blockname)))
                     (if obs (goto-char obs)
                       (error "No block named %s" blockname)))
                   (org-babel-get-src-block-info))))
         (body (org-babel--expand-body info)))
    (string-join (sort (cl-remove-duplicates
                        (split-string body "\n")
                        :test #'string=)
                       #'string<)
                 "\n")))

(fix-ocbe-source)

(defmacro with-error-on-fail (&rest body)
  `(cl-letf (((symbol-function 'org-babel-eval-error-notify)
              (lambda (exit-code stderr)
                (when (> exit-code 0)
                  (error "Babel evaluation failed with %s%s%s"
                         exit-code
                         (if stderr "\n" "")
                         (if stderr stderr ""))))))
     ,@body))

(defun find-tag-build-scr-block (tag &optional execute)
  (save-excursion
    (goto-char (point-min))
    (re-search-forward (concat "--tag " tag " ")) ; trailing space to avoid shared prefix issues
    (let ((info (org-babel-get-src-block-info)))
      (when execute
        (org-babel-execute-src-block))
      ;; always return the name we we execute build blocks they are nearly always screen
      ;; and the return value is thus nil
      (nth 4 info))))

(defun execute-tag-build-src-block (tag)
  (find-tag-build-scr-block 'execute))

(defun execute-src-block (name)
  (save-excursion ; can't use org-sbe because it calls some other random block !?
    (org-babel-goto-named-src-block name)
    (org-babel-execute-src-block)))

(defun cli-opt (opt)
  (let ((index (cl-position opt argv :test #'string=)))
    (and index (elt argv (1+ index)))))

(when noninteractive
  (let ((setup (member "setup" argv))
        (build (member "build" argv))
        (tangle (member "tangle" argv))
        (build-image (member "build-image" argv)) ; FIXME yes the naming is annoying
        (test (member "test" argv)))
    (let ((no-screen    (and build (member "--no-screen" argv)))
          (refresh      (and build (member "--refresh" argv)))
          (repos        (and build (member "--repos" argv)))
          (sync-gentoo  (and build (member "--sync-gentoo" argv)))
          (resnap       (and build (member "--resnap" argv)))
          (only-static  (and build (member "--only-static" argv)))
          (live-rebuild (and build (member "--live-rebuild" argv)))
          (no-pkg-bldr  (and build (or
                                    (member "--no-build" argv)
                                    (member "--no-pkg-bldr" argv))))
          (cli-images  (cdr build-image)) ; must come last will build all listed images in order they are listed
          (cli-pretend (member "--pretend" argv)) ; FIXME sequencing wrt build-image and cli-images
          (cli-uif (cli-opt "--user-init-file"))
          (cli-ued (cli-opt "--user-emacs-directory"))
          (cli-ssc (cli-opt "--path-sparcron-sparcur-config"))
          (cli-ss  (cli-opt "--path-sparcron-secrets"))
          (cli-sg  (cli-opt "--path-sparcron-gsaro")))
      (setq argv nil) ; FIXME should we allow the uif to see argv? probably not?
      (when cli-uif
        (load cli-uif)
        (setq user-init-file cli-uif))
      (let ((path-sparcron-sparcur-config (or cli-ssc path-sparcron-sparcur-config ""))
            (path-sparcron-secrets (or cli-ss path-sparcron-secrets ""))
            (path-sparcron-gsaro (or cli-sg path-sparcron-gsaro "")))
        ;; FIXME need an extensible way to handle this probably? see prrequaestor for inspiration?
        ;; or not quite because we need a way to pass variable values from options, but that means
        ;; that the elisp does have to explicitly make the bridge unless we come up with a fully
        ;; dynamic/generative option, see how frequently we actually need it, vs using cli-uif
        (when (or build build-image test)
          (org-babel-do-load-languages
           'org-babel-load-languages
           '((screen . t)
             (shell . t))))
        (when setup
          (run-setup))
        (when build
          ;; either use bash internally here (bad) or try to use screen
          ;; currently going with screen since we have a hack for passing vars
          ;;(message "build:\n%s" (make-screen-vars))
          ;; check that setup was run correctly, if not, fail
          ;; start screen
          ;; start up the packages server
          ;; run build
          ;; TODO block until build finishes or fails
          (fix-ocbe-source)
          (let ((process (execute-src-block "workflow-cli")))
            ;; prevent emacs exit from killing the subprocess before it has finished
            ;; send to the screen session
            (while (eq (process-status process) 'run)
              (sleep-for 0.1))))
        (when build-image ; FIXME sometimes leaving from this can still produce Wrong type argument: keymapp, nil
          (fix-ocbe-source)
          (if cli-images
              (let* ((org-confirm-babel-evaluate (lambda (_l _b))) ; XXX BEWARE THESE WILL RUN WITHOUT PROMPTING
                     (max-iml 0)
                     backtrace-on-error-noninteractive ; we mostly know where the error is if we hit this
                     (image-blocks
                      (cl-loop
                       for image in cli-images
                       do (let ((iml (length image)))
                            (when (> iml max-iml)
                              (setq max-iml iml))) ; FIXME consider collecting image names, printing them and only then executing them
                       collect (cons
                                image
                                (with-error-on-fail ; FIXME sequencing here is a bit off, so we fail to get the block name
                                 (find-tag-build-scr-block image (not cli-pretend)))))))
                (message "image src blocks:")
                (cl-loop
                 for (image . block) in image-blocks do
                 (message "%s %s %s" image (make-string (- max-iml (length image)) ?\s) block)))
            (let (backtrace-on-error-noninteractive)
              (user-error "no images to build"))))
        (when tangle
          (unless (fboundp #'dockerfile-mode)
            (define-derived-mode dockerfile-mode prog-mode "Dockerfile"
              "Stub to avoid comment-start issues"
              (set (make-local-variable 'comment-start) "#")))
          (let (enable-local-eval)
            ;; this pattern is required when tangling to avoid infinite loops
            (revert-buffer nil t nil)
            (setq-local find-file-literally nil))
          (fix-ocbe-source)
          (org-babel-tangle))
        (when test
          ;; sckan
          ;; kg-dev
          ;; kg-release
          ;; sparcron (probably not? should do it)
          (fix-ocbe-source)
          ;; collect named test blocks by pattern
          (let (blocks)
            (save-excursion
              (goto-char (point-min))
              (while (re-search-forward "#\\+name: \\(&test-.+\\)" nil t)
                (setq blocks (cons (match-string 1) blocks))
                ;; FIXME in screen these kind of need to block??? FIXME alternately forward stdout/err instead of capturing?
                (ignore-errors (org-babel-execute-src-block))))
            (message "test blocks run: %s" blocks)))))))
#+end_src

Helper block to make it easier to use elisp functions as noweb inputs.
#+name: ident
#+begin_src elisp :var value=""
value
#+end_src

Helper blocks to pass variables to screen from cli.
#+name: &screen-pass-vars
#+begin_src elisp
(make-screen-vars)
#+end_src

Note that all screen blocks have an implicit eval.
#+name: &screen-set-vars
#+begin_src screen
<<&screen-pass-vars()>>
#+end_src

*** test with-error-on-fail
#+name: bash-exit-0-test
#+begin_src bash
exit 0
#+end_src

#+RESULTS: bash-exit-0-test

#+name: bash-exit-1-test
#+begin_src bash
exit 1
#+end_src

#+begin_src elisp :lexical yes
(let ((org-confirm-babel-evaluate (lambda (_l _b))))
  (with-error-on-fail (execute-src-block "bash-exit-0-test"))
  (message "before")
  (with-error-on-fail (execute-src-block "bash-exit-1-test"))
  (message "after"))
#+end_src

** Local Variables :ARCHIVE:
# close powershell comment #>
# Local Variables:
# eval: (progn (setq-local orgstrap-min-org-version "8.2.10") (let ((a (org-version)) (n orgstrap-min-org-version)) (or (fboundp #'orgstrap--confirm-eval) (not n) (string< n a) (string= n a) (error "Your Org is too old! %s < %s" a n))) (defun orgstrap-norm-func--dprp-1-0 (body) (let ((p (read (concat "(progn\n" body "\n)"))) (m '(defun defun-local defmacro defvar defvar-local defconst defcustom)) print-quoted print-length print-level) (cl-labels ((f (b) (cl-loop for e in b when (listp e) do (or (and (memq (car e) m) (let ((n (nthcdr 4 e))) (and (stringp (nth 3 e)) (or (cl-subseq m 3) n) (f n) (or (setcdr (cddr e) n) t)))) (f e))) p)) (prin1-to-string (f p))))) (unless (boundp 'orgstrap-norm-func) (defvar-local orgstrap-norm-func orgstrap-norm-func-name)) (defun orgstrap-norm-embd (body) (funcall orgstrap-norm-func body)) (unless (fboundp #'orgstrap-norm) (defalias 'orgstrap-norm #'orgstrap-norm-embd)) (defun orgstrap-org-src-coderef-regexp (_fmt &optional label) (let ((fmt org-coderef-label-format)) (format "\\([:blank:]*\\(%s\\)[:blank:]*\\)$" (replace-regexp-in-string "%s" (if label (regexp-quote label) "\\([-a-zA-Z0-9_][-a-zA-Z0-9_ ]*\\)") (regexp-quote fmt) nil t)))) (unless (fboundp #'org-src-coderef-regexp) (defalias 'org-src-coderef-regexp #'orgstrap-org-src-coderef-regexp)) (defun orgstrap--expand-body (info) (let ((coderef (nth 6 info)) (expand (if (org-babel-noweb-p (nth 2 info) :eval) (org-babel-expand-noweb-references info) (nth 1 info)))) (if (not coderef) expand (replace-regexp-in-string (org-src-coderef-regexp coderef) "" expand nil nil 1)))) (defun orgstrap--confirm-eval-portable (lang _body) (not (and (member lang '("elisp" "emacs-lisp")) (let* ((body (orgstrap--expand-body (org-babel-get-src-block-info))) (body-normalized (orgstrap-norm body)) (content-checksum (intern (secure-hash orgstrap-cypher body-normalized)))) (eq orgstrap-block-checksum content-checksum))))) (unless (fboundp #'orgstrap--confirm-eval) (defalias 'orgstrap--confirm-eval #'orgstrap--confirm-eval-portable)) (let (enable-local-eval) (vc-find-file-hook)) (let ((ocbe org-confirm-babel-evaluate) (obs (org-babel-find-named-block "orgstrap"))) (if obs (unwind-protect (save-excursion (setq-local orgstrap-norm-func orgstrap-norm-func-name) (setq-local org-confirm-babel-evaluate #'orgstrap--confirm-eval) (goto-char obs) (org-babel-execute-src-block)) (when (eq org-confirm-babel-evaluate #'orgstrap--confirm-eval) (setq-local org-confirm-babel-evaluate ocbe)) (ignore-errors (org-set-visibility-according-to-property))) (warn "No orgstrap block."))))
# End:
